{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "from collections import Counter\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tromso_description = \"\"\"Tromsø is a beautiful city between FJORDS, ISLANDS AND MOUNTAINS, with a visible past, a fascinating history, a lively, colourful city centre, an inclusive nightlife and numerous attractions. Use the city as a base to foray into Arctic wilderness chasing Midnight Sun and Northern Lights. 01. 02.\"\"\"\n",
    "oslo_description = \"\"\"Oslo is considered as a global city and is the major Norwegian hub for trading, shipping and banking. Location of Oslo: OSLO IS POSITIONED AT THE NORTHERNMOST END OF THE OSLOFJORD and occupies around 40 big and small islands within its limits. The climate of the region is temperate, humid.\"\"\"\n",
    "mining_course_description = \"\"\"The aim of the course is to introduce the students to the concepts and techniques of natural languages processing and analysis, unstructured information analysis and management for better decision- making by deriving valuable insights from enterprise content regardless of source or format. The course provides deep and rich knowledge of text analysis techniques and applications including sentiment analysis and opinion mining, information access and text mining, document classification, topic extraction and other techniques and applications using real-world data and cases.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepText(text, tokenName):\n",
    "    tokenName = word_tokenize(text)\n",
    "    tokenName = [token.lower() for token in tokenName]\n",
    "    tokenName = [token.strip() for token in tokenName]\n",
    "    tokenName = [word for word in tokenName if word not in stop_words]\n",
    "    tokenName = [word for word in tokenName if word.isalnum()]\n",
    "    return tokenName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tromsø', 'beautiful', 'city', 'fjords', 'islands', 'mountains', 'visible', 'past', 'fascinating', 'history']\n",
      "['oslo', 'considered', 'global', 'city', 'major', 'norwegian', 'hub', 'trading', 'shipping', 'banking']\n",
      "['aim', 'course', 'introduce', 'students', 'concepts', 'techniques', 'natural', 'languages', 'processing', 'analysis']\n"
     ]
    }
   ],
   "source": [
    "token_tromso = prepText(tromso_description, 'token_tromso')\n",
    "token_oslo = prepText(oslo_description, 'token_oslo')\n",
    "token_nlp =  prepText(mining_course_description, 'token_nlp')\n",
    "\n",
    "\n",
    "print(token_tromso[:10])\n",
    "print(token_oslo[:10])\n",
    "print(token_nlp[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Project Gutenberg eBook of Crime and Punishment, by Fyodor Dostoevsky\n",
      "\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with a\n",
      "['project', 'gutenberg', 'ebook', 'crime', 'punishment', 'fyodor', 'dostoevsky', 'ebook', 'use', 'anyone']\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "print(raw[:200])\n",
    "\n",
    "token_CP = prepText(raw, 'token_CP')\n",
    "print(token_CP[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('city', 3), ('tromsø', 1), ('beautiful', 1), ('fjords', 1), ('islands', 1), ('mountains', 1), ('visible', 1), ('past', 1), ('fascinating', 1), ('history', 1)]\n"
     ]
    }
   ],
   "source": [
    "wordCount = Counter(token_tromso)\n",
    "print(wordCount.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def buildBow(corpus: list):\n",
    "    vectorizer = CountVectorizer()\n",
    "    bow_representations = vectorizer.fit_transform([\" \".join(description) for description in corpus])\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    bow_matrix = bow_representations.toarray()\n",
    "    return bow_matrix, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Representations:\n",
      "[[1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1]]\n",
      "[[1 1 4 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1]]\n",
      "[[1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2]]\n",
      "Feature Names (Words):\n",
      "['01' '02' 'arctic' 'attractions' 'base' 'beautiful' 'centre' 'chasing'\n",
      " 'city' 'colourful' 'fascinating' 'fjords' 'foray' 'history' 'inclusive'\n",
      " 'islands' 'lights' 'lively' 'midnight' 'mountains']\n",
      "['40' 'around' 'banking' 'big' 'city' 'climate' 'considered' 'end'\n",
      " 'global' 'hub' 'humid' 'islands' 'limits' 'location' 'major'\n",
      " 'northernmost' 'norwegian' 'occupies' 'oslo' 'oslofjord']\n",
      "['access' 'aim' 'analysis' 'applications' 'better' 'cases'\n",
      " 'classification' 'concepts' 'content' 'course' 'data' 'deep' 'deriving'\n",
      " 'document' 'enterprise' 'extraction' 'format' 'including' 'information'\n",
      " 'insights']\n",
      "['14' '1500' '1849' '1859' '1861' '1864' '1880' '20' '2001' '2021' '2554'\n",
      " '30' '47' '50' '501' '60' '801' '809' '84116' '90']\n"
     ]
    }
   ],
   "source": [
    "bow_tromso, feature_tromso = buildBow([token_tromso])\n",
    "bow_oslo, feature_oslo = buildBow([token_oslo])\n",
    "bow_nlp, feature_nlp = buildBow([token_nlp])\n",
    "bow_CP, feature_CP = buildBow([token_CP])\n",
    "\n",
    "# Display the BoW representations\n",
    "print(\"BoW Representations:\")\n",
    "print(bow_tromso[:, :20])\n",
    "print(bow_oslo[:, :20])\n",
    "print(bow_nlp[:, :20])\n",
    "print(bow_CP[:, :20])\n",
    "\n",
    "# Display the feature names\n",
    "print(\"Feature Names (Words):\")\n",
    "print(feature_tromso[:20])\n",
    "print(feature_oslo[:20])\n",
    "print(feature_nlp[:20])\n",
    "print(feature_CP[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
