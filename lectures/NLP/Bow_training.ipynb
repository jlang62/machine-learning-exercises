{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import copy\n",
    "import math\n",
    "\n",
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = \"\"\"The bustling city of New York is a melting pot of cultures and a hub for business and innovation. With its iconic skyline, Central Park, and the Statue of Liberty, New York City has a unique charm that draws millions of tourists every year. The city that never sleeps is known for its diverse neighborhoods, such as Chinatown, Little Italy, and Harlem, each offering a distinct cultural experience. The subway system, yellow taxis, and the famous Times Square are symbols of the city's energy and pace of life. New York is home to Wall Street, the epicenter of global finance, and Silicon Alley, a burgeoning tech hub. Whether you're exploring art at the Metropolitan Museum, enjoying a Broadway show, or savoring a classic New York-style pizza, the Big Apple has something for everyone.\"\"\"\n",
    "txt2 = \"\"\"The Great Barrier Reef is a natural wonder of the world, located off the coast of Queensland, Australia. It is the largest coral reef system on the planet, spanning over 2,300 kilometers and comprising thousands of individual reefs and islands. The reef is a haven for marine biodiversity, housing a stunning array of coral species, fish, turtles, sharks, and other marine life. Snorkeling and diving in the crystal-clear waters of the Great Barrier Reef offer a chance to witness this underwater paradise up close. Tourists from around the globe flock to explore its vibrant coral formations, including the renowned Heart Reef. This ecological wonder, however, faces challenges from climate change and pollution, making conservation efforts crucial to protect its delicate ecosystem.\"\"\"\n",
    "txt3 = \"\"\"New York City, often referred to as the \"Big Apple,\" is a bustling metropolis on the East Coast of the United States. It's a city known for its iconic skyline, which includes the Empire State Building and One World Trade Center, and its diverse neighborhoods, such as Brooklyn, Queens, and the Bronx. Central Park, a massive urban green space, offers a peaceful escape in the heart of the city. The city is also famous for its culinary scene, featuring a wide range of international cuisines. From the historic charm of the Statue of Liberty to the vibrant arts scene in SoHo, New York City has something for everyone. Whether you're a tourist or a resident, there's always something new and exciting happening in the city that never sleeps.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_pro(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens] # everything lowercase\n",
    "    tokens = [word.strip() for word in tokens] # strips whitespaces\n",
    "    tokens = [word for word in tokens if word.isalnum()] # only alpha numerical values\n",
    "    tokens = [word for word in tokens if not word in stops] # removes stopwords\n",
    "    return tokens \n",
    "\n",
    "def genBow(tokens):\n",
    "    bow = Counter(tokens)\n",
    "    return bow\n",
    "\n",
    "def printBow(bow, queryString):\n",
    "    query_frequency = Counter(queryString)\n",
    "    tf_vec = []\n",
    "    for word in bow:\n",
    "        if word in queryString:\n",
    "            tf = query_frequency[word] #/len(bow)\n",
    "        else:\n",
    "            tf = 0\n",
    "        tf_vec.append(tf)\n",
    "    return tf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bustling',\n",
       " 'city',\n",
       " 'new',\n",
       " 'york',\n",
       " 'melting',\n",
       " 'pot',\n",
       " 'cultures',\n",
       " 'hub',\n",
       " 'business',\n",
       " 'innovation']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [txt1, txt2, txt3]\n",
    "corpus_tokens = token_pro((' ').join(corpus))\n",
    "corpus_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bustling</th>\n",
       "      <th>city</th>\n",
       "      <th>new</th>\n",
       "      <th>york</th>\n",
       "      <th>melting</th>\n",
       "      <th>pot</th>\n",
       "      <th>cultures</th>\n",
       "      <th>hub</th>\n",
       "      <th>business</th>\n",
       "      <th>innovation</th>\n",
       "      <th>...</th>\n",
       "      <th>international</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>historic</th>\n",
       "      <th>arts</th>\n",
       "      <th>soho</th>\n",
       "      <th>tourist</th>\n",
       "      <th>resident</th>\n",
       "      <th>always</th>\n",
       "      <th>exciting</th>\n",
       "      <th>happening</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bustling  city  new  york  melting  pot  cultures  hub  business  \\\n",
       "0         1     4    4     3        1    1         1    2         1   \n",
       "1         0     0    0     0        0    0         0    0         0   \n",
       "2         1     6    3     2        0    0         0    0         0   \n",
       "\n",
       "   innovation  ...  international  cuisines  historic  arts  soho  tourist  \\\n",
       "0           1  ...              0         0         0     0     0        0   \n",
       "1           0  ...              0         0         0     0     0        0   \n",
       "2           0  ...              1         1         1     1     1        1   \n",
       "\n",
       "   resident  always  exciting  happening  \n",
       "0         0       0         0          0  \n",
       "1         0       0         0          0  \n",
       "2         1       1         1          1  \n",
       "\n",
       "[3 rows x 172 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = genBow(corpus_tokens)\n",
    "\n",
    "bow_txt1 = genBow(token_pro(txt1))\n",
    "bow_txt2 = genBow(token_pro(txt2))\n",
    "bow_txt3 = genBow(token_pro(txt3))\n",
    "\n",
    "#running our sentences through the tf function:\n",
    "tf_txt1 = printBow(bow_corpus, bow_txt1)\n",
    "tf_txt2 = printBow(bow_corpus, bow_txt2)\n",
    "tf_txt3 = printBow(bow_corpus, bow_txt3)\n",
    "\n",
    "#Converting to dataframe for visualization\n",
    "tf_df= pd.DataFrame([tf_txt1, tf_txt2, tf_txt3], columns = bow_corpus.keys())\n",
    "tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027156</td>\n",
       "      <td>0.539212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.539212</td>\n",
       "      <td>0.035584</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  1.000000  0.027156  0.539212\n",
       "1  0.027156  1.000000  0.035584\n",
       "2  0.539212  0.035584  1.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "df2 = pd.DataFrame(cosine_similarity(tf_df, dense_output=True))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.69314718, 1.28768207, 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 1.28768207, 0.        , 1.69314718,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 1.69314718,\n",
       "        1.28768207, 0.        , 1.28768207, 0.        , 0.        ,\n",
       "        0.        , 1.28768207, 1.69314718, 5.15072829, 1.69314718,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.69314718, 1.69314718, 0.        , 1.69314718,\n",
       "        1.28768207, 0.        , 1.69314718, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 1.69314718,\n",
       "        1.69314718, 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        1.69314718, 0.        , 1.28768207, 0.        , 1.69314718,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 1.69314718, 0.        , 3.38629436,\n",
       "        1.28768207, 0.        , 0.        , 0.        , 1.69314718,\n",
       "        0.        , 0.        , 1.69314718, 0.        , 1.28768207,\n",
       "        0.        , 1.28768207, 1.28768207, 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        1.69314718, 1.69314718, 1.69314718, 0.        , 1.28768207,\n",
       "        5.15072829, 0.        , 1.69314718, 0.        , 1.69314718,\n",
       "        0.        , 1.28768207, 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 1.69314718, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.28768207, 1.69314718, 0.        , 0.        ,\n",
       "        1.69314718, 1.28768207, 1.28768207, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 1.28768207, 1.69314718, 0.        , 1.69314718,\n",
       "        1.69314718, 1.69314718, 1.69314718, 1.69314718, 0.        ,\n",
       "        1.69314718, 0.        , 1.28768207, 0.        , 0.        ,\n",
       "        0.        , 1.69314718, 0.        , 0.        , 0.        ,\n",
       "        1.69314718, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.69314718, 1.69314718, 5.15072829],\n",
       "       [0.        , 0.        , 1.69314718, 0.        , 0.        ,\n",
       "        1.69314718, 3.38629436, 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 1.69314718,\n",
       "        1.69314718, 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.69314718, 1.69314718, 1.69314718, 1.28768207, 1.69314718,\n",
       "        1.69314718, 5.07944154, 1.69314718, 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 1.69314718, 0.        , 0.        , 1.69314718,\n",
       "        1.69314718, 1.69314718, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.69314718,\n",
       "        0.        , 1.69314718, 0.        , 0.        , 0.        ,\n",
       "        1.69314718, 1.69314718, 1.69314718, 0.        , 1.69314718,\n",
       "        3.38629436, 0.        , 0.        , 0.        , 1.69314718,\n",
       "        1.28768207, 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 1.69314718, 1.69314718, 0.        ,\n",
       "        0.        , 1.69314718, 0.        , 1.69314718, 0.        ,\n",
       "        1.69314718, 0.        , 1.28768207, 0.        , 1.69314718,\n",
       "        1.69314718, 3.38629436, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 1.69314718, 0.        , 0.        , 0.        ,\n",
       "        1.69314718, 0.        , 0.        , 0.        , 1.69314718,\n",
       "        1.69314718, 0.        , 1.69314718, 0.        , 1.69314718,\n",
       "        0.        , 8.4657359 , 1.69314718, 0.        , 1.69314718,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.69314718,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 1.69314718, 1.69314718, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.69314718,\n",
       "        0.        , 0.        , 1.28768207, 0.        , 1.69314718,\n",
       "        1.69314718, 0.        , 0.        , 0.        , 1.28768207,\n",
       "        0.        , 1.69314718, 0.        , 1.69314718, 3.38629436,\n",
       "        1.28768207, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.28768207, 0.        , 0.        , 1.69314718,\n",
       "        0.        , 0.        , 1.28768207, 0.        , 0.        ,\n",
       "        1.69314718, 1.69314718, 1.69314718, 0.        , 0.        ,\n",
       "        1.28768207, 1.69314718, 1.28768207, 0.        , 0.        ,\n",
       "        0.        , 1.28768207, 0.        , 7.72609243, 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.28768207, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.69314718,\n",
       "        1.69314718, 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.28768207, 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 1.69314718, 0.        , 0.        ,\n",
       "        0.        , 1.69314718, 1.69314718, 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.28768207, 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.69314718, 1.69314718, 0.        , 0.        ,\n",
       "        1.28768207, 1.69314718, 0.        , 0.        , 0.        ,\n",
       "        1.28768207, 1.69314718, 0.        , 0.        , 0.        ,\n",
       "        1.69314718, 0.        , 0.        , 0.        , 1.28768207,\n",
       "        0.        , 1.28768207, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.69314718, 0.        , 1.69314718,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.28768207,\n",
       "        3.86304622, 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 1.28768207, 1.69314718, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        1.69314718, 0.        , 0.        , 1.69314718, 0.        ,\n",
       "        1.69314718, 2.57536414, 0.        , 3.38629436, 0.        ,\n",
       "        0.        , 1.28768207, 1.28768207, 0.        , 1.69314718,\n",
       "        1.69314718, 0.        , 0.        , 0.        , 1.69314718,\n",
       "        1.69314718, 1.28768207, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.69314718, 0.        , 1.69314718, 0.        ,\n",
       "        0.        , 0.        , 1.69314718, 1.69314718, 1.28768207,\n",
       "        0.        , 0.        , 1.69314718, 0.        , 0.        ,\n",
       "        1.28768207, 0.        , 0.        , 2.57536414]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords, white spaces, and punctuation, and convert to lowercase, and only keep alpha-numeric values\n",
    "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True, token_pattern=r'(?u)\\b[A-Za-z]+\\b', norm=None)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt1</th>\n",
       "      <th>txt2</th>\n",
       "      <th>txt3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>txt1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>0.423433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt2</th>\n",
       "      <td>0.012064</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txt3</th>\n",
       "      <td>0.423433</td>\n",
       "      <td>0.025243</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          txt1      txt2      txt3\n",
       "txt1  1.000000  0.012064  0.423433\n",
       "txt2  0.012064  1.000000  0.025243\n",
       "txt3  0.423433  0.025243  1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(cosine_similarity(X, dense_output=True), columns = ['txt1', 'txt2', 'txt3'], index = ['txt1', 'txt2', 'txt3'])\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
