{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# KUC, PGR210\n",
    "# P6.2\n",
    "# 14:30 - 16:00\n",
    "# Suppose you have three texts, describing the city of Oslo, NLP, and the city of Trondheim, i.e.,\n",
    "\n",
    "txt1  = \"Oslo is the economic and governmental centre of Norway. The city is also a hub of Norwegian trade, banking, industry and shipping. It is an important centre for maritime industries and maritime trade in Europe. The city is home to many companies within the maritime sector, some of which are among the world's largest shipping companies, shipbrokers and maritime insurance brokers. Oslo is a pilot city of the Council of Europe and the European Commission intercultural cities programme.\"\n",
    "txt2 = \"Natural language processing (NLP) is a subfield of \" \\\n",
    "            \"linguistics, computer science, and artificial intelligence \" \\\n",
    "            \"concerned with the interactions between computers and \" \\\n",
    "            \"human language, in particular how to program computers \" \\\n",
    "            \"to process and analyze large amounts of natural language data.\" \\\n",
    "            \" The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\"\n",
    "tx3 = \"Trondheim has a very mild climate for its northerly latitude, resulting in moderate summers and winters that often remain above the freezing point in seaside areas. On higher elevation, though, the microclimate is colder and snowier. The city functions as the seat of the County Mayor of Trøndelag county, but not as the administrative centre, which is Steinkjer. This is to make the county more efficient and not too centralized, as Trøndelag is the third largest county in Norway.\"\n",
    "\n",
    "Implement the code functioning the same as in P6.1, however, this time, the code should import sklearn.feature_extraction.text for the implementation:\n",
    "1. Have a group discussion on corpus: compare the generated corpus with the corpus in P6.1.\n",
    "2. generate BoW (bag of words) from scratch, represent each text and understand the representation.\n",
    "3. generate TF-IDF from scratch, represent each text and understand the representation.\n",
    "4. find the most similar two texts through BoW and TF-IDF combined with cosine_similarity , respectively among the given three texts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import copy\n",
    "import math\n",
    "\n",
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1  = \"Oslo is the economic and governmental centre of Norway. The city is also a hub of Norwegian trade, banking, industry and shipping. It is an important centre for maritime industries and maritime trade in Europe. The city is home to many companies within the maritime sector, some of which are among the world's largest shipping companies, shipbrokers and maritime insurance brokers. Oslo is a pilot city of the Council of Europe and the European Commission intercultural cities programme.\"\n",
    "txt2 = \"Natural language processing (NLP) is a subfield of \" \\\n",
    "            \"linguistics, computer science, and artificial intelligence \" \\\n",
    "            \"concerned with the interactions between computers and \" \\\n",
    "            \"human language, in particular how to program computers \" \\\n",
    "            \"to process and analyze large amounts of natural language data.\" \\\n",
    "            \" The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\"\n",
    "txt3 = \"Trondheim has a very mild climate for its northerly latitude, resulting in moderate summers and winters that often remain above the freezing point in seaside areas. On higher elevation, though, the microclimate is colder and snowier. The city functions as the seat of the County Mayor of Trøndelag county, but not as the administrative centre, which is Steinkjer. This is to make the county more efficient and not too centralized, as Trøndelag is the third largest county in Norway.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_pro(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens] # everything lowercase\n",
    "    tokens = [word.strip() for word in tokens] # strips whitespaces\n",
    "    tokens = [word for word in tokens if word.isalnum()] # only alpha numerical values\n",
    "    tokens = [word for word in tokens if not word in stops] # removes stopwords\n",
    "    return tokens \n",
    "\n",
    "def genBow(tokens):\n",
    "    bow = Counter(tokens)\n",
    "    return bow\n",
    "\n",
    "def printBow(bow, queryString):\n",
    "    query_frequency = Counter(queryString)\n",
    "    tf_vec = []\n",
    "    for word in bow:\n",
    "        if word in queryString:\n",
    "            tf = query_frequency[word] #/len(bow)\n",
    "        else:\n",
    "            tf = 0\n",
    "        tf_vec.append(tf)\n",
    "    return tf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oslo',\n",
       " 'economic',\n",
       " 'governmental',\n",
       " 'centre',\n",
       " 'norway',\n",
       " 'city',\n",
       " 'also',\n",
       " 'hub',\n",
       " 'norwegian',\n",
       " 'trade']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [txt1, txt2, txt3]\n",
    "tokens_corpus = token_pro((' ').join(corpus))\n",
    "tokens_corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('language', 7), ('natural', 5), ('city', 4), ('maritime', 4), ('county', 4), ('centre', 3), ('documents', 3), ('oslo', 2), ('norway', 2), ('trade', 2)]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = genBow(tokens_corpus)\n",
    "print(bow_corpus.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  101  102  103  104  \\\n",
       "0    2    1    1    2    1    3    1    1    1    2  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    1    1    1    0    0    0    0  ...    1    4    1    2   \n",
       "\n",
       "   105  106  107  108  109  110  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    1    1    1    1    1    1  \n",
       "\n",
       "[3 rows x 111 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_txt1 = genBow(token_pro(txt1))\n",
    "bow_txt2 = genBow(token_pro(txt2))\n",
    "bow_txt3 = genBow(token_pro(txt3))\n",
    "\n",
    "#running our sentences through the tf function:\n",
    "tf_txt1 = printBow(bow_corpus, bow_txt1)\n",
    "tf_txt2 = printBow(bow_corpus, bow_txt2)\n",
    "tf_txt3 = printBow(bow_corpus, bow_txt3)\n",
    "\n",
    "#Converting to dataframe for visualization\n",
    "tf_df= pd.DataFrame([tf_txt1, tf_txt2, tf_txt3])\n",
    "tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.09191602, 0.09191602,\n",
       "        0.        , 0.09191602, 0.        , 0.27143541, 0.09191602,\n",
       "        0.        , 0.        , 0.        , 0.09191602, 0.        ,\n",
       "        0.09191602, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.139809  , 0.        , 0.09191602, 0.20971351,\n",
       "        0.        , 0.        , 0.09191602, 0.18383204, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09191602, 0.        , 0.        , 0.        , 0.09191602,\n",
       "        0.        , 0.        , 0.18383204, 0.09191602, 0.        ,\n",
       "        0.0699045 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09191602, 0.        , 0.        , 0.09191602,\n",
       "        0.        , 0.09191602, 0.        , 0.09191602, 0.05428708,\n",
       "        0.        , 0.09191602, 0.09191602, 0.        , 0.        ,\n",
       "        0.09191602, 0.        , 0.        , 0.09191602, 0.        ,\n",
       "        0.27143541, 0.09191602, 0.        , 0.        , 0.        ,\n",
       "        0.0699045 , 0.        , 0.        , 0.        , 0.09191602,\n",
       "        0.36766408, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.0699045 ,\n",
       "        0.09191602, 0.        , 0.        , 0.27143541, 0.        ,\n",
       "        0.        , 0.        , 0.18383204, 0.        , 0.09191602,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09191602,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09191602, 0.09191602, 0.18383204, 0.        ,\n",
       "        0.09191602, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.38000957, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05428708,\n",
       "        0.        , 0.18383204, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0699045 , 0.        , 0.        ,\n",
       "        0.0699045 , 0.09191602],\n",
       "       [0.        , 0.07153349, 0.        , 0.        , 0.        ,\n",
       "        0.07153349, 0.        , 0.07153349, 0.25349298, 0.        ,\n",
       "        0.        , 0.07153349, 0.10880612, 0.        , 0.07153349,\n",
       "        0.        , 0.        , 0.07153349, 0.07153349, 0.07153349,\n",
       "        0.        , 0.        , 0.07153349, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.14306698,\n",
       "        0.14306698, 0.07153349, 0.07153349, 0.07153349, 0.07153349,\n",
       "        0.        , 0.        , 0.07153349, 0.21460046, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07153349,\n",
       "        0.        , 0.        , 0.07153349, 0.        , 0.07153349,\n",
       "        0.07153349, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.07153349, 0.        , 0.07153349, 0.        , 0.12674649,\n",
       "        0.07153349, 0.        , 0.        , 0.07153349, 0.07153349,\n",
       "        0.        , 0.07153349, 0.07153349, 0.        , 0.07153349,\n",
       "        0.08449766, 0.        , 0.        , 0.50073441, 0.07153349,\n",
       "        0.        , 0.        , 0.07153349, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.35766744, 0.07153349, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07153349, 0.21124415, 0.        ,\n",
       "        0.        , 0.07153349, 0.        , 0.07153349, 0.        ,\n",
       "        0.        , 0.07153349, 0.14306698, 0.07153349, 0.        ,\n",
       "        0.07153349, 0.        , 0.        , 0.07153349, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07153349, 0.        , 0.07153349, 0.        ,\n",
       "        0.07153349, 0.        , 0.33799064, 0.07153349, 0.07153349,\n",
       "        0.07153349, 0.        , 0.        , 0.        , 0.08449766,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.14306698,\n",
       "        0.        , 0.07153349, 0.        , 0.        , 0.07153349,\n",
       "        0.05440306, 0.        ],\n",
       "       [0.09595656, 0.        , 0.09595656, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.17002047, 0.        ,\n",
       "        0.09595656, 0.        , 0.21893231, 0.        , 0.        ,\n",
       "        0.        , 0.09595656, 0.        , 0.        , 0.        ,\n",
       "        0.09595656, 0.07297744, 0.        , 0.        , 0.07297744,\n",
       "        0.09595656, 0.09595656, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.38382623, 0.        , 0.        , 0.        ,\n",
       "        0.09595656, 0.09595656, 0.        , 0.        , 0.        ,\n",
       "        0.07297744, 0.09595656, 0.        , 0.09595656, 0.        ,\n",
       "        0.        , 0.        , 0.09595656, 0.09595656, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17002047,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.22669396, 0.        , 0.09595656, 0.        , 0.        ,\n",
       "        0.07297744, 0.09595656, 0.        , 0.09595656, 0.        ,\n",
       "        0.        , 0.09595656, 0.09595656, 0.09595656, 0.09595656,\n",
       "        0.09595656, 0.        , 0.        , 0.09595656, 0.07297744,\n",
       "        0.        , 0.19191312, 0.        , 0.11334698, 0.09595656,\n",
       "        0.09595656, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09595656, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.09595656, 0.09595656, 0.        , 0.09595656,\n",
       "        0.09595656, 0.        , 0.        , 0.        , 0.09595656,\n",
       "        0.        , 0.        , 0.09595656, 0.        , 0.09595656,\n",
       "        0.        , 0.09595656, 0.45338791, 0.        , 0.        ,\n",
       "        0.        , 0.09595656, 0.09595656, 0.09595656, 0.05667349,\n",
       "        0.09595656, 0.        , 0.09595656, 0.19191312, 0.        ,\n",
       "        0.09595656, 0.        , 0.07297744, 0.09595656, 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.292792</td>\n",
       "      <td>0.368960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.292792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.368960</td>\n",
       "      <td>0.289598</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  1.000000  0.292792  0.368960\n",
       "1  0.292792  1.000000  0.289598\n",
       "2  0.368960  0.289598  1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "df2 = pd.DataFrame(cosine_similarity(X, dense_output=True))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
