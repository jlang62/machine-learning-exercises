{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "from urllib import request\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original content to handle with import numpy as np\n",
    "sentence1  = \"Oslo is the economic and governmental centre of Norway. The city is also a hub of Norwegian trade, banking, industry and shipping. It is an important centre for maritime industries and maritime trade in Europe. The city is home to many companies within the maritime sector, some of which are among the world's largest shipping companies, shipbrokers and maritime insurance brokers. Oslo is a pilot city of the Council of Europe and the European Commission intercultural cities programme.\"\n",
    "sentence2 = \"Natural language processing (NLP) is a subfield of \" \\\n",
    "            \"linguistics, computer science, and artificial intelligence \" \\\n",
    "            \"concerned with the interactions between computers and \" \\\n",
    "            \"human language, in particular how to program computers \" \\\n",
    "            \"to process and analyze large amounts of natural language data.\" \\\n",
    "            \" The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\"\n",
    "sentence3 = \"Trondheim has a very mild climate for its northerly latitude, resulting in moderate summers and winters that often remain above the freezing point in seaside areas. On higher elevation, though, the microclimate is colder and snowier. The city functions as the seat of the County Mayor of Trøndelag county, but not as the administrative centre, which is Steinkjer. This is to make the county more efficient and not too centralized, as Trøndelag is the third largest county in Norway.\"\n",
    "\n",
    "corpusList = [sentence1,sentence2,sentence3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genCorpus(corpusList: list):\n",
    "    corpus = ''.join(corpusList)\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def tokenText(text):\n",
    "    token = word_tokenize(text)\n",
    "    token = [token.lower() for token in token]\n",
    "    token = [token.strip() for token in token]\n",
    "    token = [word for word in token if word not in stop_words]\n",
    "    token = [word for word in token if word.isalnum()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    token = [lemmatizer.lemmatize(word, pos =\"a\") for word in token]\n",
    "    return token\n",
    "\n",
    "def genBow(token):\n",
    "    bow = Counter(token)\n",
    "    return bow\n",
    "\n",
    "\n",
    "def genTfVec(bow,query_str):\n",
    "    query_frequency = Counter(query_str)\n",
    "    # num_unique_words = len(bow)\n",
    "    # tf = times_sentence1_appears # / num_unique_words\n",
    "    # print(tf)\n",
    "    #%%\n",
    "    tf_vec = []\n",
    "    for word in bow:\n",
    "        if word in query_str:\n",
    "            tf = query_frequency[word] #/ len(bow)\n",
    "        else:\n",
    "            tf=0\n",
    "        tf_vec.append(tf)\n",
    "\n",
    "    return tf_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oslo', 'economic', 'governmental', 'centre', 'norway', 'city', 'also', 'hub', 'norwegian', 'trade', 'banking', 'industry', 'shipping', 'important', 'centre', 'maritime', 'industries', 'maritime', 'trade', 'europe', 'city', 'home', 'many', 'companies', 'within', 'maritime', 'sector', 'among', 'world', 'large', 'shipping', 'companies', 'shipbrokers', 'maritime', 'insurance', 'brokers', 'oslo', 'pilot', 'city', 'council', 'europe', 'european', 'commission', 'intercultural', 'cities', 'language', 'processing', 'nlp', 'subfield', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', 'language', 'particular', 'program', 'computers', 'process', 'analyze', 'large', 'amounts', 'natural', 'language', 'data', 'goal', 'computer', 'capable', 'understanding', 'contents', 'documents', 'including', 'contextual', 'nuances', 'language', 'within', 'technology', 'accurately', 'extract', 'information', 'insights', 'contained', 'documents', 'well', 'categorize', 'organize', 'documents', 'challenges', 'natural', 'language', 'processing', 'frequently', 'involve', 'speech', 'recognition', 'natural', 'language', 'understanding', 'natural', 'language', 'mild', 'climate', 'northerly', 'latitude', 'resulting', 'moderate', 'summers', 'winters', 'often', 'remain', 'freezing', 'point', 'seaside', 'areas', 'high', 'elevation', 'though', 'microclimate', 'cold', 'snowy', 'city', 'functions', 'seat', 'county', 'mayor', 'trøndelag', 'county', 'administrative', 'centre', 'steinkjer', 'make', 'county', 'efficient', 'centralized', 'trøndelag', 'third', 'large', 'county', 'norway']\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "corpus = genCorpus(corpusList)\n",
    "tokens_full = tokenText(''.join(corpus))\n",
    "\n",
    "print(tokens_full)\n",
    "print(len(tokens_full))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 7),\n",
       " ('city', 4),\n",
       " ('maritime', 4),\n",
       " ('natural', 4),\n",
       " ('county', 4),\n",
       " ('centre', 3),\n",
       " ('large', 3),\n",
       " ('documents', 3),\n",
       " ('oslo', 2),\n",
       " ('norway', 2)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = genBow(tokens_full)\n",
    "bow.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oslo', 'economic', 'governmental', 'centre', 'norway', 'city', 'also', 'hub', 'norwegian', 'trade', 'banking', 'industry', 'shipping', 'important', 'centre', 'maritime', 'industries', 'maritime', 'trade', 'europe', 'city', 'home', 'many', 'companies', 'within', 'maritime', 'sector', 'among', 'world', 'large', 'shipping', 'companies', 'shipbrokers', 'maritime', 'insurance', 'brokers', 'oslo', 'pilot', 'city', 'council', 'europe', 'european', 'commission', 'intercultural', 'cities', 'programme']\n",
      "['oslo', 'centre', 'norway']\n"
     ]
    }
   ],
   "source": [
    "tokens_sent1 = tokenText(sentence1)\n",
    "print(tokens_sent1)\n",
    "\n",
    "query = \"Oslo is the centre of Norway.\"\n",
    "query_token = tokenText(query)\n",
    "print(query_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[('language', 7), ('city', 4), ('maritime', 4), ('natural', 4), ('county', 4), ('centre', 3), ('large', 3), ('documents', 3), ('oslo', 2), ('norway', 2)]\n"
     ]
    }
   ],
   "source": [
    "tf_vec = genTfVec(bow,query_token)\n",
    "print(tf_vec)\n",
    "print(bow.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Counter({'language': 7, 'city': 4, 'maritime': 4, 'natural': 4, 'county': 4, 'centre': 3, 'large': 3, 'documents': 3, 'oslo': 2, 'norway': 2, 'trade': 2, 'shipping': 2, 'europe': 2, 'companies': 2, 'within': 2, 'processing': 2, 'computer': 2, 'computers': 2, 'understanding': 2, 'trøndelag': 2, 'economic': 1, 'governmental': 1, 'also': 1, 'hub': 1, 'norwegian': 1, 'banking': 1, 'industry': 1, 'important': 1, 'industries': 1, 'home': 1, 'many': 1, 'sector': 1, 'among': 1, 'world': 1, 'shipbrokers': 1, 'insurance': 1, 'brokers': 1, 'pilot': 1, 'council': 1, 'european': 1, 'commission': 1, 'intercultural': 1, 'cities': 1, 'nlp': 1, 'subfield': 1, 'linguistics': 1, 'science': 1, 'artificial': 1, 'intelligence': 1, 'concerned': 1, 'interactions': 1, 'human': 1, 'particular': 1, 'program': 1, 'process': 1, 'analyze': 1, 'amounts': 1, 'data': 1, 'goal': 1, 'capable': 1, 'contents': 1, 'including': 1, 'contextual': 1, 'nuances': 1, 'technology': 1, 'accurately': 1, 'extract': 1, 'information': 1, 'insights': 1, 'contained': 1, 'well': 1, 'categorize': 1, 'organize': 1, 'challenges': 1, 'frequently': 1, 'involve': 1, 'speech': 1, 'recognition': 1, 'mild': 1, 'climate': 1, 'northerly': 1, 'latitude': 1, 'resulting': 1, 'moderate': 1, 'summers': 1, 'winters': 1, 'often': 1, 'remain': 1, 'freezing': 1, 'point': 1, 'seaside': 1, 'areas': 1, 'high': 1, 'elevation': 1, 'though': 1, 'microclimate': 1, 'cold': 1, 'snowy': 1, 'functions': 1, 'seat': 1, 'mayor': 1, 'administrative': 1, 'steinkjer': 1, 'make': 1, 'efficient': 1, 'centralized': 1, 'third': 1})\n"
     ]
    }
   ],
   "source": [
    "query_str = 'Oslo language. It was established in 1842 following a parliamentary decision from 1836. Originally located in the Royal Palace, Oslo, it got its own museum building in 1882, designed by Heinrich Ernst and Adolf Schirmer. Former names of the museum include Den norske stats sentralmuseum for billedkunst and from 1903 to 1920 Statens Kunstmuseum. Directors include Jens Thiis (1908–1941), Sigurd Willoch (1946–1973), Knut Berg (1975–1995), Tone Skedsmo (1995–2000) and Anniken Thue (2001–2003).'\n",
    "tokens_query = tokenText(query_str)\n",
    "tf_vec_query = genTfVec(bow,tokens_query)\n",
    "print(tf_vec_query)\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('language', 7), ('city', 4), ('maritime', 4), ('natural', 4), ('county', 4), ('centre', 3), ('large', 3), ('documents', 3), ('oslo', 2), ('norway', 2)]\n",
      "dict_keys(['oslo', 'economic', 'governmental', 'centre', 'norway', 'city', 'also', 'hub', 'norwegian', 'trade', 'banking', 'industry', 'shipping', 'important', 'maritime', 'industries', 'europe', 'home', 'many', 'companies', 'within', 'sector', 'among', 'world', 'large', 'shipbrokers', 'insurance', 'brokers', 'pilot', 'council', 'european', 'commission', 'intercultural', 'cities', 'language', 'processing', 'nlp', 'subfield', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', 'particular', 'program', 'process', 'analyze', 'amounts', 'natural', 'data', 'goal', 'capable', 'understanding', 'contents', 'documents', 'including', 'contextual', 'nuances', 'technology', 'accurately', 'extract', 'information', 'insights', 'contained', 'well', 'categorize', 'organize', 'challenges', 'frequently', 'involve', 'speech', 'recognition', 'mild', 'climate', 'northerly', 'latitude', 'resulting', 'moderate', 'summers', 'winters', 'often', 'remain', 'freezing', 'point', 'seaside', 'areas', 'high', 'elevation', 'though', 'microclimate', 'cold', 'snowy', 'functions', 'seat', 'county', 'mayor', 'trøndelag', 'administrative', 'steinkjer', 'make', 'efficient', 'centralized', 'third'])\n",
      "[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bow.most_common(10))\n",
    "print(bow.keys())\n",
    "print(tf_vec_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 2, 1, 4, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# calculate similarity\n",
    "# compare tf1, tf2 and tf3\n",
    "tokens1 = tokenText(sentence1)\n",
    "tokens2 = tokenText(sentence2)\n",
    "tokens3 = tokenText(sentence3)\n",
    "tf1 = genTfVec(bow,tokens1)\n",
    "tf2 = genTfVec(bow,tokens2)\n",
    "tf3 = genTfVec(bow,tokens3)\n",
    "print(tf1)\n",
    "print(tf2)\n",
    "print(tf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "d12 = sum(np.asarray(tf1)- np.asarray(tf2))\n",
    "print(d12)\n",
    "d13 = sum(np.asarray(tf1)- np.asarray(tf3))\n",
    "print(d13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
