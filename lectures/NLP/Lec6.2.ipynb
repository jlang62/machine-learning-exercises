{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# KUC, NLP\n",
    "# Lec6.2 Bow and tf-idf from scikit-learn\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "sentence1  = \"Oslo is the economic and governmental centre of Norway. The city is also a hub of Norwegian trade, banking, industry and shipping. It is an important centre for maritime industries and maritime trade in Europe. The city is home to many companies within the maritime sector, some of which are among the world's largest shipping companies, shipbrokers and maritime insurance brokers. Oslo is a pilot city of the Council of Europe and the European Commission intercultural cities programme.\"\n",
    "sentence2 = \"Natural language processing (NLP) is a subfield of \" \\\n",
    "            \"linguistics, computer science, and artificial intelligence \" \\\n",
    "            \"concerned with the interactions between computers and \" \\\n",
    "            \"human language, in particular how to program computers \" \\\n",
    "            \"to process and analyze large amounts of natural language data.\" \\\n",
    "            \" The goal is a computer capable of understanding the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves. Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.\"\n",
    "sentence3 = \"Trondheim has a very mild climate for its northerly latitude, resulting in moderate summers and winters that often remain above the freezing point in seaside areas. On higher elevation, though, the microclimate is colder and snowier. The city functions as the seat of the County Mayor of Trøndelag county, but not as the administrative centre, which is Steinkjer. This is to make the county more efficient and not too centralized, as Trøndelag is the third largest county in Norway.\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%# original content to handle with import numpy as np\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from  sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "corpus = [sentence1,sentence2,sentence3]\n",
    "cv_matrix = cv.fit_transform(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 97)\t2\n",
      "  (0, 70)\t5\n",
      "  (0, 122)\t7\n",
      "  (0, 39)\t1\n",
      "  (0, 8)\t5\n",
      "  (0, 51)\t1\n",
      "  (0, 21)\t2\n",
      "  (0, 93)\t5\n",
      "  (0, 89)\t1\n",
      "  (0, 24)\t3\n",
      "  (0, 3)\t1\n",
      "  (0, 56)\t1\n",
      "  (0, 90)\t1\n",
      "  (0, 131)\t2\n",
      "  (0, 13)\t1\n",
      "  (0, 62)\t1\n",
      "  (0, 113)\t2\n",
      "  (0, 71)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 58)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 80)\t4\n",
      "  (0, 61)\t1\n",
      "  (0, 59)\t1\n",
      "  (0, 42)\t2\n",
      "  :\t:\n",
      "  (2, 109)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 95)\t1\n",
      "  (2, 53)\t1\n",
      "  (2, 41)\t1\n",
      "  (2, 128)\t1\n",
      "  (2, 82)\t1\n",
      "  (2, 26)\t1\n",
      "  (2, 114)\t1\n",
      "  (2, 48)\t1\n",
      "  (2, 110)\t1\n",
      "  (2, 36)\t4\n",
      "  (2, 81)\t1\n",
      "  (2, 133)\t2\n",
      "  (2, 16)\t1\n",
      "  (2, 91)\t2\n",
      "  (2, 2)\t1\n",
      "  (2, 117)\t1\n",
      "  (2, 127)\t1\n",
      "  (2, 78)\t1\n",
      "  (2, 85)\t1\n",
      "  (2, 40)\t1\n",
      "  (2, 130)\t1\n",
      "  (2, 20)\t1\n",
      "  (2, 126)\t1\n"
     ]
    }
   ],
   "source": [
    "print(cv_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 1 0 1 0 5 1 0 0 0 1 0 1 0 0 0 0 0 2 0 1 3 0 0 1 2 0 0 0 0 0 0 1\n",
      "  0 0 0 1 0 0 2 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 5 1\n",
      "  0 0 0 1 0 0 0 1 4 0 0 0 0 0 0 0 0 1 1 0 0 5 0 0 0 2 0 1 0 0 0 0 1 0 0 0\n",
      "  0 0 0 1 1 2 0 1 0 0 0 0 0 0 7 0 0 0 0 0 0 1 0 2 0 0 0 0 0 1 0 0 1 1]\n",
      " [0 1 0 0 0 1 0 1 6 0 0 1 2 0 1 0 0 1 1 1 0 0 1 0 0 0 0 0 0 2 2 1 1 1 1 0\n",
      "  0 1 3 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 3 1 0 0 1 1 0 1 1 0 1 2 0\n",
      "  0 7 1 0 0 1 0 0 0 0 0 0 0 0 5 1 0 0 0 0 1 5 0 0 1 0 1 0 0 1 2 1 0 1 0 0\n",
      "  1 0 0 0 0 0 0 0 1 0 1 0 1 0 8 1 1 1 0 0 0 2 0 0 0 0 2 0 1 0 0 1 1 0]\n",
      " [1 0 1 0 0 0 0 0 3 0 1 0 3 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      "  4 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 4 0\n",
      "  1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 0 2 0 2 1 1 0 0 0 0 1 0 0 0 0 0 1 1\n",
      "  0 1 1 0 0 0 1 0 0 1 0 1 0 1 8 0 0 0 1 1 1 1 1 0 1 2 0 1 0 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv_array = cv_matrix.toarray()\n",
    "print(cv_array)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "vocab = cv.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['above' 'accurately' 'administrative' 'also' 'among' 'amounts' 'an'\n",
      " 'analyze' 'and' 'are' 'areas' 'artificial' 'as' 'banking' 'between'\n",
      " 'brokers' 'but' 'can' 'capable' 'categorize' 'centralized' 'centre'\n",
      " 'challenges' 'cities' 'city' 'climate' 'colder' 'commission' 'companies'\n",
      " 'computer' 'computers' 'concerned' 'contained' 'contents' 'contextual'\n",
      " 'council' 'county' 'data' 'documents' 'economic' 'efficient' 'elevation'\n",
      " 'europe' 'european' 'extract' 'for' 'freezing' 'frequently' 'functions'\n",
      " 'generation' 'goal' 'governmental' 'has' 'higher' 'home' 'how' 'hub'\n",
      " 'human' 'important' 'in' 'including' 'industries' 'industry'\n",
      " 'information' 'insights' 'insurance' 'intelligence' 'interactions'\n",
      " 'intercultural' 'involve' 'is' 'it' 'its' 'language' 'large' 'largest'\n",
      " 'latitude' 'linguistics' 'make' 'many' 'maritime' 'mayor' 'microclimate'\n",
      " 'mild' 'moderate' 'more' 'natural' 'nlp' 'northerly' 'norway' 'norwegian'\n",
      " 'not' 'nuances' 'of' 'often' 'on' 'organize' 'oslo' 'particular' 'pilot'\n",
      " 'point' 'process' 'processing' 'program' 'programme' 'recognition'\n",
      " 'remain' 'resulting' 'science' 'seaside' 'seat' 'sector' 'shipbrokers'\n",
      " 'shipping' 'snowier' 'some' 'speech' 'steinkjer' 'subfield' 'summers'\n",
      " 'technology' 'that' 'the' 'them' 'themselves' 'then' 'third' 'this'\n",
      " 'though' 'to' 'too' 'trade' 'trondheim' 'trøndelag' 'understanding'\n",
      " 'very' 'well' 'which' 'winters' 'with' 'within' 'world']\n",
      "142\n"
     ]
    }
   ],
   "source": [
    "# show document feature vectors\n",
    "print(vocab)\n",
    "print(len(vocab))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 81)\t0.12339474928852548\n",
      "  (0, 13)\t0.12339474928852548\n",
      "  (0, 54)\t0.12339474928852548\n",
      "  (0, 17)\t0.12339474928852548\n",
      "  (0, 33)\t0.12339474928852548\n",
      "  (0, 25)\t0.12339474928852548\n",
      "  (0, 76)\t0.12339474928852548\n",
      "  (0, 7)\t0.12339474928852548\n",
      "  (0, 51)\t0.12339474928852548\n",
      "  (0, 89)\t0.12339474928852548\n",
      "  (0, 58)\t0.09384488738951116\n",
      "  (0, 102)\t0.12339474928852548\n",
      "  (0, 88)\t0.12339474928852548\n",
      "  (0, 18)\t0.24678949857705096\n",
      "  (0, 42)\t0.12339474928852548\n",
      "  (0, 32)\t0.24678949857705096\n",
      "  (0, 47)\t0.12339474928852548\n",
      "  (0, 62)\t0.4935789971541019\n",
      "  (0, 45)\t0.12339474928852548\n",
      "  (0, 90)\t0.24678949857705096\n",
      "  (0, 48)\t0.12339474928852548\n",
      "  (0, 6)\t0.12339474928852548\n",
      "  (0, 97)\t0.24678949857705096\n",
      "  (0, 71)\t0.12339474928852548\n",
      "  (0, 43)\t0.12339474928852548\n",
      "  :\t:\n",
      "  (2, 87)\t0.14240218579485214\n",
      "  (2, 37)\t0.14240218579485214\n",
      "  (2, 91)\t0.14240218579485214\n",
      "  (2, 16)\t0.14240218579485214\n",
      "  (2, 64)\t0.14240218579485214\n",
      "  (2, 31)\t0.14240218579485214\n",
      "  (2, 41)\t0.14240218579485214\n",
      "  (2, 4)\t0.14240218579485214\n",
      "  (2, 86)\t0.14240218579485214\n",
      "  (2, 77)\t0.14240218579485214\n",
      "  (2, 35)\t0.14240218579485214\n",
      "  (2, 83)\t0.14240218579485214\n",
      "  (2, 101)\t0.14240218579485214\n",
      "  (2, 95)\t0.14240218579485214\n",
      "  (2, 66)\t0.14240218579485214\n",
      "  (2, 84)\t0.14240218579485214\n",
      "  (2, 59)\t0.14240218579485214\n",
      "  (2, 69)\t0.14240218579485214\n",
      "  (2, 15)\t0.14240218579485214\n",
      "  (2, 65)\t0.14240218579485214\n",
      "  (2, 98)\t0.14240218579485214\n",
      "  (2, 58)\t0.10830053277786303\n",
      "  (2, 14)\t0.10830053277786303\n",
      "  (2, 70)\t0.10830053277786303\n",
      "  (2, 11)\t0.10830053277786303\n"
     ]
    }
   ],
   "source": [
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "n_features = 100 # the size of vocabulary\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# print(corpus)\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "print(tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print(len(tfidf_feature_names))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "          0    1         2\n0  1.000000  0.0  0.071144\n1  0.000000  1.0  0.000000\n2  0.071144  0.0  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.071144</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.071144</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(tfidf)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "similarity_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1         2\n0  1.000000  0.517098  0.585919\n1  0.517098  1.000000  0.509274\n2  0.585919  0.509274  1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.517098</td>\n      <td>0.585919</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.517098</td>\n      <td>1.000000</td>\n      <td>0.509274</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.585919</td>\n      <td>0.509274</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = cosine_similarity(cv_array)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "similarity_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# discussion!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}