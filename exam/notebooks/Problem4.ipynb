{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 14:17:51.194026: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv('../data/deep_learning_task_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            5000 non-null   object \n",
      " 1   Item_Weight                4182 non-null   float64\n",
      " 2   Item_Fat_Content           5000 non-null   object \n",
      " 3   Item_Visibility            5000 non-null   float64\n",
      " 4   Item_Type                  5000 non-null   object \n",
      " 5   Item_MRP                   5000 non-null   float64\n",
      " 6   Outlet_Identifier          5000 non-null   object \n",
      " 7   Outlet_Establishment_Year  5000 non-null   int64  \n",
      " 8   Outlet_Size                3561 non-null   object \n",
      " 9   Outlet_Location_Type       5000 non-null   object \n",
      " 10  Outlet_Type                5000 non-null   object \n",
      " 11  Item_Outlet_Sales          5000 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                   818\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  1439\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/pk9yd5v978d_6j_wky4ptw480000gn/T/ipykernel_32867/889244835.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df.fillna(df.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# fill the missing values with the mean of the column\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df['Outlet_Size'].fillna(df['Outlet_Size'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    3044\n",
       "Small     1398\n",
       "High       558\n",
       "Name: Outlet_Size, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Outlet_Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat' 'Regular' 'low fat' 'LF' 'reg']\n",
      "['Dairy' 'Soft Drinks' 'Meat' 'Fruits and Vegetables' 'Household'\n",
      " 'Baking Goods' 'Snack Foods' 'Frozen Foods' 'Breakfast'\n",
      " 'Health and Hygiene' 'Hard Drinks' 'Canned' 'Breads' 'Starchy Foods'\n",
      " 'Others' 'Seafood']\n",
      "['Medium' 'High' 'Small']\n",
      "['Tier 1' 'Tier 3' 'Tier 2']\n",
      "['OUT049' 'OUT018' 'OUT010' 'OUT013' 'OUT027' 'OUT045' 'OUT017' 'OUT046'\n",
      " 'OUT035' 'OUT019']\n",
      "['Supermarket Type1' 'Supermarket Type2' 'Grocery Store'\n",
      " 'Supermarket Type3']\n"
     ]
    }
   ],
   "source": [
    "print(df['Item_Fat_Content'].unique())\n",
    "print(df['Item_Type'].unique())\n",
    "print(df['Outlet_Size'].unique())\n",
    "print(df['Outlet_Location_Type'].unique())\n",
    "print(df['Outlet_Identifier'].unique())\n",
    "print(df['Outlet_Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low Fat', 'Regular'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Item_Fat_Content'].replace(['low fat', 'LF', 'reg'], ['Low Fat', 'Low Fat', 'Regular'], inplace=True)\n",
    "df['Item_Fat_Content'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998      Medium               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df.drop(['Item_Identifier', 'Outlet_Establishment_Year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282525</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.048866</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>0.927507</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081274</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.058705</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>0.072068</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770765</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>Meat</td>\n",
       "      <td>0.468288</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.871986</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260494</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>0.095805</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight Item_Fat_Content  Item_Visibility              Item_Type  \\\n",
       "0     0.282525          Low Fat         0.048866                  Dairy   \n",
       "1     0.081274          Regular         0.058705            Soft Drinks   \n",
       "2     0.770765          Low Fat         0.051037                   Meat   \n",
       "3     0.871986          Regular         0.000000  Fruits and Vegetables   \n",
       "4     0.260494          Low Fat         0.000000              Household   \n",
       "\n",
       "   Item_MRP Outlet_Identifier Outlet_Size Outlet_Location_Type  \\\n",
       "0  0.927507            OUT049      Medium               Tier 1   \n",
       "1  0.072068            OUT018      Medium               Tier 3   \n",
       "2  0.468288            OUT049      Medium               Tier 1   \n",
       "3  0.640093            OUT010      Medium               Tier 3   \n",
       "4  0.095805            OUT013        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing the data Item_Weight, Item_Visibility, Item_MRP, Outlet_Establishment_Year\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_sub[['Item_Weight', 'Item_Visibility', 'Item_MRP']] = scaler.fit_transform(df_sub[['Item_Weight', 'Item_Visibility', 'Item_MRP']])\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Item_Fat_Content_Low Fat</th>\n",
       "      <th>Item_Fat_Content_Regular</th>\n",
       "      <th>Item_Type_Baking Goods</th>\n",
       "      <th>Item_Type_Breads</th>\n",
       "      <th>Item_Type_Breakfast</th>\n",
       "      <th>Item_Type_Canned</th>\n",
       "      <th>Item_Type_Dairy</th>\n",
       "      <th>...</th>\n",
       "      <th>Outlet_Size_High</th>\n",
       "      <th>Outlet_Size_Medium</th>\n",
       "      <th>Outlet_Size_Small</th>\n",
       "      <th>Outlet_Location_Type_Tier 1</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Supermarket Type2</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282525</td>\n",
       "      <td>0.048866</td>\n",
       "      <td>0.927507</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081274</td>\n",
       "      <td>0.058705</td>\n",
       "      <td>0.072068</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770765</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>0.468288</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.871986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Visibility  Item_MRP  Item_Fat_Content_Low Fat  \\\n",
       "0     0.282525         0.048866  0.927507                         1   \n",
       "1     0.081274         0.058705  0.072068                         0   \n",
       "2     0.770765         0.051037  0.468288                         1   \n",
       "3     0.871986         0.000000  0.640093                         0   \n",
       "4     0.260494         0.000000  0.095805                         1   \n",
       "\n",
       "   Item_Fat_Content_Regular  Item_Type_Baking Goods  Item_Type_Breads  \\\n",
       "0                         0                       0                 0   \n",
       "1                         1                       0                 0   \n",
       "2                         0                       0                 0   \n",
       "3                         1                       0                 0   \n",
       "4                         0                       0                 0   \n",
       "\n",
       "   Item_Type_Breakfast  Item_Type_Canned  Item_Type_Dairy  ...  \\\n",
       "0                    0                 0                1  ...   \n",
       "1                    0                 0                0  ...   \n",
       "2                    0                 0                0  ...   \n",
       "3                    0                 0                0  ...   \n",
       "4                    0                 0                0  ...   \n",
       "\n",
       "   Outlet_Size_High  Outlet_Size_Medium  Outlet_Size_Small  \\\n",
       "0                 0                   1                  0   \n",
       "1                 0                   1                  0   \n",
       "2                 0                   1                  0   \n",
       "3                 0                   1                  0   \n",
       "4                 1                   0                  0   \n",
       "\n",
       "   Outlet_Location_Type_Tier 1  Outlet_Location_Type_Tier 2  \\\n",
       "0                            1                            0   \n",
       "1                            0                            0   \n",
       "2                            1                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   Outlet_Location_Type_Tier 3  Outlet_Type_Grocery Store  \\\n",
       "0                            0                          0   \n",
       "1                            1                          0   \n",
       "2                            0                          0   \n",
       "3                            1                          1   \n",
       "4                            1                          0   \n",
       "\n",
       "   Outlet_Type_Supermarket Type1  Outlet_Type_Supermarket Type2  \\\n",
       "0                              1                              0   \n",
       "1                              0                              1   \n",
       "2                              1                              0   \n",
       "3                              0                              0   \n",
       "4                              1                              0   \n",
       "\n",
       "   Outlet_Type_Supermarket Type3  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(df_sub.drop(['Item_Outlet_Sales'], axis=1))\n",
    "y = df_sub['Item_Outlet_Sales']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 41), (5000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((4000, 41), (4000,)), ((1000, 41), (1000,)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation set\n",
    "\n",
    "# stratify will make sure that the distribution of classes in train and validation set it similar\n",
    "# random state to regenerate the same train and validation set\n",
    "# test size 0.2 will keep 20% data in validation and remaining 80% in train set\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "\n",
    "# shape of training and validation set\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the sequential model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# importing different layers from keras\n",
    "from keras.layers import InputLayer, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 41)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of input neurons\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features in the data\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining input neurons\n",
    "input_neurons = X_train.shape[1]\n",
    "input_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of output neurons\n",
    "output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hidden layers and neuron in each layer\n",
    "number_of_hidden_layers = 2\n",
    "neuron_hidden_layer_1 = 80\n",
    "neuron_hidden_layer_2 = 40\n",
    "neuron_hidden_layer_3 = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 80)                3360      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 40)                3240      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6641 (25.94 KB)\n",
      "Trainable params: 6641 (25.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "# defining the architecture of the model\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=(input_neurons)))\n",
    "model.add(Dense(units=neuron_hidden_layer_1, activation='relu'))\n",
    "model.add(Dense(units=neuron_hidden_layer_2, activation='relu'))\n",
    "model.add(Dense(units=output_neurons, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001), metrics=['mae'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 7589023.0000 - mae: 2165.8428 - val_loss: 7033859.0000 - val_mae: 2039.5002\n",
      "Epoch 2/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 5767811.0000 - mae: 1764.2582 - val_loss: 3895948.5000 - val_mae: 1375.3796\n",
      "Epoch 3/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2892447.7500 - mae: 1245.1089 - val_loss: 2420417.2500 - val_mae: 1209.7882\n",
      "Epoch 4/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2333993.7500 - mae: 1198.0708 - val_loss: 2277494.7500 - val_mae: 1184.2209\n",
      "Epoch 5/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 2201794.7500 - mae: 1163.9147 - val_loss: 2155765.0000 - val_mae: 1138.2241\n",
      "Epoch 6/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2093280.1250 - mae: 1121.0005 - val_loss: 2053278.2500 - val_mae: 1096.6877\n",
      "Epoch 7/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2004180.6250 - mae: 1087.3689 - val_loss: 1964113.5000 - val_mae: 1065.9042\n",
      "Epoch 8/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1927924.2500 - mae: 1055.6699 - val_loss: 1885245.7500 - val_mae: 1036.4149\n",
      "Epoch 9/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1861478.3750 - mae: 1028.6195 - val_loss: 1816895.0000 - val_mae: 1008.8487\n",
      "Epoch 10/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1802887.7500 - mae: 1009.0413 - val_loss: 1751326.7500 - val_mae: 985.0645\n",
      "Epoch 11/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1750646.8750 - mae: 991.1874 - val_loss: 1693028.8750 - val_mae: 965.7078\n",
      "Epoch 12/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1701950.7500 - mae: 975.1858 - val_loss: 1638040.7500 - val_mae: 949.3527\n",
      "Epoch 13/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1654043.8750 - mae: 959.6357 - val_loss: 1586337.1250 - val_mae: 937.0769\n",
      "Epoch 14/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1604946.7500 - mae: 944.8411 - val_loss: 1537642.2500 - val_mae: 921.1371\n",
      "Epoch 15/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1558914.2500 - mae: 932.2849 - val_loss: 1486076.5000 - val_mae: 896.9852\n",
      "Epoch 16/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1511624.1250 - mae: 914.4563 - val_loss: 1438910.3750 - val_mae: 884.5989\n",
      "Epoch 17/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1466549.1250 - mae: 900.3774 - val_loss: 1396555.5000 - val_mae: 863.7079\n",
      "Epoch 18/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1423167.1250 - mae: 883.7247 - val_loss: 1351036.2500 - val_mae: 847.9511\n",
      "Epoch 19/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1381606.0000 - mae: 866.9825 - val_loss: 1313500.0000 - val_mae: 840.0882\n",
      "Epoch 20/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1345878.5000 - mae: 853.9739 - val_loss: 1277509.0000 - val_mae: 822.2827\n",
      "Epoch 21/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1313538.0000 - mae: 840.6450 - val_loss: 1251318.5000 - val_mae: 807.5730\n",
      "Epoch 22/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1286815.3750 - mae: 827.9631 - val_loss: 1227019.3750 - val_mae: 797.9193\n",
      "Epoch 23/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1264823.8750 - mae: 820.2327 - val_loss: 1212111.1250 - val_mae: 787.3635\n",
      "Epoch 24/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1246077.5000 - mae: 810.3552 - val_loss: 1202028.3750 - val_mae: 781.1625\n",
      "Epoch 25/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1231656.6250 - mae: 804.2477 - val_loss: 1192683.8750 - val_mae: 776.0919\n",
      "Epoch 26/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1223770.6250 - mae: 798.8656 - val_loss: 1177941.2500 - val_mae: 776.0647\n",
      "Epoch 27/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1215389.1250 - mae: 794.4537 - val_loss: 1173926.0000 - val_mae: 771.8520\n",
      "Epoch 28/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1210083.3750 - mae: 792.2434 - val_loss: 1171293.5000 - val_mae: 769.8160\n",
      "Epoch 29/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1205833.5000 - mae: 789.6919 - val_loss: 1165790.1250 - val_mae: 769.8416\n",
      "Epoch 30/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1204646.6250 - mae: 788.3576 - val_loss: 1165288.2500 - val_mae: 769.7209\n",
      "Epoch 31/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1200866.3750 - mae: 787.5258 - val_loss: 1168936.5000 - val_mae: 767.3301\n",
      "Epoch 32/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1199049.3750 - mae: 786.0392 - val_loss: 1163021.2500 - val_mae: 768.4973\n",
      "Epoch 33/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1197371.6250 - mae: 785.2178 - val_loss: 1161897.1250 - val_mae: 769.2289\n",
      "Epoch 34/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1198926.6250 - mae: 785.5906 - val_loss: 1163387.6250 - val_mae: 768.4642\n",
      "Epoch 35/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195328.3750 - mae: 784.5359 - val_loss: 1165875.5000 - val_mae: 766.4393\n",
      "Epoch 36/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194077.1250 - mae: 783.4202 - val_loss: 1164244.6250 - val_mae: 766.5494\n",
      "Epoch 37/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1193461.2500 - mae: 782.3966 - val_loss: 1166250.6250 - val_mae: 766.4315\n",
      "Epoch 38/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194644.6250 - mae: 782.0989 - val_loss: 1162097.5000 - val_mae: 766.3233\n",
      "Epoch 39/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1192528.3750 - mae: 781.4503 - val_loss: 1161968.6250 - val_mae: 766.7397\n",
      "Epoch 40/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1192103.8750 - mae: 781.2023 - val_loss: 1162034.5000 - val_mae: 765.6973\n",
      "Epoch 41/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1189324.7500 - mae: 779.5843 - val_loss: 1165933.1250 - val_mae: 764.7983\n",
      "Epoch 42/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1191137.2500 - mae: 779.5279 - val_loss: 1161281.8750 - val_mae: 765.0524\n",
      "Epoch 43/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1188901.1250 - mae: 778.0883 - val_loss: 1159160.7500 - val_mae: 769.2836\n",
      "Epoch 44/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1190309.3750 - mae: 779.5616 - val_loss: 1167344.0000 - val_mae: 764.1613\n",
      "Epoch 45/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1190351.0000 - mae: 778.1630 - val_loss: 1158742.7500 - val_mae: 764.6416\n",
      "Epoch 46/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1189211.1250 - mae: 778.6912 - val_loss: 1158689.7500 - val_mae: 765.8523\n",
      "Epoch 47/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1190801.2500 - mae: 778.5614 - val_loss: 1158276.0000 - val_mae: 765.3484\n",
      "Epoch 48/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1188254.8750 - mae: 776.9967 - val_loss: 1155326.0000 - val_mae: 765.6580\n",
      "Epoch 49/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187012.3750 - mae: 776.9227 - val_loss: 1156653.0000 - val_mae: 763.6807\n",
      "Epoch 50/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1185747.3750 - mae: 777.0276 - val_loss: 1160068.8750 - val_mae: 763.1196\n",
      "Epoch 51/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1186227.2500 - mae: 775.6526 - val_loss: 1161266.8750 - val_mae: 763.4119\n",
      "Epoch 52/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1186093.7500 - mae: 776.2709 - val_loss: 1157517.7500 - val_mae: 764.6558\n",
      "Epoch 53/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1183956.3750 - mae: 775.7335 - val_loss: 1163200.3750 - val_mae: 761.7252\n",
      "Epoch 54/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1184163.2500 - mae: 774.6703 - val_loss: 1156622.2500 - val_mae: 763.3882\n",
      "Epoch 55/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1183383.7500 - mae: 774.2350 - val_loss: 1155934.7500 - val_mae: 765.9668\n",
      "Epoch 56/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1184915.6250 - mae: 774.6910 - val_loss: 1155089.5000 - val_mae: 762.8921\n",
      "Epoch 57/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1182129.8750 - mae: 773.9691 - val_loss: 1154712.7500 - val_mae: 762.3596\n",
      "Epoch 58/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1182395.0000 - mae: 773.0852 - val_loss: 1154907.5000 - val_mae: 764.0297\n",
      "Epoch 59/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1182785.8750 - mae: 773.6234 - val_loss: 1155289.5000 - val_mae: 761.9308\n",
      "Epoch 60/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1180517.5000 - mae: 773.3085 - val_loss: 1157204.2500 - val_mae: 760.6877\n",
      "Epoch 61/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1180713.7500 - mae: 772.3081 - val_loss: 1160590.7500 - val_mae: 760.5267\n",
      "Epoch 62/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1180045.5000 - mae: 772.9378 - val_loss: 1159963.1250 - val_mae: 760.0684\n",
      "Epoch 63/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1181092.6250 - mae: 772.3694 - val_loss: 1152408.3750 - val_mae: 761.1349\n",
      "Epoch 64/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1178217.2500 - mae: 770.5062 - val_loss: 1152057.8750 - val_mae: 763.9462\n",
      "Epoch 65/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1178820.7500 - mae: 770.7404 - val_loss: 1151783.7500 - val_mae: 763.0444\n",
      "Epoch 66/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1178460.1250 - mae: 771.0580 - val_loss: 1152243.3750 - val_mae: 762.9758\n",
      "Epoch 67/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1177093.8750 - mae: 771.1983 - val_loss: 1150402.2500 - val_mae: 760.9395\n",
      "Epoch 68/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1176766.7500 - mae: 770.5162 - val_loss: 1153077.1250 - val_mae: 759.9285\n",
      "Epoch 69/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1177823.6250 - mae: 770.5646 - val_loss: 1149571.0000 - val_mae: 761.6396\n",
      "Epoch 70/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1173925.6250 - mae: 768.6340 - val_loss: 1152369.7500 - val_mae: 765.2124\n",
      "Epoch 71/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1176023.3750 - mae: 770.2191 - val_loss: 1150225.8750 - val_mae: 762.2505\n",
      "Epoch 72/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1174917.2500 - mae: 769.8856 - val_loss: 1154234.2500 - val_mae: 764.7036\n",
      "Epoch 73/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1174548.5000 - mae: 768.4611 - val_loss: 1149893.8750 - val_mae: 761.2585\n",
      "Epoch 74/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1172675.5000 - mae: 769.1940 - val_loss: 1151428.1250 - val_mae: 763.3285\n",
      "Epoch 75/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1173400.3750 - mae: 767.7137 - val_loss: 1150590.2500 - val_mae: 762.9420\n",
      "Epoch 76/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1172203.3750 - mae: 767.9259 - val_loss: 1150570.5000 - val_mae: 762.3785\n",
      "Epoch 77/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1172756.7500 - mae: 768.6976 - val_loss: 1154340.5000 - val_mae: 758.3793\n",
      "Epoch 78/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1172420.6250 - mae: 766.6192 - val_loss: 1149233.3750 - val_mae: 760.0208\n",
      "Epoch 79/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1172595.5000 - mae: 768.5194 - val_loss: 1151103.7500 - val_mae: 759.6679\n",
      "Epoch 80/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171110.6250 - mae: 767.7490 - val_loss: 1147797.8750 - val_mae: 760.3799\n",
      "Epoch 81/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1170909.6250 - mae: 768.0070 - val_loss: 1157207.1250 - val_mae: 758.1109\n",
      "Epoch 82/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1170399.7500 - mae: 767.0444 - val_loss: 1149443.3750 - val_mae: 759.0615\n",
      "Epoch 83/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1170028.6250 - mae: 766.4105 - val_loss: 1149660.5000 - val_mae: 759.6340\n",
      "Epoch 84/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1170962.8750 - mae: 767.1642 - val_loss: 1150779.7500 - val_mae: 763.0798\n",
      "Epoch 85/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171135.5000 - mae: 767.5238 - val_loss: 1149029.0000 - val_mae: 759.4111\n",
      "Epoch 86/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168499.6250 - mae: 765.4989 - val_loss: 1148792.7500 - val_mae: 759.6944\n",
      "Epoch 87/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168288.8750 - mae: 765.6798 - val_loss: 1149733.0000 - val_mae: 758.2147\n",
      "Epoch 88/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1167333.6250 - mae: 765.8206 - val_loss: 1153512.7500 - val_mae: 766.6068\n",
      "Epoch 89/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168659.2500 - mae: 766.8494 - val_loss: 1148493.2500 - val_mae: 758.1069\n",
      "Epoch 90/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168124.0000 - mae: 765.6324 - val_loss: 1148918.1250 - val_mae: 758.2438\n",
      "Epoch 91/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1166921.6250 - mae: 764.3057 - val_loss: 1147951.6250 - val_mae: 760.7645\n",
      "Epoch 92/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1165830.8750 - mae: 765.1646 - val_loss: 1151583.6250 - val_mae: 757.4784\n",
      "Epoch 93/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1166861.1250 - mae: 764.2176 - val_loss: 1148181.7500 - val_mae: 760.6030\n",
      "Epoch 94/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1169300.5000 - mae: 766.2557 - val_loss: 1148233.0000 - val_mae: 760.6202\n",
      "Epoch 95/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164749.6250 - mae: 764.1870 - val_loss: 1149138.3750 - val_mae: 757.1182\n",
      "Epoch 96/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1166126.7500 - mae: 763.6689 - val_loss: 1149274.6250 - val_mae: 758.2865\n",
      "Epoch 97/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163660.1250 - mae: 763.7103 - val_loss: 1150050.7500 - val_mae: 758.2161\n",
      "Epoch 98/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1167024.1250 - mae: 764.8838 - val_loss: 1154769.5000 - val_mae: 756.9861\n",
      "Epoch 99/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163192.8750 - mae: 763.0144 - val_loss: 1151709.8750 - val_mae: 756.0831\n",
      "Epoch 100/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1165024.1250 - mae: 762.5807 - val_loss: 1147964.5000 - val_mae: 757.1246\n",
      "Epoch 101/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164307.2500 - mae: 762.5937 - val_loss: 1145616.3750 - val_mae: 757.3481\n",
      "Epoch 102/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160864.2500 - mae: 763.0404 - val_loss: 1150663.0000 - val_mae: 756.0558\n",
      "Epoch 103/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1161927.1250 - mae: 761.2325 - val_loss: 1149432.6250 - val_mae: 761.8323\n",
      "Epoch 104/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163393.6250 - mae: 762.4933 - val_loss: 1151921.1250 - val_mae: 764.2850\n",
      "Epoch 105/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1162777.6250 - mae: 763.2176 - val_loss: 1145773.5000 - val_mae: 758.3508\n",
      "Epoch 106/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163346.5000 - mae: 762.8444 - val_loss: 1148007.3750 - val_mae: 755.6445\n",
      "Epoch 107/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163070.6250 - mae: 762.3916 - val_loss: 1149195.1250 - val_mae: 756.4607\n",
      "Epoch 108/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1162403.3750 - mae: 762.4192 - val_loss: 1149777.6250 - val_mae: 756.0020\n",
      "Epoch 109/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160628.6250 - mae: 760.6669 - val_loss: 1145072.6250 - val_mae: 757.4733\n",
      "Epoch 110/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159518.0000 - mae: 761.1475 - val_loss: 1146696.7500 - val_mae: 756.2689\n",
      "Epoch 111/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160304.7500 - mae: 759.9445 - val_loss: 1148234.8750 - val_mae: 760.2939\n",
      "Epoch 112/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159142.7500 - mae: 760.6932 - val_loss: 1146602.0000 - val_mae: 758.8073\n",
      "Epoch 113/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159169.6250 - mae: 760.4872 - val_loss: 1146526.5000 - val_mae: 758.3967\n",
      "Epoch 114/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159260.1250 - mae: 760.3729 - val_loss: 1144494.3750 - val_mae: 756.4020\n",
      "Epoch 115/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1158998.6250 - mae: 760.1138 - val_loss: 1146774.8750 - val_mae: 756.8696\n",
      "Epoch 116/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160261.7500 - mae: 761.4029 - val_loss: 1147409.1250 - val_mae: 759.8176\n",
      "Epoch 117/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155882.2500 - mae: 758.5299 - val_loss: 1150673.1250 - val_mae: 763.2223\n",
      "Epoch 118/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159768.6250 - mae: 760.8964 - val_loss: 1146434.8750 - val_mae: 758.2130\n",
      "Epoch 119/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156500.7500 - mae: 759.3713 - val_loss: 1147606.7500 - val_mae: 753.8093\n",
      "Epoch 120/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1158038.6250 - mae: 759.1840 - val_loss: 1143787.7500 - val_mae: 755.2959\n",
      "Epoch 121/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156508.1250 - mae: 759.2462 - val_loss: 1144298.1250 - val_mae: 756.6553\n",
      "Epoch 122/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156736.1250 - mae: 759.8660 - val_loss: 1151165.8750 - val_mae: 753.5259\n",
      "Epoch 123/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157288.6250 - mae: 758.4863 - val_loss: 1145108.6250 - val_mae: 755.9019\n",
      "Epoch 124/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155704.1250 - mae: 758.8297 - val_loss: 1145440.5000 - val_mae: 754.5651\n",
      "Epoch 125/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155784.3750 - mae: 758.1752 - val_loss: 1143712.8750 - val_mae: 756.0205\n",
      "Epoch 126/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156222.0000 - mae: 759.1432 - val_loss: 1145935.5000 - val_mae: 756.5936\n",
      "Epoch 127/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1154307.6250 - mae: 758.2162 - val_loss: 1145931.1250 - val_mae: 754.0685\n",
      "Epoch 128/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153368.7500 - mae: 756.9398 - val_loss: 1144783.3750 - val_mae: 758.0062\n",
      "Epoch 129/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1154532.8750 - mae: 759.3583 - val_loss: 1151191.7500 - val_mae: 753.0987\n",
      "Epoch 130/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1154927.6250 - mae: 756.7049 - val_loss: 1141302.8750 - val_mae: 755.3840\n",
      "Epoch 131/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153364.2500 - mae: 758.1707 - val_loss: 1147304.2500 - val_mae: 753.4035\n",
      "Epoch 132/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153559.3750 - mae: 756.6483 - val_loss: 1142577.0000 - val_mae: 755.3550\n",
      "Epoch 133/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152863.6250 - mae: 757.4063 - val_loss: 1144848.8750 - val_mae: 756.8206\n",
      "Epoch 134/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153453.1250 - mae: 758.0666 - val_loss: 1144261.5000 - val_mae: 753.8578\n",
      "Epoch 135/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1150819.5000 - mae: 756.6820 - val_loss: 1144627.0000 - val_mae: 758.0907\n",
      "Epoch 136/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152802.2500 - mae: 757.0621 - val_loss: 1144849.6250 - val_mae: 753.5427\n",
      "Epoch 137/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152007.8750 - mae: 756.3654 - val_loss: 1145316.0000 - val_mae: 753.2397\n",
      "Epoch 138/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151869.8750 - mae: 756.0709 - val_loss: 1144154.3750 - val_mae: 753.8174\n",
      "Epoch 139/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151048.8750 - mae: 756.6215 - val_loss: 1146600.8750 - val_mae: 752.4166\n",
      "Epoch 140/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152469.3750 - mae: 757.3214 - val_loss: 1142485.0000 - val_mae: 752.7952\n",
      "Epoch 141/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151598.0000 - mae: 755.3576 - val_loss: 1142486.3750 - val_mae: 755.8488\n",
      "Epoch 142/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1150503.5000 - mae: 756.7771 - val_loss: 1145455.5000 - val_mae: 753.6676\n",
      "Epoch 143/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149600.5000 - mae: 755.2116 - val_loss: 1145256.8750 - val_mae: 758.6061\n",
      "Epoch 144/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1150182.5000 - mae: 755.4216 - val_loss: 1144773.2500 - val_mae: 753.3417\n",
      "Epoch 145/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149136.7500 - mae: 755.0872 - val_loss: 1142834.0000 - val_mae: 754.6832\n",
      "Epoch 146/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149170.1250 - mae: 756.3620 - val_loss: 1142785.2500 - val_mae: 752.6741\n",
      "Epoch 147/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1148451.1250 - mae: 754.1766 - val_loss: 1145474.1250 - val_mae: 752.5992\n",
      "Epoch 148/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149854.8750 - mae: 755.0605 - val_loss: 1144403.0000 - val_mae: 756.0123\n",
      "Epoch 149/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149356.0000 - mae: 756.0577 - val_loss: 1142910.0000 - val_mae: 753.5483\n",
      "Epoch 150/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147925.7500 - mae: 754.4566 - val_loss: 1146201.7500 - val_mae: 752.0688\n",
      "Epoch 151/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148249.6250 - mae: 754.6215 - val_loss: 1143355.7500 - val_mae: 753.5491\n",
      "Epoch 152/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147712.6250 - mae: 754.7177 - val_loss: 1143905.0000 - val_mae: 753.7424\n",
      "Epoch 153/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147267.1250 - mae: 754.9597 - val_loss: 1143024.0000 - val_mae: 757.0626\n",
      "Epoch 154/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146438.2500 - mae: 755.2964 - val_loss: 1147001.1250 - val_mae: 751.9124\n",
      "Epoch 155/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147496.1250 - mae: 754.2596 - val_loss: 1142655.6250 - val_mae: 755.3798\n",
      "Epoch 156/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147604.6250 - mae: 756.0294 - val_loss: 1142004.1250 - val_mae: 756.8683\n",
      "Epoch 157/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149484.5000 - mae: 755.2571 - val_loss: 1141090.8750 - val_mae: 755.2960\n",
      "Epoch 158/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145528.3750 - mae: 753.4894 - val_loss: 1143629.5000 - val_mae: 754.4225\n",
      "Epoch 159/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147833.3750 - mae: 755.5671 - val_loss: 1143188.2500 - val_mae: 756.8777\n",
      "Epoch 160/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146007.6250 - mae: 753.6362 - val_loss: 1142635.2500 - val_mae: 757.6857\n",
      "Epoch 161/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147269.0000 - mae: 754.9972 - val_loss: 1141888.2500 - val_mae: 753.7472\n",
      "Epoch 162/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146398.2500 - mae: 755.0643 - val_loss: 1143771.0000 - val_mae: 753.2004\n",
      "Epoch 163/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144362.8750 - mae: 752.9657 - val_loss: 1142411.7500 - val_mae: 755.5463\n",
      "Epoch 164/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144388.2500 - mae: 754.0893 - val_loss: 1145949.7500 - val_mae: 753.9386\n",
      "Epoch 165/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144504.3750 - mae: 753.5515 - val_loss: 1145812.6250 - val_mae: 753.2711\n",
      "Epoch 166/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145965.7500 - mae: 754.0923 - val_loss: 1142319.0000 - val_mae: 755.0005\n",
      "Epoch 167/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144052.6250 - mae: 754.1885 - val_loss: 1144716.7500 - val_mae: 759.5103\n",
      "Epoch 168/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144487.7500 - mae: 753.6866 - val_loss: 1142712.2500 - val_mae: 757.1320\n",
      "Epoch 169/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144330.6250 - mae: 754.9564 - val_loss: 1145968.8750 - val_mae: 752.7255\n",
      "Epoch 170/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141894.3750 - mae: 753.3372 - val_loss: 1153396.0000 - val_mae: 752.2252\n",
      "Epoch 171/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145142.5000 - mae: 752.6534 - val_loss: 1141038.8750 - val_mae: 754.8895\n",
      "Epoch 172/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140778.2500 - mae: 752.5989 - val_loss: 1144432.0000 - val_mae: 758.9927\n",
      "Epoch 173/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1142839.0000 - mae: 752.9973 - val_loss: 1140054.7500 - val_mae: 754.7772\n",
      "Epoch 174/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144247.1250 - mae: 754.3022 - val_loss: 1142975.8750 - val_mae: 752.2701\n",
      "Epoch 175/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144106.0000 - mae: 754.2985 - val_loss: 1143029.6250 - val_mae: 753.8979\n",
      "Epoch 176/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141540.7500 - mae: 752.2599 - val_loss: 1141708.5000 - val_mae: 753.7571\n",
      "Epoch 177/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141996.5000 - mae: 752.9475 - val_loss: 1143354.0000 - val_mae: 756.6122\n",
      "Epoch 178/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1142087.5000 - mae: 752.9607 - val_loss: 1144081.7500 - val_mae: 753.7562\n",
      "Epoch 179/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141966.7500 - mae: 753.5608 - val_loss: 1142441.0000 - val_mae: 754.0139\n",
      "Epoch 180/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140769.2500 - mae: 751.6909 - val_loss: 1149222.8750 - val_mae: 762.9525\n",
      "Epoch 181/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140949.8750 - mae: 753.2735 - val_loss: 1139847.0000 - val_mae: 755.2647\n",
      "Epoch 182/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141118.2500 - mae: 752.6722 - val_loss: 1140082.5000 - val_mae: 755.3698\n",
      "Epoch 183/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140742.2500 - mae: 752.8237 - val_loss: 1141726.8750 - val_mae: 755.7574\n",
      "Epoch 184/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140593.0000 - mae: 752.6384 - val_loss: 1142420.2500 - val_mae: 753.9506\n",
      "Epoch 185/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140456.6250 - mae: 752.4467 - val_loss: 1143070.3750 - val_mae: 753.9344\n",
      "Epoch 186/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140680.1250 - mae: 752.1025 - val_loss: 1143232.5000 - val_mae: 755.1272\n",
      "Epoch 187/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1144686.1250 - mae: 754.8196 - val_loss: 1144465.2500 - val_mae: 755.2474\n",
      "Epoch 188/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139210.2500 - mae: 750.8948 - val_loss: 1141803.1250 - val_mae: 756.0635\n",
      "Epoch 189/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139690.3750 - mae: 752.8399 - val_loss: 1143632.6250 - val_mae: 753.5463\n",
      "Epoch 190/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140431.3750 - mae: 751.3104 - val_loss: 1142723.6250 - val_mae: 754.6305\n",
      "Epoch 191/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140735.8750 - mae: 752.0361 - val_loss: 1143056.6250 - val_mae: 756.4026\n",
      "Epoch 192/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139016.1250 - mae: 752.0667 - val_loss: 1142831.2500 - val_mae: 755.4428\n",
      "Epoch 193/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139772.6250 - mae: 752.9025 - val_loss: 1150871.3750 - val_mae: 753.3394\n",
      "Epoch 194/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138410.3750 - mae: 751.1752 - val_loss: 1144564.1250 - val_mae: 754.3764\n",
      "Epoch 195/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138346.5000 - mae: 750.8754 - val_loss: 1144136.1250 - val_mae: 758.0952\n",
      "Epoch 196/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139282.3750 - mae: 753.6629 - val_loss: 1143883.5000 - val_mae: 755.3140\n",
      "Epoch 197/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139607.0000 - mae: 752.1778 - val_loss: 1143162.3750 - val_mae: 753.8630\n",
      "Epoch 198/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139016.7500 - mae: 751.4865 - val_loss: 1144219.5000 - val_mae: 753.6978\n",
      "Epoch 199/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137835.1250 - mae: 752.3015 - val_loss: 1150020.3750 - val_mae: 753.3361\n",
      "Epoch 200/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139124.0000 - mae: 751.1073 - val_loss: 1141889.2500 - val_mae: 755.4301\n",
      "Epoch 201/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137331.8750 - mae: 751.8074 - val_loss: 1141013.1250 - val_mae: 754.1702\n",
      "Epoch 202/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136978.2500 - mae: 750.9448 - val_loss: 1142495.7500 - val_mae: 756.1232\n",
      "Epoch 203/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139450.3750 - mae: 753.1599 - val_loss: 1143530.2500 - val_mae: 757.3406\n",
      "Epoch 204/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136585.0000 - mae: 750.7292 - val_loss: 1144054.2500 - val_mae: 757.1169\n",
      "Epoch 205/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137780.3750 - mae: 751.6561 - val_loss: 1142456.7500 - val_mae: 754.6297\n",
      "Epoch 206/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137339.0000 - mae: 751.0052 - val_loss: 1148853.5000 - val_mae: 753.8271\n",
      "Epoch 207/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136563.8750 - mae: 750.8598 - val_loss: 1143447.3750 - val_mae: 754.3737\n",
      "Epoch 208/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137308.5000 - mae: 750.2306 - val_loss: 1142567.7500 - val_mae: 756.9297\n",
      "Epoch 209/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135914.7500 - mae: 751.7018 - val_loss: 1143892.2500 - val_mae: 754.9974\n",
      "Epoch 210/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137457.0000 - mae: 751.4747 - val_loss: 1141889.3750 - val_mae: 755.3513\n",
      "Epoch 211/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135479.1250 - mae: 749.6957 - val_loss: 1144742.5000 - val_mae: 758.3019\n",
      "Epoch 212/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135201.8750 - mae: 751.7007 - val_loss: 1144191.8750 - val_mae: 758.8796\n",
      "Epoch 213/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134904.5000 - mae: 750.8806 - val_loss: 1144402.3750 - val_mae: 758.1205\n",
      "Epoch 214/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134603.5000 - mae: 751.2043 - val_loss: 1143899.5000 - val_mae: 754.0024\n",
      "Epoch 215/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1134860.7500 - mae: 749.7916 - val_loss: 1145693.8750 - val_mae: 758.4086\n",
      "Epoch 216/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134721.2500 - mae: 751.2089 - val_loss: 1148507.1250 - val_mae: 753.7263\n",
      "Epoch 217/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135813.1250 - mae: 750.2164 - val_loss: 1142310.8750 - val_mae: 755.4222\n",
      "Epoch 218/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137219.6250 - mae: 751.7908 - val_loss: 1150017.6250 - val_mae: 753.6086\n",
      "Epoch 219/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134880.7500 - mae: 750.0566 - val_loss: 1142391.7500 - val_mae: 754.7196\n",
      "Epoch 220/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134665.1250 - mae: 750.2761 - val_loss: 1144309.2500 - val_mae: 755.0402\n",
      "Epoch 221/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135064.1250 - mae: 750.8378 - val_loss: 1146250.3750 - val_mae: 754.5489\n",
      "Epoch 222/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135019.5000 - mae: 749.8141 - val_loss: 1148657.8750 - val_mae: 754.2490\n",
      "Epoch 223/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133977.2500 - mae: 749.9785 - val_loss: 1145059.6250 - val_mae: 755.3038\n",
      "Epoch 224/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134810.1250 - mae: 750.4064 - val_loss: 1144452.7500 - val_mae: 755.0090\n",
      "Epoch 225/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135357.8750 - mae: 751.0369 - val_loss: 1142516.6250 - val_mae: 756.5226\n",
      "Epoch 226/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135257.7500 - mae: 750.7740 - val_loss: 1148392.7500 - val_mae: 754.0417\n",
      "Epoch 227/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136633.8750 - mae: 750.2787 - val_loss: 1144059.1250 - val_mae: 754.8948\n",
      "Epoch 228/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134679.6250 - mae: 750.8658 - val_loss: 1144698.6250 - val_mae: 756.8300\n",
      "Epoch 229/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135541.5000 - mae: 751.3587 - val_loss: 1143097.0000 - val_mae: 756.2352\n",
      "Epoch 230/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134221.7500 - mae: 749.5620 - val_loss: 1145868.5000 - val_mae: 754.2817\n",
      "Epoch 231/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131405.7500 - mae: 749.6756 - val_loss: 1145496.1250 - val_mae: 754.8814\n",
      "Epoch 232/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132819.5000 - mae: 749.2498 - val_loss: 1152706.0000 - val_mae: 765.0221\n",
      "Epoch 233/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136926.1250 - mae: 751.1932 - val_loss: 1145459.3750 - val_mae: 755.1142\n",
      "Epoch 234/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133537.0000 - mae: 750.1358 - val_loss: 1152605.6250 - val_mae: 755.3629\n",
      "Epoch 235/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133650.1250 - mae: 749.6335 - val_loss: 1145145.5000 - val_mae: 754.9130\n",
      "Epoch 236/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132524.2500 - mae: 750.0575 - val_loss: 1144358.0000 - val_mae: 754.8922\n",
      "Epoch 237/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132510.3750 - mae: 748.8027 - val_loss: 1143894.1250 - val_mae: 755.5867\n",
      "Epoch 238/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132565.3750 - mae: 750.1858 - val_loss: 1143855.8750 - val_mae: 756.1635\n",
      "Epoch 239/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133883.5000 - mae: 750.8236 - val_loss: 1143410.7500 - val_mae: 754.6713\n",
      "Epoch 240/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133494.6250 - mae: 750.5443 - val_loss: 1142604.3750 - val_mae: 756.4269\n",
      "Epoch 241/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131814.3750 - mae: 749.7136 - val_loss: 1143064.8750 - val_mae: 755.2035\n",
      "Epoch 242/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131333.0000 - mae: 750.2987 - val_loss: 1146432.8750 - val_mae: 754.3016\n",
      "Epoch 243/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131615.2500 - mae: 749.5166 - val_loss: 1144905.8750 - val_mae: 755.0306\n",
      "Epoch 244/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130769.5000 - mae: 748.8245 - val_loss: 1144038.2500 - val_mae: 757.2890\n",
      "Epoch 245/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130325.7500 - mae: 748.6600 - val_loss: 1143945.6250 - val_mae: 758.5126\n",
      "Epoch 246/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133052.8750 - mae: 749.8544 - val_loss: 1143079.5000 - val_mae: 756.0624\n",
      "Epoch 247/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130788.5000 - mae: 749.4617 - val_loss: 1142084.8750 - val_mae: 755.1727\n",
      "Epoch 248/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130152.8750 - mae: 748.2177 - val_loss: 1143995.6250 - val_mae: 755.8221\n",
      "Epoch 249/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132032.5000 - mae: 749.9011 - val_loss: 1143244.0000 - val_mae: 755.0372\n",
      "Epoch 250/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130854.1250 - mae: 748.2677 - val_loss: 1144208.8750 - val_mae: 755.2327\n",
      "Epoch 251/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130251.8750 - mae: 748.3323 - val_loss: 1146162.7500 - val_mae: 757.9887\n",
      "Epoch 252/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132111.1250 - mae: 749.9016 - val_loss: 1145575.8750 - val_mae: 757.6498\n",
      "Epoch 253/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131084.2500 - mae: 749.5468 - val_loss: 1144757.3750 - val_mae: 755.2371\n",
      "Epoch 254/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131480.3750 - mae: 748.7266 - val_loss: 1143690.1250 - val_mae: 757.6170\n",
      "Epoch 255/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130251.6250 - mae: 748.8408 - val_loss: 1144559.8750 - val_mae: 756.4150\n",
      "Epoch 256/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128663.8750 - mae: 748.1856 - val_loss: 1146803.7500 - val_mae: 760.0248\n",
      "Epoch 257/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1129910.0000 - mae: 750.0947 - val_loss: 1151082.0000 - val_mae: 754.5413\n",
      "Epoch 258/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130560.5000 - mae: 748.1199 - val_loss: 1144569.0000 - val_mae: 756.4235\n",
      "Epoch 259/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130918.5000 - mae: 749.6166 - val_loss: 1145898.3750 - val_mae: 757.5544\n",
      "Epoch 260/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130061.5000 - mae: 749.1476 - val_loss: 1143127.8750 - val_mae: 755.4747\n",
      "Epoch 261/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1129437.2500 - mae: 748.5280 - val_loss: 1143806.8750 - val_mae: 756.8434\n",
      "Epoch 262/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1129152.0000 - mae: 748.9373 - val_loss: 1142467.2500 - val_mae: 756.7875\n",
      "Epoch 263/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128816.8750 - mae: 749.2411 - val_loss: 1144212.6250 - val_mae: 754.9333\n",
      "Epoch 264/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1129318.5000 - mae: 748.7430 - val_loss: 1144618.2500 - val_mae: 757.1441\n",
      "Epoch 265/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128123.8750 - mae: 748.4442 - val_loss: 1144091.3750 - val_mae: 755.2122\n",
      "Epoch 266/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128317.5000 - mae: 747.5237 - val_loss: 1144461.6250 - val_mae: 754.9369\n",
      "Epoch 267/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128492.6250 - mae: 748.8257 - val_loss: 1145259.0000 - val_mae: 755.2373\n",
      "Epoch 268/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128820.8750 - mae: 747.3114 - val_loss: 1146123.2500 - val_mae: 755.2455\n",
      "Epoch 269/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128720.5000 - mae: 748.5995 - val_loss: 1145719.5000 - val_mae: 758.8478\n",
      "Epoch 270/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1129134.6250 - mae: 750.1032 - val_loss: 1145679.0000 - val_mae: 754.7327\n",
      "Epoch 271/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125818.1250 - mae: 748.1576 - val_loss: 1148612.0000 - val_mae: 761.1508\n",
      "Epoch 272/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130749.7500 - mae: 749.4003 - val_loss: 1142632.5000 - val_mae: 756.2321\n",
      "Epoch 273/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127956.3750 - mae: 748.2080 - val_loss: 1144551.8750 - val_mae: 757.2088\n",
      "Epoch 274/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125979.2500 - mae: 748.4949 - val_loss: 1153190.6250 - val_mae: 754.6655\n",
      "Epoch 275/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1129659.3750 - mae: 748.3203 - val_loss: 1143257.7500 - val_mae: 754.9856\n",
      "Epoch 276/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126833.3750 - mae: 748.2861 - val_loss: 1145522.3750 - val_mae: 755.2639\n",
      "Epoch 277/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126297.6250 - mae: 747.6022 - val_loss: 1145726.5000 - val_mae: 755.0274\n",
      "Epoch 278/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127943.6250 - mae: 747.5434 - val_loss: 1144290.5000 - val_mae: 757.4125\n",
      "Epoch 279/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127636.5000 - mae: 747.9335 - val_loss: 1153004.5000 - val_mae: 764.1704\n",
      "Epoch 280/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131471.3750 - mae: 749.9980 - val_loss: 1146057.0000 - val_mae: 758.6755\n",
      "Epoch 281/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127631.8750 - mae: 748.7228 - val_loss: 1148107.0000 - val_mae: 755.3925\n",
      "Epoch 282/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126889.8750 - mae: 747.5757 - val_loss: 1146217.0000 - val_mae: 757.8588\n",
      "Epoch 283/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126299.6250 - mae: 747.3178 - val_loss: 1149039.1250 - val_mae: 761.0862\n",
      "Epoch 284/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1129519.6250 - mae: 749.9628 - val_loss: 1146755.8750 - val_mae: 755.1219\n",
      "Epoch 285/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128140.3750 - mae: 747.5634 - val_loss: 1145305.8750 - val_mae: 754.5273\n",
      "Epoch 286/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1127106.1250 - mae: 748.1245 - val_loss: 1143885.0000 - val_mae: 756.0895\n",
      "Epoch 287/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126871.7500 - mae: 747.5242 - val_loss: 1143904.2500 - val_mae: 755.1163\n",
      "Epoch 288/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127321.8750 - mae: 747.5654 - val_loss: 1146167.8750 - val_mae: 757.0452\n",
      "Epoch 289/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125859.3750 - mae: 747.0172 - val_loss: 1146020.1250 - val_mae: 758.0890\n",
      "Epoch 290/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125412.5000 - mae: 747.3456 - val_loss: 1151455.6250 - val_mae: 763.2618\n",
      "Epoch 291/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127829.2500 - mae: 747.5777 - val_loss: 1145837.2500 - val_mae: 757.9211\n",
      "Epoch 292/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127445.8750 - mae: 748.0445 - val_loss: 1142719.6250 - val_mae: 756.0497\n",
      "Epoch 293/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125271.6250 - mae: 746.5435 - val_loss: 1143862.3750 - val_mae: 758.1068\n",
      "Epoch 294/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127757.7500 - mae: 748.8976 - val_loss: 1144053.7500 - val_mae: 756.2348\n",
      "Epoch 295/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1124818.0000 - mae: 746.9119 - val_loss: 1143433.5000 - val_mae: 755.8096\n",
      "Epoch 296/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125555.2500 - mae: 748.3669 - val_loss: 1153166.8750 - val_mae: 755.0510\n",
      "Epoch 297/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126740.3750 - mae: 747.7327 - val_loss: 1147537.1250 - val_mae: 755.2653\n",
      "Epoch 298/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124916.2500 - mae: 746.8779 - val_loss: 1146924.6250 - val_mae: 755.5298\n",
      "Epoch 299/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125272.1250 - mae: 746.9916 - val_loss: 1144503.1250 - val_mae: 754.5062\n",
      "Epoch 300/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124837.6250 - mae: 746.6729 - val_loss: 1145497.7500 - val_mae: 758.8778\n",
      "Epoch 301/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126124.1250 - mae: 748.0519 - val_loss: 1143816.6250 - val_mae: 757.9540\n",
      "Epoch 302/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125313.5000 - mae: 747.2659 - val_loss: 1144045.6250 - val_mae: 756.3656\n",
      "Epoch 303/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1124968.2500 - mae: 747.2943 - val_loss: 1144791.7500 - val_mae: 756.3312\n",
      "Epoch 304/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123747.7500 - mae: 747.4578 - val_loss: 1145146.2500 - val_mae: 755.2476\n",
      "Epoch 305/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124188.0000 - mae: 746.5231 - val_loss: 1144897.2500 - val_mae: 755.9536\n",
      "Epoch 306/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123784.6250 - mae: 747.5803 - val_loss: 1147746.2500 - val_mae: 754.8882\n",
      "Epoch 307/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124161.8750 - mae: 746.3710 - val_loss: 1144294.6250 - val_mae: 757.9137\n",
      "Epoch 308/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124315.5000 - mae: 747.1351 - val_loss: 1150316.2500 - val_mae: 755.4694\n",
      "Epoch 309/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124938.7500 - mae: 746.8139 - val_loss: 1146981.3750 - val_mae: 758.8146\n",
      "Epoch 310/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124319.3750 - mae: 747.6816 - val_loss: 1152828.5000 - val_mae: 755.1743\n",
      "Epoch 311/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124431.1250 - mae: 747.2194 - val_loss: 1145963.1250 - val_mae: 756.4794\n",
      "Epoch 312/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124082.7500 - mae: 747.7421 - val_loss: 1144625.1250 - val_mae: 755.9093\n",
      "Epoch 313/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125295.2500 - mae: 746.5677 - val_loss: 1150607.3750 - val_mae: 755.3910\n",
      "Epoch 314/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122030.3750 - mae: 745.9697 - val_loss: 1146608.8750 - val_mae: 759.0032\n",
      "Epoch 315/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124150.0000 - mae: 747.5050 - val_loss: 1146810.1250 - val_mae: 755.2831\n",
      "Epoch 316/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123491.6250 - mae: 745.9821 - val_loss: 1145047.2500 - val_mae: 756.8210\n",
      "Epoch 317/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123955.7500 - mae: 747.5242 - val_loss: 1147566.8750 - val_mae: 756.0737\n",
      "Epoch 318/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1122100.2500 - mae: 745.8533 - val_loss: 1146296.5000 - val_mae: 758.8325\n",
      "Epoch 319/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123266.7500 - mae: 747.7523 - val_loss: 1148134.2500 - val_mae: 755.2976\n",
      "Epoch 320/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123587.6250 - mae: 745.6742 - val_loss: 1145971.7500 - val_mae: 758.0806\n",
      "Epoch 321/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124248.1250 - mae: 747.3328 - val_loss: 1147326.0000 - val_mae: 756.4061\n",
      "Epoch 322/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123550.3750 - mae: 747.2881 - val_loss: 1146159.3750 - val_mae: 755.9564\n",
      "Epoch 323/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122690.7500 - mae: 746.4020 - val_loss: 1146968.3750 - val_mae: 755.6658\n",
      "Epoch 324/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122366.3750 - mae: 746.1065 - val_loss: 1146163.7500 - val_mae: 756.1235\n",
      "Epoch 325/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122166.3750 - mae: 745.1497 - val_loss: 1145331.0000 - val_mae: 758.2873\n",
      "Epoch 326/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123649.2500 - mae: 747.7458 - val_loss: 1146383.5000 - val_mae: 755.6593\n",
      "Epoch 327/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123305.3750 - mae: 745.7783 - val_loss: 1144731.2500 - val_mae: 757.0179\n",
      "Epoch 328/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121833.3750 - mae: 746.7734 - val_loss: 1148300.2500 - val_mae: 760.1276\n",
      "Epoch 329/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121194.3750 - mae: 745.7174 - val_loss: 1146762.5000 - val_mae: 756.0273\n",
      "Epoch 330/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120714.6250 - mae: 745.3326 - val_loss: 1144160.1250 - val_mae: 755.2244\n",
      "Epoch 331/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121889.5000 - mae: 745.7674 - val_loss: 1144801.3750 - val_mae: 756.2523\n",
      "Epoch 332/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120915.8750 - mae: 746.4957 - val_loss: 1149938.3750 - val_mae: 755.2548\n",
      "Epoch 333/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123836.5000 - mae: 745.5337 - val_loss: 1145296.1250 - val_mae: 758.9331\n",
      "Epoch 334/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122867.3750 - mae: 746.4594 - val_loss: 1144108.7500 - val_mae: 757.8855\n",
      "Epoch 335/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121413.5000 - mae: 746.8983 - val_loss: 1144930.0000 - val_mae: 756.1117\n",
      "Epoch 336/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122443.6250 - mae: 745.3303 - val_loss: 1145690.0000 - val_mae: 756.1492\n",
      "Epoch 337/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121746.0000 - mae: 745.6011 - val_loss: 1145686.0000 - val_mae: 757.3488\n",
      "Epoch 338/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120382.0000 - mae: 745.2635 - val_loss: 1147008.5000 - val_mae: 759.5389\n",
      "Epoch 339/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121459.3750 - mae: 746.4095 - val_loss: 1145051.5000 - val_mae: 757.8001\n",
      "Epoch 340/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1120335.0000 - mae: 746.6741 - val_loss: 1148603.2500 - val_mae: 755.4803\n",
      "Epoch 341/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122483.1250 - mae: 745.8280 - val_loss: 1151451.7500 - val_mae: 755.7090\n",
      "Epoch 342/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120418.0000 - mae: 745.2849 - val_loss: 1145148.1250 - val_mae: 758.2026\n",
      "Epoch 343/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121366.0000 - mae: 746.6455 - val_loss: 1144358.7500 - val_mae: 755.7739\n",
      "Epoch 344/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120339.7500 - mae: 745.2467 - val_loss: 1146687.5000 - val_mae: 758.9133\n",
      "Epoch 345/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120274.5000 - mae: 745.8854 - val_loss: 1144694.0000 - val_mae: 756.5851\n",
      "Epoch 346/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121783.0000 - mae: 745.4896 - val_loss: 1143320.3750 - val_mae: 756.6501\n",
      "Epoch 347/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1121381.2500 - mae: 746.1642 - val_loss: 1144525.1250 - val_mae: 755.9494\n",
      "Epoch 348/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119633.8750 - mae: 745.9005 - val_loss: 1147806.2500 - val_mae: 755.9644\n",
      "Epoch 349/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119713.7500 - mae: 744.6229 - val_loss: 1145501.2500 - val_mae: 757.7634\n",
      "Epoch 350/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119509.1250 - mae: 745.0564 - val_loss: 1146798.7500 - val_mae: 755.5989\n",
      "Epoch 351/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120164.1250 - mae: 745.3455 - val_loss: 1145702.7500 - val_mae: 756.0110\n",
      "Epoch 352/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120635.7500 - mae: 745.0173 - val_loss: 1145067.0000 - val_mae: 755.7428\n",
      "Epoch 353/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120038.2500 - mae: 745.6105 - val_loss: 1146204.1250 - val_mae: 757.5719\n",
      "Epoch 354/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118688.6250 - mae: 745.2750 - val_loss: 1145641.8750 - val_mae: 757.6722\n",
      "Epoch 355/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119199.8750 - mae: 745.3696 - val_loss: 1152945.6250 - val_mae: 755.7526\n",
      "Epoch 356/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119195.3750 - mae: 744.7769 - val_loss: 1147269.2500 - val_mae: 755.5701\n",
      "Epoch 357/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118093.2500 - mae: 744.9127 - val_loss: 1146547.8750 - val_mae: 760.3265\n",
      "Epoch 358/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118469.6250 - mae: 745.9144 - val_loss: 1146176.5000 - val_mae: 755.4789\n",
      "Epoch 359/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120353.6250 - mae: 745.5520 - val_loss: 1147252.1250 - val_mae: 756.0309\n",
      "Epoch 360/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119627.1250 - mae: 744.9335 - val_loss: 1144741.1250 - val_mae: 755.6898\n",
      "Epoch 361/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117938.5000 - mae: 744.2743 - val_loss: 1143991.1250 - val_mae: 758.9624\n",
      "Epoch 362/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119847.8750 - mae: 746.3152 - val_loss: 1144857.6250 - val_mae: 757.1794\n",
      "Epoch 363/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119027.1250 - mae: 745.0599 - val_loss: 1143785.3750 - val_mae: 757.8940\n",
      "Epoch 364/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116423.2500 - mae: 744.4664 - val_loss: 1149013.3750 - val_mae: 755.9526\n",
      "Epoch 365/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118362.7500 - mae: 744.5406 - val_loss: 1144689.3750 - val_mae: 757.1960\n",
      "Epoch 366/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117422.8750 - mae: 744.8166 - val_loss: 1144999.1250 - val_mae: 756.7442\n",
      "Epoch 367/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117020.0000 - mae: 744.8710 - val_loss: 1145574.3750 - val_mae: 755.6733\n",
      "Epoch 368/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118211.7500 - mae: 744.3098 - val_loss: 1144447.6250 - val_mae: 757.2076\n",
      "Epoch 369/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1116741.3750 - mae: 744.7300 - val_loss: 1160124.6250 - val_mae: 756.4238\n",
      "Epoch 370/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119607.6250 - mae: 744.1921 - val_loss: 1145305.7500 - val_mae: 757.9289\n",
      "Epoch 371/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117636.5000 - mae: 744.4100 - val_loss: 1144724.3750 - val_mae: 757.4789\n",
      "Epoch 372/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116938.6250 - mae: 745.0079 - val_loss: 1145953.1250 - val_mae: 756.9602\n",
      "Epoch 373/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116573.1250 - mae: 744.6460 - val_loss: 1147950.7500 - val_mae: 756.1569\n",
      "Epoch 374/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117937.1250 - mae: 744.9538 - val_loss: 1148482.5000 - val_mae: 756.3849\n",
      "Epoch 375/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1115029.7500 - mae: 744.8207 - val_loss: 1155192.6250 - val_mae: 756.1376\n",
      "Epoch 376/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116976.8750 - mae: 743.3408 - val_loss: 1145209.8750 - val_mae: 757.3325\n",
      "Epoch 377/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116831.7500 - mae: 744.1912 - val_loss: 1144595.0000 - val_mae: 757.2673\n",
      "Epoch 378/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117477.5000 - mae: 744.8563 - val_loss: 1147233.3750 - val_mae: 756.5343\n",
      "Epoch 379/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1115764.2500 - mae: 743.6767 - val_loss: 1144185.6250 - val_mae: 757.7808\n",
      "Epoch 380/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116750.2500 - mae: 744.6528 - val_loss: 1146715.5000 - val_mae: 756.7187\n",
      "Epoch 381/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116451.7500 - mae: 744.6952 - val_loss: 1145136.2500 - val_mae: 757.0521\n",
      "Epoch 382/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116074.8750 - mae: 743.9678 - val_loss: 1145867.2500 - val_mae: 757.6192\n",
      "Epoch 383/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1117333.8750 - mae: 744.8830 - val_loss: 1146220.3750 - val_mae: 757.0941\n",
      "Epoch 384/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117645.5000 - mae: 744.9745 - val_loss: 1144108.3750 - val_mae: 757.6880\n",
      "Epoch 385/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118029.2500 - mae: 745.2820 - val_loss: 1145283.7500 - val_mae: 757.7211\n",
      "Epoch 386/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117570.0000 - mae: 746.3938 - val_loss: 1145245.0000 - val_mae: 758.8874\n",
      "Epoch 387/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1115530.7500 - mae: 743.7521 - val_loss: 1145237.5000 - val_mae: 757.2368\n",
      "Epoch 388/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114446.6250 - mae: 742.9500 - val_loss: 1148722.0000 - val_mae: 761.7101\n",
      "Epoch 389/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117898.0000 - mae: 746.0152 - val_loss: 1150307.7500 - val_mae: 756.7936\n",
      "Epoch 390/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1115634.1250 - mae: 743.9190 - val_loss: 1145690.1250 - val_mae: 757.1705\n",
      "Epoch 391/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114944.1250 - mae: 744.0450 - val_loss: 1147611.1250 - val_mae: 755.6926\n",
      "Epoch 392/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114905.7500 - mae: 743.3608 - val_loss: 1149447.1250 - val_mae: 756.8193\n",
      "Epoch 393/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1115715.7500 - mae: 744.7036 - val_loss: 1147770.5000 - val_mae: 758.1296\n",
      "Epoch 394/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1113758.7500 - mae: 743.0640 - val_loss: 1144784.1250 - val_mae: 759.0728\n",
      "Epoch 395/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114176.3750 - mae: 742.7946 - val_loss: 1146172.3750 - val_mae: 760.1318\n",
      "Epoch 396/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1116625.0000 - mae: 745.6583 - val_loss: 1145196.1250 - val_mae: 759.0345\n",
      "Epoch 397/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114481.1250 - mae: 744.0706 - val_loss: 1145180.5000 - val_mae: 756.1035\n",
      "Epoch 398/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114990.2500 - mae: 743.1608 - val_loss: 1144932.8750 - val_mae: 757.8252\n",
      "Epoch 399/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114569.7500 - mae: 743.9603 - val_loss: 1145579.6250 - val_mae: 757.8188\n",
      "Epoch 400/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114736.1250 - mae: 742.7984 - val_loss: 1146615.6250 - val_mae: 756.6321\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "# passing the independent and dependent features for training set for training the model\n",
    "\n",
    "# validation data will be evaluated at the end of each epoch\n",
    "\n",
    "# setting the epochs as 50\n",
    "\n",
    "# storing the trained model in model_history variable which will be used to visualize the training process\n",
    "\n",
    "model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 973us/step - loss: 1146615.6250 - mae: 756.6321\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "R2 Score: 0.6028369536929801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model_history.history['mae'])\n",
    "plt.plot(model_history.history['val_mae'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.605356359282686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
