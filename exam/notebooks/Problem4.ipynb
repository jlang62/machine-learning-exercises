{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 14:17:51.194026: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv('../data/deep_learning_task_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            5000 non-null   object \n",
      " 1   Item_Weight                4182 non-null   float64\n",
      " 2   Item_Fat_Content           5000 non-null   object \n",
      " 3   Item_Visibility            5000 non-null   float64\n",
      " 4   Item_Type                  5000 non-null   object \n",
      " 5   Item_MRP                   5000 non-null   float64\n",
      " 6   Outlet_Identifier          5000 non-null   object \n",
      " 7   Outlet_Establishment_Year  5000 non-null   int64  \n",
      " 8   Outlet_Size                3561 non-null   object \n",
      " 9   Outlet_Location_Type       5000 non-null   object \n",
      " 10  Outlet_Type                5000 non-null   object \n",
      " 11  Item_Outlet_Sales          5000 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                   818\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  1439\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/pk9yd5v978d_6j_wky4ptw480000gn/T/ipykernel_32867/889244835.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df.fillna(df.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# fill the missing values with the mean of the column\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df['Outlet_Size'].fillna(df['Outlet_Size'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    3044\n",
       "Small     1398\n",
       "High       558\n",
       "Name: Outlet_Size, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Outlet_Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat' 'Regular' 'low fat' 'LF' 'reg']\n",
      "['Dairy' 'Soft Drinks' 'Meat' 'Fruits and Vegetables' 'Household'\n",
      " 'Baking Goods' 'Snack Foods' 'Frozen Foods' 'Breakfast'\n",
      " 'Health and Hygiene' 'Hard Drinks' 'Canned' 'Breads' 'Starchy Foods'\n",
      " 'Others' 'Seafood']\n",
      "['Medium' 'High' 'Small']\n",
      "['Tier 1' 'Tier 3' 'Tier 2']\n",
      "['OUT049' 'OUT018' 'OUT010' 'OUT013' 'OUT027' 'OUT045' 'OUT017' 'OUT046'\n",
      " 'OUT035' 'OUT019']\n",
      "['Supermarket Type1' 'Supermarket Type2' 'Grocery Store'\n",
      " 'Supermarket Type3']\n"
     ]
    }
   ],
   "source": [
    "print(df['Item_Fat_Content'].unique())\n",
    "print(df['Item_Type'].unique())\n",
    "print(df['Outlet_Size'].unique())\n",
    "print(df['Outlet_Location_Type'].unique())\n",
    "print(df['Outlet_Identifier'].unique())\n",
    "print(df['Outlet_Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low Fat', 'Regular'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Item_Fat_Content'].replace(['low fat', 'LF', 'reg'], ['Low Fat', 'Low Fat', 'Regular'], inplace=True)\n",
    "df['Item_Fat_Content'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998      Medium               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df.drop(['Item_Identifier', 'Outlet_Establishment_Year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282525</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.048866</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>0.927507</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081274</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.058705</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>0.072068</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770765</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>Meat</td>\n",
       "      <td>0.468288</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.871986</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260494</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>0.095805</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight Item_Fat_Content  Item_Visibility              Item_Type  \\\n",
       "0     0.282525          Low Fat         0.048866                  Dairy   \n",
       "1     0.081274          Regular         0.058705            Soft Drinks   \n",
       "2     0.770765          Low Fat         0.051037                   Meat   \n",
       "3     0.871986          Regular         0.000000  Fruits and Vegetables   \n",
       "4     0.260494          Low Fat         0.000000              Household   \n",
       "\n",
       "   Item_MRP Outlet_Identifier Outlet_Size Outlet_Location_Type  \\\n",
       "0  0.927507            OUT049      Medium               Tier 1   \n",
       "1  0.072068            OUT018      Medium               Tier 3   \n",
       "2  0.468288            OUT049      Medium               Tier 1   \n",
       "3  0.640093            OUT010      Medium               Tier 3   \n",
       "4  0.095805            OUT013        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing the data Item_Weight, Item_Visibility, Item_MRP, Outlet_Establishment_Year\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_sub[['Item_Weight', 'Item_Visibility', 'Item_MRP']] = scaler.fit_transform(df_sub[['Item_Weight', 'Item_Visibility', 'Item_MRP']])\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Item_Fat_Content_Low Fat</th>\n",
       "      <th>Item_Fat_Content_Regular</th>\n",
       "      <th>Item_Type_Baking Goods</th>\n",
       "      <th>Item_Type_Breads</th>\n",
       "      <th>Item_Type_Breakfast</th>\n",
       "      <th>Item_Type_Canned</th>\n",
       "      <th>Item_Type_Dairy</th>\n",
       "      <th>...</th>\n",
       "      <th>Outlet_Size_High</th>\n",
       "      <th>Outlet_Size_Medium</th>\n",
       "      <th>Outlet_Size_Small</th>\n",
       "      <th>Outlet_Location_Type_Tier 1</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Supermarket Type2</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282525</td>\n",
       "      <td>0.048866</td>\n",
       "      <td>0.927507</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081274</td>\n",
       "      <td>0.058705</td>\n",
       "      <td>0.072068</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770765</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>0.468288</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.871986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Visibility  Item_MRP  Item_Fat_Content_Low Fat  \\\n",
       "0     0.282525         0.048866  0.927507                         1   \n",
       "1     0.081274         0.058705  0.072068                         0   \n",
       "2     0.770765         0.051037  0.468288                         1   \n",
       "3     0.871986         0.000000  0.640093                         0   \n",
       "4     0.260494         0.000000  0.095805                         1   \n",
       "\n",
       "   Item_Fat_Content_Regular  Item_Type_Baking Goods  Item_Type_Breads  \\\n",
       "0                         0                       0                 0   \n",
       "1                         1                       0                 0   \n",
       "2                         0                       0                 0   \n",
       "3                         1                       0                 0   \n",
       "4                         0                       0                 0   \n",
       "\n",
       "   Item_Type_Breakfast  Item_Type_Canned  Item_Type_Dairy  ...  \\\n",
       "0                    0                 0                1  ...   \n",
       "1                    0                 0                0  ...   \n",
       "2                    0                 0                0  ...   \n",
       "3                    0                 0                0  ...   \n",
       "4                    0                 0                0  ...   \n",
       "\n",
       "   Outlet_Size_High  Outlet_Size_Medium  Outlet_Size_Small  \\\n",
       "0                 0                   1                  0   \n",
       "1                 0                   1                  0   \n",
       "2                 0                   1                  0   \n",
       "3                 0                   1                  0   \n",
       "4                 1                   0                  0   \n",
       "\n",
       "   Outlet_Location_Type_Tier 1  Outlet_Location_Type_Tier 2  \\\n",
       "0                            1                            0   \n",
       "1                            0                            0   \n",
       "2                            1                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   Outlet_Location_Type_Tier 3  Outlet_Type_Grocery Store  \\\n",
       "0                            0                          0   \n",
       "1                            1                          0   \n",
       "2                            0                          0   \n",
       "3                            1                          1   \n",
       "4                            1                          0   \n",
       "\n",
       "   Outlet_Type_Supermarket Type1  Outlet_Type_Supermarket Type2  \\\n",
       "0                              1                              0   \n",
       "1                              0                              1   \n",
       "2                              1                              0   \n",
       "3                              0                              0   \n",
       "4                              1                              0   \n",
       "\n",
       "   Outlet_Type_Supermarket Type3  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(df_sub.drop(['Item_Outlet_Sales'], axis=1))\n",
    "y = df_sub['Item_Outlet_Sales']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 41), (5000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((4000, 41), (4000,)), ((1000, 41), (1000,)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation set\n",
    "\n",
    "# stratify will make sure that the distribution of classes in train and validation set it similar\n",
    "# random state to regenerate the same train and validation set\n",
    "# test size 0.2 will keep 20% data in validation and remaining 80% in train set\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "\n",
    "# shape of training and validation set\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the sequential model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# importing different layers from keras\n",
    "from keras.layers import InputLayer, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 41)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of input neurons\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features in the data\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining input neurons\n",
    "input_neurons = X_train.shape[1]\n",
    "input_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of output neurons\n",
    "output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hidden layers and neuron in each layer\n",
    "number_of_hidden_layers = 2\n",
    "neuron_hidden_layer_1 = 80\n",
    "neuron_hidden_layer_2 = 40\n",
    "neuron_hidden_layer_3 = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                3360      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                3240      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6641 (25.94 KB)\n",
      "Trainable params: 6641 (25.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "# defining the architecture of the model\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=(input_neurons)))\n",
    "model.add(Dense(units=neuron_hidden_layer_1, activation='relu'))\n",
    "model.add(Dense(units=neuron_hidden_layer_2, activation='relu'))\n",
    "model.add(Dense(units=output_neurons, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001), metrics=['mae'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 2ms/step - loss: 7624415.5000 - mae: 2173.0447 - val_loss: 7150946.5000 - val_mae: 2066.7029\n",
      "Epoch 2/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 6114836.5000 - mae: 1838.5911 - val_loss: 4401769.5000 - val_mae: 1473.7480\n",
      "Epoch 3/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 3242747.0000 - mae: 1293.9894 - val_loss: 2517301.2500 - val_mae: 1200.2748\n",
      "Epoch 4/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2401183.0000 - mae: 1206.2974 - val_loss: 2341291.0000 - val_mae: 1202.6135\n",
      "Epoch 5/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2267240.2500 - mae: 1185.7405 - val_loss: 2228504.7500 - val_mae: 1163.4055\n",
      "Epoch 6/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2164709.0000 - mae: 1145.4685 - val_loss: 2134268.7500 - val_mae: 1134.5491\n",
      "Epoch 7/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2079179.8750 - mae: 1114.4761 - val_loss: 2051990.7500 - val_mae: 1105.5114\n",
      "Epoch 8/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2003884.8750 - mae: 1087.7971 - val_loss: 1973754.6250 - val_mae: 1067.8599\n",
      "Epoch 9/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1939390.6250 - mae: 1061.0593 - val_loss: 1905758.2500 - val_mae: 1040.1299\n",
      "Epoch 10/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1881808.3750 - mae: 1036.6449 - val_loss: 1843637.8750 - val_mae: 1020.5535\n",
      "Epoch 11/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1830905.3750 - mae: 1018.2162 - val_loss: 1787216.6250 - val_mae: 999.9293\n",
      "Epoch 12/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1782890.2500 - mae: 1000.9508 - val_loss: 1735816.6250 - val_mae: 983.7008\n",
      "Epoch 13/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1739844.5000 - mae: 989.2106 - val_loss: 1685905.7500 - val_mae: 962.2153\n",
      "Epoch 14/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1695440.7500 - mae: 970.4939 - val_loss: 1639322.5000 - val_mae: 953.6829\n",
      "Epoch 15/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1654549.1250 - mae: 961.9299 - val_loss: 1592433.0000 - val_mae: 933.1805\n",
      "Epoch 16/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1612985.0000 - mae: 946.6405 - val_loss: 1546500.5000 - val_mae: 915.3965\n",
      "Epoch 17/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1570154.2500 - mae: 930.6003 - val_loss: 1504739.0000 - val_mae: 910.9249\n",
      "Epoch 18/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1530480.3750 - mae: 918.8442 - val_loss: 1461362.2500 - val_mae: 881.3561\n",
      "Epoch 19/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1486627.5000 - mae: 902.3098 - val_loss: 1418437.2500 - val_mae: 876.7912\n",
      "Epoch 20/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1447066.0000 - mae: 889.0446 - val_loss: 1377680.3750 - val_mae: 852.0709\n",
      "Epoch 21/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1409294.5000 - mae: 872.0861 - val_loss: 1340748.5000 - val_mae: 843.3470\n",
      "Epoch 22/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1374366.7500 - mae: 859.5500 - val_loss: 1305088.0000 - val_mae: 824.7140\n",
      "Epoch 23/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1339336.8750 - mae: 845.6707 - val_loss: 1274573.7500 - val_mae: 810.5685\n",
      "Epoch 24/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1310073.6250 - mae: 831.0932 - val_loss: 1246290.2500 - val_mae: 801.4045\n",
      "Epoch 25/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1283897.3750 - mae: 819.9263 - val_loss: 1224808.5000 - val_mae: 798.8605\n",
      "Epoch 26/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1262150.0000 - mae: 811.9041 - val_loss: 1207195.0000 - val_mae: 780.4288\n",
      "Epoch 27/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1246723.0000 - mae: 802.5464 - val_loss: 1194518.1250 - val_mae: 775.8076\n",
      "Epoch 28/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1232207.3750 - mae: 795.3712 - val_loss: 1181401.7500 - val_mae: 771.6609\n",
      "Epoch 29/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1221657.2500 - mae: 790.2407 - val_loss: 1175327.2500 - val_mae: 767.6312\n",
      "Epoch 30/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1212598.2500 - mae: 785.6820 - val_loss: 1168546.3750 - val_mae: 765.5015\n",
      "Epoch 31/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1207800.2500 - mae: 781.7745 - val_loss: 1162414.2500 - val_mae: 762.5370\n",
      "Epoch 32/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1201383.6250 - mae: 778.8017 - val_loss: 1161046.1250 - val_mae: 763.1099\n",
      "Epoch 33/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1198484.8750 - mae: 778.4207 - val_loss: 1162976.7500 - val_mae: 757.2852\n",
      "Epoch 34/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1196729.0000 - mae: 775.1141 - val_loss: 1158719.8750 - val_mae: 758.8408\n",
      "Epoch 35/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194118.5000 - mae: 775.6971 - val_loss: 1158344.8750 - val_mae: 759.2953\n",
      "Epoch 36/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1193514.8750 - mae: 774.6209 - val_loss: 1155867.5000 - val_mae: 759.7291\n",
      "Epoch 37/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1192101.7500 - mae: 772.9238 - val_loss: 1158855.0000 - val_mae: 756.1345\n",
      "Epoch 38/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1189275.8750 - mae: 771.3344 - val_loss: 1156909.5000 - val_mae: 762.6229\n",
      "Epoch 39/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1189393.7500 - mae: 772.8567 - val_loss: 1156161.6250 - val_mae: 756.7548\n",
      "Epoch 40/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1188460.7500 - mae: 772.0463 - val_loss: 1158940.6250 - val_mae: 755.3836\n",
      "Epoch 41/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1188730.6250 - mae: 771.8643 - val_loss: 1155381.7500 - val_mae: 757.3816\n",
      "Epoch 42/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187193.8750 - mae: 770.1420 - val_loss: 1155998.6250 - val_mae: 758.3324\n",
      "Epoch 43/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187234.8750 - mae: 770.6829 - val_loss: 1156383.2500 - val_mae: 761.9249\n",
      "Epoch 44/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187329.1250 - mae: 771.1613 - val_loss: 1154222.7500 - val_mae: 756.9155\n",
      "Epoch 45/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1185528.5000 - mae: 768.9263 - val_loss: 1156031.3750 - val_mae: 763.3400\n",
      "Epoch 46/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1186071.3750 - mae: 770.9349 - val_loss: 1156521.5000 - val_mae: 763.2997\n",
      "Epoch 47/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1184439.2500 - mae: 769.8127 - val_loss: 1154056.3750 - val_mae: 757.2037\n",
      "Epoch 48/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1184527.8750 - mae: 769.1495 - val_loss: 1153931.8750 - val_mae: 758.2106\n",
      "Epoch 49/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1185489.2500 - mae: 769.5010 - val_loss: 1152885.1250 - val_mae: 757.7087\n",
      "Epoch 50/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1183662.7500 - mae: 769.2550 - val_loss: 1153719.6250 - val_mae: 756.9006\n",
      "Epoch 51/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1183401.5000 - mae: 768.3157 - val_loss: 1153319.0000 - val_mae: 755.6124\n",
      "Epoch 52/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1182465.8750 - mae: 769.0042 - val_loss: 1153363.6250 - val_mae: 757.4681\n",
      "Epoch 53/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1181955.8750 - mae: 767.7371 - val_loss: 1154026.7500 - val_mae: 757.9385\n",
      "Epoch 54/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1182316.6250 - mae: 768.5322 - val_loss: 1152145.7500 - val_mae: 758.1144\n",
      "Epoch 55/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1181071.8750 - mae: 767.7432 - val_loss: 1153454.6250 - val_mae: 755.7211\n",
      "Epoch 56/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1180250.1250 - mae: 766.4047 - val_loss: 1150609.7500 - val_mae: 757.1556\n",
      "Epoch 57/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1177570.5000 - mae: 767.6279 - val_loss: 1162068.6250 - val_mae: 754.6658\n",
      "Epoch 58/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1181245.7500 - mae: 765.9744 - val_loss: 1153798.2500 - val_mae: 755.1422\n",
      "Epoch 59/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1179163.3750 - mae: 766.7244 - val_loss: 1153257.0000 - val_mae: 755.5445\n",
      "Epoch 60/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1178855.5000 - mae: 766.5248 - val_loss: 1150140.7500 - val_mae: 757.4158\n",
      "Epoch 61/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1178565.2500 - mae: 766.0973 - val_loss: 1150948.8750 - val_mae: 758.5299\n",
      "Epoch 62/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1177764.1250 - mae: 767.6119 - val_loss: 1153031.0000 - val_mae: 755.2675\n",
      "Epoch 63/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1177471.1250 - mae: 765.6102 - val_loss: 1151568.3750 - val_mae: 758.8569\n",
      "Epoch 64/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1176810.5000 - mae: 764.7780 - val_loss: 1151275.5000 - val_mae: 758.8911\n",
      "Epoch 65/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1175593.3750 - mae: 765.5264 - val_loss: 1150325.7500 - val_mae: 756.1218\n",
      "Epoch 66/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1176060.5000 - mae: 765.2470 - val_loss: 1151583.1250 - val_mae: 761.1302\n",
      "Epoch 67/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1175723.2500 - mae: 765.6164 - val_loss: 1148161.5000 - val_mae: 757.6961\n",
      "Epoch 68/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1175473.8750 - mae: 764.5909 - val_loss: 1148133.5000 - val_mae: 756.2419\n",
      "Epoch 69/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1174714.5000 - mae: 765.0924 - val_loss: 1149518.5000 - val_mae: 756.5519\n",
      "Epoch 70/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1174866.3750 - mae: 764.6290 - val_loss: 1149399.1250 - val_mae: 756.9555\n",
      "Epoch 71/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1173440.0000 - mae: 764.4504 - val_loss: 1150631.8750 - val_mae: 757.8766\n",
      "Epoch 72/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1173166.8750 - mae: 763.7651 - val_loss: 1148521.6250 - val_mae: 756.7547\n",
      "Epoch 73/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1172687.2500 - mae: 764.0800 - val_loss: 1148780.0000 - val_mae: 755.3793\n",
      "Epoch 74/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171602.1250 - mae: 763.1672 - val_loss: 1148943.0000 - val_mae: 757.5448\n",
      "Epoch 75/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171501.0000 - mae: 763.9741 - val_loss: 1149630.1250 - val_mae: 755.7360\n",
      "Epoch 76/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171542.0000 - mae: 762.9891 - val_loss: 1148443.6250 - val_mae: 755.9309\n",
      "Epoch 77/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1169995.6250 - mae: 762.9019 - val_loss: 1147035.0000 - val_mae: 755.6575\n",
      "Epoch 78/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1170878.2500 - mae: 763.0008 - val_loss: 1147588.7500 - val_mae: 754.5758\n",
      "Epoch 79/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1170104.1250 - mae: 762.5677 - val_loss: 1146677.2500 - val_mae: 755.8525\n",
      "Epoch 80/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168253.6250 - mae: 762.5649 - val_loss: 1146806.7500 - val_mae: 755.1682\n",
      "Epoch 81/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168882.8750 - mae: 762.8580 - val_loss: 1148783.8750 - val_mae: 753.9794\n",
      "Epoch 82/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1169516.0000 - mae: 762.1074 - val_loss: 1149220.6250 - val_mae: 753.9277\n",
      "Epoch 83/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1167278.1250 - mae: 761.3498 - val_loss: 1147311.6250 - val_mae: 758.7921\n",
      "Epoch 84/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168060.8750 - mae: 761.6232 - val_loss: 1146572.2500 - val_mae: 755.7512\n",
      "Epoch 85/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1167944.7500 - mae: 761.0491 - val_loss: 1146412.2500 - val_mae: 755.0506\n",
      "Epoch 86/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1166556.7500 - mae: 761.3627 - val_loss: 1147949.8750 - val_mae: 753.9902\n",
      "Epoch 87/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1167582.0000 - mae: 760.8500 - val_loss: 1146811.1250 - val_mae: 758.0756\n",
      "Epoch 88/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1166405.0000 - mae: 761.0848 - val_loss: 1144222.7500 - val_mae: 755.9461\n",
      "Epoch 89/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1165086.1250 - mae: 762.0640 - val_loss: 1149148.1250 - val_mae: 753.3076\n",
      "Epoch 90/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1167452.5000 - mae: 760.4526 - val_loss: 1145253.0000 - val_mae: 755.3680\n",
      "Epoch 91/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1165954.1250 - mae: 761.4470 - val_loss: 1145322.0000 - val_mae: 755.4633\n",
      "Epoch 92/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164033.0000 - mae: 761.1736 - val_loss: 1150616.1250 - val_mae: 753.1943\n",
      "Epoch 93/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1164073.3750 - mae: 758.8969 - val_loss: 1145267.1250 - val_mae: 757.2922\n",
      "Epoch 94/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1163670.1250 - mae: 760.6088 - val_loss: 1147363.6250 - val_mae: 753.3337\n",
      "Epoch 95/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1163595.3750 - mae: 759.7053 - val_loss: 1145059.3750 - val_mae: 755.5754\n",
      "Epoch 96/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1163565.2500 - mae: 760.0421 - val_loss: 1148190.0000 - val_mae: 753.4265\n",
      "Epoch 97/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160905.8750 - mae: 758.9157 - val_loss: 1152368.8750 - val_mae: 751.8062\n",
      "Epoch 98/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1163456.1250 - mae: 760.1588 - val_loss: 1147093.6250 - val_mae: 752.5272\n",
      "Epoch 99/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1162577.7500 - mae: 759.2769 - val_loss: 1145164.2500 - val_mae: 755.0224\n",
      "Epoch 100/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1161538.1250 - mae: 758.4926 - val_loss: 1144617.6250 - val_mae: 757.4800\n",
      "Epoch 101/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163196.0000 - mae: 759.9480 - val_loss: 1143925.6250 - val_mae: 754.1871\n",
      "Epoch 102/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1161365.1250 - mae: 759.1084 - val_loss: 1143928.8750 - val_mae: 754.5669\n",
      "Epoch 103/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1161413.5000 - mae: 759.0189 - val_loss: 1144557.8750 - val_mae: 753.4483\n",
      "Epoch 104/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1162009.2500 - mae: 759.6883 - val_loss: 1142835.0000 - val_mae: 754.6318\n",
      "Epoch 105/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159874.1250 - mae: 758.9716 - val_loss: 1148304.8750 - val_mae: 752.2465\n",
      "Epoch 106/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1161303.7500 - mae: 758.9982 - val_loss: 1144954.2500 - val_mae: 753.1541\n",
      "Epoch 107/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160271.1250 - mae: 757.8292 - val_loss: 1144397.1250 - val_mae: 753.6736\n",
      "Epoch 108/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1161700.8750 - mae: 758.3286 - val_loss: 1142832.5000 - val_mae: 754.4465\n",
      "Epoch 109/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1158424.3750 - mae: 758.0427 - val_loss: 1143209.2500 - val_mae: 756.1035\n",
      "Epoch 110/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160551.7500 - mae: 759.5189 - val_loss: 1142564.7500 - val_mae: 754.1392\n",
      "Epoch 111/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1161096.7500 - mae: 758.8375 - val_loss: 1146273.1250 - val_mae: 752.4099\n",
      "Epoch 112/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1158042.7500 - mae: 758.5289 - val_loss: 1143911.7500 - val_mae: 752.4973\n",
      "Epoch 113/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1158620.1250 - mae: 758.1393 - val_loss: 1146036.3750 - val_mae: 751.7780\n",
      "Epoch 114/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1158952.2500 - mae: 757.4882 - val_loss: 1142268.0000 - val_mae: 753.1198\n",
      "Epoch 115/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159301.5000 - mae: 758.0540 - val_loss: 1144921.2500 - val_mae: 753.1667\n",
      "Epoch 116/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1159683.7500 - mae: 758.8250 - val_loss: 1144174.8750 - val_mae: 751.9438\n",
      "Epoch 117/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1157904.7500 - mae: 758.0419 - val_loss: 1143794.0000 - val_mae: 752.5872\n",
      "Epoch 118/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157111.1250 - mae: 757.2717 - val_loss: 1142151.3750 - val_mae: 756.2329\n",
      "Epoch 119/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157863.6250 - mae: 757.2125 - val_loss: 1143052.7500 - val_mae: 755.4408\n",
      "Epoch 120/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156582.1250 - mae: 756.8415 - val_loss: 1143758.7500 - val_mae: 754.0371\n",
      "Epoch 121/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155722.3750 - mae: 757.5537 - val_loss: 1144890.1250 - val_mae: 751.9680\n",
      "Epoch 122/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156738.8750 - mae: 756.8796 - val_loss: 1146847.6250 - val_mae: 751.4095\n",
      "Epoch 123/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155882.0000 - mae: 755.8481 - val_loss: 1141449.1250 - val_mae: 754.1181\n",
      "Epoch 124/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157283.5000 - mae: 757.7651 - val_loss: 1143207.3750 - val_mae: 752.9852\n",
      "Epoch 125/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156652.6250 - mae: 757.5135 - val_loss: 1142533.0000 - val_mae: 753.3045\n",
      "Epoch 126/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155738.0000 - mae: 755.9699 - val_loss: 1145038.0000 - val_mae: 751.4541\n",
      "Epoch 127/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155442.5000 - mae: 756.4109 - val_loss: 1141344.0000 - val_mae: 753.6191\n",
      "Epoch 128/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155607.3750 - mae: 756.8546 - val_loss: 1142598.5000 - val_mae: 752.2617\n",
      "Epoch 129/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153889.8750 - mae: 755.9365 - val_loss: 1142009.2500 - val_mae: 754.2244\n",
      "Epoch 130/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1154694.5000 - mae: 756.3222 - val_loss: 1142089.8750 - val_mae: 752.1619\n",
      "Epoch 131/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155146.0000 - mae: 756.6996 - val_loss: 1141825.1250 - val_mae: 752.3090\n",
      "Epoch 132/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155205.0000 - mae: 755.8058 - val_loss: 1140435.6250 - val_mae: 755.1526\n",
      "Epoch 133/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155220.8750 - mae: 756.7391 - val_loss: 1141562.5000 - val_mae: 752.2096\n",
      "Epoch 134/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1153643.0000 - mae: 755.3256 - val_loss: 1141841.2500 - val_mae: 755.2004\n",
      "Epoch 135/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1154594.1250 - mae: 757.7069 - val_loss: 1141427.3750 - val_mae: 752.6119\n",
      "Epoch 136/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153482.5000 - mae: 755.7196 - val_loss: 1141205.6250 - val_mae: 752.9431\n",
      "Epoch 137/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153430.3750 - mae: 756.0264 - val_loss: 1141883.6250 - val_mae: 752.0599\n",
      "Epoch 138/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153760.6250 - mae: 755.8759 - val_loss: 1141745.2500 - val_mae: 753.0225\n",
      "Epoch 139/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1152565.0000 - mae: 755.6395 - val_loss: 1142223.5000 - val_mae: 752.4435\n",
      "Epoch 140/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151361.1250 - mae: 755.7372 - val_loss: 1142472.7500 - val_mae: 751.7718\n",
      "Epoch 141/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152257.2500 - mae: 755.0421 - val_loss: 1141987.1250 - val_mae: 752.6481\n",
      "Epoch 142/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149055.7500 - mae: 753.6751 - val_loss: 1146673.0000 - val_mae: 761.2922\n",
      "Epoch 143/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153754.6250 - mae: 755.9643 - val_loss: 1141495.3750 - val_mae: 753.5237\n",
      "Epoch 144/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1151047.6250 - mae: 755.5659 - val_loss: 1147622.0000 - val_mae: 751.5532\n",
      "Epoch 145/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153029.7500 - mae: 755.4053 - val_loss: 1140775.3750 - val_mae: 754.0569\n",
      "Epoch 146/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149669.1250 - mae: 754.9172 - val_loss: 1141187.7500 - val_mae: 753.2571\n",
      "Epoch 147/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151457.0000 - mae: 755.6746 - val_loss: 1144113.2500 - val_mae: 751.3403\n",
      "Epoch 148/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151464.6250 - mae: 755.1476 - val_loss: 1141840.5000 - val_mae: 754.9235\n",
      "Epoch 149/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149002.1250 - mae: 754.7609 - val_loss: 1146726.6250 - val_mae: 751.7006\n",
      "Epoch 150/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1150487.0000 - mae: 754.9093 - val_loss: 1142311.5000 - val_mae: 753.6147\n",
      "Epoch 151/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1150540.7500 - mae: 754.5166 - val_loss: 1141792.5000 - val_mae: 753.6519\n",
      "Epoch 152/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148529.1250 - mae: 754.3708 - val_loss: 1145090.7500 - val_mae: 751.4484\n",
      "Epoch 153/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149301.1250 - mae: 754.3116 - val_loss: 1141565.8750 - val_mae: 752.7401\n",
      "Epoch 154/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1148580.0000 - mae: 753.8758 - val_loss: 1140526.6250 - val_mae: 753.8768\n",
      "Epoch 155/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149375.2500 - mae: 754.2283 - val_loss: 1139307.2500 - val_mae: 754.1663\n",
      "Epoch 156/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1150232.3750 - mae: 754.2434 - val_loss: 1139758.7500 - val_mae: 752.8932\n",
      "Epoch 157/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148207.2500 - mae: 754.1444 - val_loss: 1145621.6250 - val_mae: 752.0324\n",
      "Epoch 158/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149957.7500 - mae: 753.6984 - val_loss: 1143237.3750 - val_mae: 752.4291\n",
      "Epoch 159/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148200.7500 - mae: 753.9623 - val_loss: 1141377.5000 - val_mae: 753.8253\n",
      "Epoch 160/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148377.1250 - mae: 754.4462 - val_loss: 1142325.6250 - val_mae: 752.4852\n",
      "Epoch 161/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148147.5000 - mae: 753.6250 - val_loss: 1140315.0000 - val_mae: 754.2293\n",
      "Epoch 162/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147511.7500 - mae: 754.2794 - val_loss: 1141056.0000 - val_mae: 752.4788\n",
      "Epoch 163/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147279.2500 - mae: 753.5733 - val_loss: 1142578.3750 - val_mae: 753.0067\n",
      "Epoch 164/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148153.7500 - mae: 753.2798 - val_loss: 1142774.3750 - val_mae: 752.8600\n",
      "Epoch 165/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148465.7500 - mae: 753.5102 - val_loss: 1140678.5000 - val_mae: 755.0002\n",
      "Epoch 166/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147168.6250 - mae: 754.0522 - val_loss: 1140985.0000 - val_mae: 755.4411\n",
      "Epoch 167/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145802.7500 - mae: 753.0228 - val_loss: 1140894.8750 - val_mae: 754.8568\n",
      "Epoch 168/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147197.7500 - mae: 753.6207 - val_loss: 1139992.6250 - val_mae: 753.5840\n",
      "Epoch 169/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147336.7500 - mae: 754.2480 - val_loss: 1140692.1250 - val_mae: 753.2184\n",
      "Epoch 170/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145724.0000 - mae: 752.4756 - val_loss: 1142402.1250 - val_mae: 755.7476\n",
      "Epoch 171/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146759.8750 - mae: 753.1660 - val_loss: 1141852.8750 - val_mae: 754.4586\n",
      "Epoch 172/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146105.2500 - mae: 753.2354 - val_loss: 1145015.0000 - val_mae: 759.1422\n",
      "Epoch 173/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147381.3750 - mae: 754.6080 - val_loss: 1144820.3750 - val_mae: 753.5175\n",
      "Epoch 174/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146263.5000 - mae: 754.4025 - val_loss: 1142763.6250 - val_mae: 752.1701\n",
      "Epoch 175/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146451.8750 - mae: 752.5092 - val_loss: 1139547.3750 - val_mae: 753.6011\n",
      "Epoch 176/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144419.5000 - mae: 752.5856 - val_loss: 1141470.3750 - val_mae: 752.5316\n",
      "Epoch 177/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1145828.8750 - mae: 752.9944 - val_loss: 1141275.6250 - val_mae: 753.3928\n",
      "Epoch 178/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1144225.6250 - mae: 753.2473 - val_loss: 1144964.3750 - val_mae: 752.4583\n",
      "Epoch 179/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145150.6250 - mae: 753.0433 - val_loss: 1141562.1250 - val_mae: 753.4144\n",
      "Epoch 180/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144499.1250 - mae: 752.1936 - val_loss: 1143432.5000 - val_mae: 752.2728\n",
      "Epoch 181/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144117.7500 - mae: 753.0203 - val_loss: 1144764.0000 - val_mae: 752.7401\n",
      "Epoch 182/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144496.1250 - mae: 752.8572 - val_loss: 1142455.3750 - val_mae: 752.5683\n",
      "Epoch 183/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1143333.6250 - mae: 751.7619 - val_loss: 1140020.2500 - val_mae: 754.6422\n",
      "Epoch 184/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1143380.5000 - mae: 752.9904 - val_loss: 1140111.6250 - val_mae: 753.3490\n",
      "Epoch 185/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1143207.3750 - mae: 752.0161 - val_loss: 1144512.0000 - val_mae: 752.2590\n",
      "Epoch 186/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144549.5000 - mae: 752.5141 - val_loss: 1142530.7500 - val_mae: 753.3015\n",
      "Epoch 187/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1143319.6250 - mae: 752.1262 - val_loss: 1139334.5000 - val_mae: 755.6387\n",
      "Epoch 188/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1143585.7500 - mae: 752.7917 - val_loss: 1143078.6250 - val_mae: 752.9052\n",
      "Epoch 189/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141944.6250 - mae: 751.5516 - val_loss: 1145091.8750 - val_mae: 752.0349\n",
      "Epoch 190/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1143312.7500 - mae: 752.3274 - val_loss: 1139623.8750 - val_mae: 753.1868\n",
      "Epoch 191/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1141876.1250 - mae: 751.7502 - val_loss: 1139115.5000 - val_mae: 754.2015\n",
      "Epoch 192/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1143780.2500 - mae: 752.3740 - val_loss: 1140324.7500 - val_mae: 752.4943\n",
      "Epoch 193/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1143183.3750 - mae: 752.3231 - val_loss: 1141165.1250 - val_mae: 755.9235\n",
      "Epoch 194/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141791.8750 - mae: 752.3529 - val_loss: 1141862.2500 - val_mae: 752.7145\n",
      "Epoch 195/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1141093.7500 - mae: 751.4151 - val_loss: 1142137.1250 - val_mae: 754.1796\n",
      "Epoch 196/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1141832.5000 - mae: 752.0476 - val_loss: 1141207.1250 - val_mae: 752.4836\n",
      "Epoch 197/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1142229.7500 - mae: 751.7910 - val_loss: 1140012.1250 - val_mae: 753.4512\n",
      "Epoch 198/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141397.5000 - mae: 751.7108 - val_loss: 1139459.6250 - val_mae: 754.5854\n",
      "Epoch 199/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141492.0000 - mae: 751.7749 - val_loss: 1141815.0000 - val_mae: 753.6338\n",
      "Epoch 200/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1142180.5000 - mae: 751.9063 - val_loss: 1140058.3750 - val_mae: 753.0388\n",
      "Epoch 201/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140831.2500 - mae: 751.2772 - val_loss: 1139697.2500 - val_mae: 755.3399\n",
      "Epoch 202/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141391.8750 - mae: 752.0258 - val_loss: 1141367.3750 - val_mae: 755.1596\n",
      "Epoch 203/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1139389.0000 - mae: 751.8318 - val_loss: 1144857.1250 - val_mae: 751.9729\n",
      "Epoch 204/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1141131.3750 - mae: 750.8653 - val_loss: 1141144.7500 - val_mae: 752.9080\n",
      "Epoch 205/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141172.3750 - mae: 750.9847 - val_loss: 1138021.1250 - val_mae: 753.6702\n",
      "Epoch 206/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140118.2500 - mae: 751.2809 - val_loss: 1140842.8750 - val_mae: 754.1358\n",
      "Epoch 207/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140007.5000 - mae: 750.4462 - val_loss: 1141086.5000 - val_mae: 756.4611\n",
      "Epoch 208/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1140583.1250 - mae: 751.0446 - val_loss: 1139399.8750 - val_mae: 755.8471\n",
      "Epoch 209/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140510.5000 - mae: 751.7156 - val_loss: 1139564.5000 - val_mae: 754.9653\n",
      "Epoch 210/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138325.7500 - mae: 749.9356 - val_loss: 1139556.8750 - val_mae: 756.7268\n",
      "Epoch 211/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140210.5000 - mae: 752.4627 - val_loss: 1141603.6250 - val_mae: 752.6954\n",
      "Epoch 212/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138967.2500 - mae: 750.4102 - val_loss: 1138935.2500 - val_mae: 754.4109\n",
      "Epoch 213/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139046.8750 - mae: 750.1144 - val_loss: 1141164.8750 - val_mae: 753.9938\n",
      "Epoch 214/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139328.1250 - mae: 751.8418 - val_loss: 1139978.3750 - val_mae: 755.8665\n",
      "Epoch 215/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138413.5000 - mae: 750.6777 - val_loss: 1142812.8750 - val_mae: 752.9203\n",
      "Epoch 216/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139049.8750 - mae: 749.9560 - val_loss: 1140134.1250 - val_mae: 753.1694\n",
      "Epoch 217/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1137809.0000 - mae: 750.0844 - val_loss: 1140094.2500 - val_mae: 754.6585\n",
      "Epoch 218/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139723.7500 - mae: 751.1063 - val_loss: 1141187.2500 - val_mae: 752.6585\n",
      "Epoch 219/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1138286.0000 - mae: 750.5428 - val_loss: 1139617.8750 - val_mae: 753.1921\n",
      "Epoch 220/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137054.0000 - mae: 750.6572 - val_loss: 1140890.7500 - val_mae: 752.7309\n",
      "Epoch 221/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138320.5000 - mae: 750.4832 - val_loss: 1138493.7500 - val_mae: 754.9956\n",
      "Epoch 222/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137156.5000 - mae: 750.6667 - val_loss: 1138840.7500 - val_mae: 754.7949\n",
      "Epoch 223/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137027.5000 - mae: 750.7136 - val_loss: 1143594.5000 - val_mae: 751.8522\n",
      "Epoch 224/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137237.8750 - mae: 749.8382 - val_loss: 1138565.8750 - val_mae: 755.1052\n",
      "Epoch 225/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1136533.1250 - mae: 749.8811 - val_loss: 1140795.8750 - val_mae: 756.7504\n",
      "Epoch 226/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136397.2500 - mae: 750.2456 - val_loss: 1140702.6250 - val_mae: 756.0598\n",
      "Epoch 227/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136634.8750 - mae: 749.8838 - val_loss: 1139980.0000 - val_mae: 755.0958\n",
      "Epoch 228/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136584.7500 - mae: 750.5203 - val_loss: 1139164.5000 - val_mae: 753.5162\n",
      "Epoch 229/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137662.1250 - mae: 749.7479 - val_loss: 1138394.2500 - val_mae: 752.3765\n",
      "Epoch 230/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135588.2500 - mae: 749.5782 - val_loss: 1141699.8750 - val_mae: 752.2032\n",
      "Epoch 231/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135440.2500 - mae: 749.9859 - val_loss: 1146545.0000 - val_mae: 752.6586\n",
      "Epoch 232/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139798.5000 - mae: 751.0975 - val_loss: 1139800.3750 - val_mae: 756.5839\n",
      "Epoch 233/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135348.3750 - mae: 749.0662 - val_loss: 1138592.6250 - val_mae: 753.1845\n",
      "Epoch 234/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135235.6250 - mae: 749.5139 - val_loss: 1139152.3750 - val_mae: 755.0719\n",
      "Epoch 235/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136735.2500 - mae: 750.2028 - val_loss: 1140587.7500 - val_mae: 753.9981\n",
      "Epoch 236/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136020.6250 - mae: 749.1746 - val_loss: 1137919.8750 - val_mae: 754.5264\n",
      "Epoch 237/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134378.5000 - mae: 749.2712 - val_loss: 1138051.0000 - val_mae: 753.9165\n",
      "Epoch 238/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133682.3750 - mae: 749.2094 - val_loss: 1147576.1250 - val_mae: 752.3470\n",
      "Epoch 239/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136198.2500 - mae: 749.3268 - val_loss: 1141746.8750 - val_mae: 752.3991\n",
      "Epoch 240/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135329.0000 - mae: 749.0171 - val_loss: 1139039.2500 - val_mae: 753.4377\n",
      "Epoch 241/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133825.2500 - mae: 749.2164 - val_loss: 1140111.7500 - val_mae: 753.1025\n",
      "Epoch 242/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135014.5000 - mae: 748.6503 - val_loss: 1139022.1250 - val_mae: 755.0750\n",
      "Epoch 243/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133586.7500 - mae: 749.0314 - val_loss: 1140995.2500 - val_mae: 756.7768\n",
      "Epoch 244/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1136002.3750 - mae: 750.4745 - val_loss: 1138866.2500 - val_mae: 752.9719\n",
      "Epoch 245/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133731.7500 - mae: 749.9736 - val_loss: 1139412.2500 - val_mae: 752.2709\n",
      "Epoch 246/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133675.2500 - mae: 748.8339 - val_loss: 1141511.7500 - val_mae: 753.0747\n",
      "Epoch 247/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134496.0000 - mae: 748.9748 - val_loss: 1141167.7500 - val_mae: 753.5895\n",
      "Epoch 248/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134083.8750 - mae: 749.7509 - val_loss: 1138544.3750 - val_mae: 752.7701\n",
      "Epoch 249/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134167.6250 - mae: 748.1151 - val_loss: 1137450.7500 - val_mae: 753.7549\n",
      "Epoch 250/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132741.2500 - mae: 749.2773 - val_loss: 1136955.1250 - val_mae: 754.6931\n",
      "Epoch 251/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134090.1250 - mae: 749.9789 - val_loss: 1141499.1250 - val_mae: 752.2110\n",
      "Epoch 252/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132449.3750 - mae: 749.3256 - val_loss: 1149088.1250 - val_mae: 752.3336\n",
      "Epoch 253/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133284.5000 - mae: 748.3091 - val_loss: 1138902.5000 - val_mae: 752.7120\n",
      "Epoch 254/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133577.6250 - mae: 748.7980 - val_loss: 1139859.3750 - val_mae: 756.3770\n",
      "Epoch 255/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1132637.7500 - mae: 749.1385 - val_loss: 1140358.0000 - val_mae: 753.1455\n",
      "Epoch 256/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132890.3750 - mae: 748.7365 - val_loss: 1138279.6250 - val_mae: 754.5128\n",
      "Epoch 257/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132311.8750 - mae: 748.7734 - val_loss: 1138592.0000 - val_mae: 752.1454\n",
      "Epoch 258/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132505.7500 - mae: 749.3475 - val_loss: 1145318.6250 - val_mae: 752.9938\n",
      "Epoch 259/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131801.0000 - mae: 748.2183 - val_loss: 1138596.6250 - val_mae: 753.1913\n",
      "Epoch 260/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130678.0000 - mae: 748.7609 - val_loss: 1137412.6250 - val_mae: 755.0508\n",
      "Epoch 261/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131789.5000 - mae: 748.8649 - val_loss: 1139334.5000 - val_mae: 753.9067\n",
      "Epoch 262/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131363.0000 - mae: 748.4796 - val_loss: 1138631.1250 - val_mae: 752.8149\n",
      "Epoch 263/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130620.2500 - mae: 747.4926 - val_loss: 1139254.5000 - val_mae: 753.0605\n",
      "Epoch 264/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1130818.0000 - mae: 747.8883 - val_loss: 1142337.7500 - val_mae: 752.5886\n",
      "Epoch 265/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1132161.1250 - mae: 748.4286 - val_loss: 1137647.8750 - val_mae: 754.3665\n",
      "Epoch 266/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130446.7500 - mae: 747.6955 - val_loss: 1139835.0000 - val_mae: 756.8904\n",
      "Epoch 267/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130247.6250 - mae: 749.1488 - val_loss: 1140384.1250 - val_mae: 752.3475\n",
      "Epoch 268/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131475.1250 - mae: 747.8891 - val_loss: 1138951.2500 - val_mae: 752.6484\n",
      "Epoch 269/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130209.6250 - mae: 748.1285 - val_loss: 1139620.1250 - val_mae: 752.6595\n",
      "Epoch 270/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131092.6250 - mae: 748.3202 - val_loss: 1137351.1250 - val_mae: 753.7820\n",
      "Epoch 271/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1130824.2500 - mae: 747.4805 - val_loss: 1139065.3750 - val_mae: 757.4022\n",
      "Epoch 272/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131132.2500 - mae: 748.4924 - val_loss: 1139195.3750 - val_mae: 752.8708\n",
      "Epoch 273/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130622.2500 - mae: 748.1682 - val_loss: 1140155.8750 - val_mae: 753.7084\n",
      "Epoch 274/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128819.5000 - mae: 747.3159 - val_loss: 1138468.6250 - val_mae: 755.0406\n",
      "Epoch 275/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1131302.6250 - mae: 747.8954 - val_loss: 1137864.6250 - val_mae: 754.0081\n",
      "Epoch 276/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1129612.5000 - mae: 747.8004 - val_loss: 1138097.3750 - val_mae: 755.2325\n",
      "Epoch 277/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128316.7500 - mae: 747.4430 - val_loss: 1142918.6250 - val_mae: 752.7483\n",
      "Epoch 278/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128487.7500 - mae: 746.5364 - val_loss: 1137822.5000 - val_mae: 756.1004\n",
      "Epoch 279/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130184.3750 - mae: 747.8007 - val_loss: 1139042.1250 - val_mae: 756.5569\n",
      "Epoch 280/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130480.7500 - mae: 747.6779 - val_loss: 1138487.1250 - val_mae: 754.8151\n",
      "Epoch 281/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1129307.7500 - mae: 748.2836 - val_loss: 1138246.0000 - val_mae: 753.7448\n",
      "Epoch 282/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128745.0000 - mae: 747.1110 - val_loss: 1138469.7500 - val_mae: 754.8064\n",
      "Epoch 283/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1127482.6250 - mae: 747.2599 - val_loss: 1141538.2500 - val_mae: 752.9620\n",
      "Epoch 284/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128208.0000 - mae: 746.7746 - val_loss: 1139618.1250 - val_mae: 752.9484\n",
      "Epoch 285/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127629.8750 - mae: 746.8840 - val_loss: 1136779.2500 - val_mae: 754.6350\n",
      "Epoch 286/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127613.7500 - mae: 746.5854 - val_loss: 1138102.6250 - val_mae: 755.6029\n",
      "Epoch 287/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128540.0000 - mae: 747.6517 - val_loss: 1137754.8750 - val_mae: 753.4479\n",
      "Epoch 288/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127704.2500 - mae: 747.5143 - val_loss: 1140073.2500 - val_mae: 754.3506\n",
      "Epoch 289/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127177.8750 - mae: 746.3811 - val_loss: 1137041.8750 - val_mae: 755.1541\n",
      "Epoch 290/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128283.6250 - mae: 748.1697 - val_loss: 1139665.2500 - val_mae: 751.7449\n",
      "Epoch 291/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127187.6250 - mae: 747.3278 - val_loss: 1135891.2500 - val_mae: 753.7906\n",
      "Epoch 292/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127923.0000 - mae: 747.7332 - val_loss: 1137738.3750 - val_mae: 753.7292\n",
      "Epoch 293/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127793.6250 - mae: 746.9512 - val_loss: 1137893.3750 - val_mae: 753.5436\n",
      "Epoch 294/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126210.7500 - mae: 747.3622 - val_loss: 1142894.8750 - val_mae: 752.4625\n",
      "Epoch 295/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126882.2500 - mae: 746.7318 - val_loss: 1140014.1250 - val_mae: 753.6158\n",
      "Epoch 296/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126653.8750 - mae: 747.2043 - val_loss: 1142204.8750 - val_mae: 753.4510\n",
      "Epoch 297/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127386.2500 - mae: 746.2549 - val_loss: 1139240.6250 - val_mae: 754.9438\n",
      "Epoch 298/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126165.5000 - mae: 746.0999 - val_loss: 1140586.2500 - val_mae: 758.2060\n",
      "Epoch 299/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128890.7500 - mae: 747.9933 - val_loss: 1137548.7500 - val_mae: 753.1024\n",
      "Epoch 300/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125913.0000 - mae: 746.1575 - val_loss: 1141415.1250 - val_mae: 753.2063\n",
      "Epoch 301/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126081.3750 - mae: 746.7723 - val_loss: 1137762.7500 - val_mae: 755.8159\n",
      "Epoch 302/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1127907.5000 - mae: 747.7880 - val_loss: 1136304.2500 - val_mae: 754.0823\n",
      "Epoch 303/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126110.0000 - mae: 746.8828 - val_loss: 1138749.0000 - val_mae: 753.2720\n",
      "Epoch 304/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125779.3750 - mae: 747.8765 - val_loss: 1143679.1250 - val_mae: 752.2392\n",
      "Epoch 305/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125503.2500 - mae: 746.9288 - val_loss: 1146699.5000 - val_mae: 752.4164\n",
      "Epoch 306/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126824.5000 - mae: 745.9457 - val_loss: 1136424.6250 - val_mae: 753.6317\n",
      "Epoch 307/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126261.7500 - mae: 745.8358 - val_loss: 1136853.2500 - val_mae: 754.3926\n",
      "Epoch 308/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126347.0000 - mae: 747.1825 - val_loss: 1137310.3750 - val_mae: 753.7889\n",
      "Epoch 309/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122999.1250 - mae: 744.6379 - val_loss: 1139542.6250 - val_mae: 758.8287\n",
      "Epoch 310/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1128521.8750 - mae: 747.4343 - val_loss: 1136361.3750 - val_mae: 753.9776\n",
      "Epoch 311/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125641.6250 - mae: 745.8194 - val_loss: 1137630.8750 - val_mae: 754.6316\n",
      "Epoch 312/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125731.8750 - mae: 747.9788 - val_loss: 1138485.6250 - val_mae: 754.5178\n",
      "Epoch 313/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126041.8750 - mae: 746.4983 - val_loss: 1139532.8750 - val_mae: 753.9330\n",
      "Epoch 314/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125916.5000 - mae: 745.9181 - val_loss: 1138889.1250 - val_mae: 754.9615\n",
      "Epoch 315/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1126827.0000 - mae: 747.3271 - val_loss: 1143426.0000 - val_mae: 759.5360\n",
      "Epoch 316/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123668.7500 - mae: 745.3458 - val_loss: 1137798.0000 - val_mae: 755.6819\n",
      "Epoch 317/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124979.3750 - mae: 746.7680 - val_loss: 1139065.2500 - val_mae: 753.0743\n",
      "Epoch 318/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125370.3750 - mae: 746.3235 - val_loss: 1139255.0000 - val_mae: 756.4291\n",
      "Epoch 319/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124222.3750 - mae: 746.2113 - val_loss: 1139256.5000 - val_mae: 753.9408\n",
      "Epoch 320/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123610.1250 - mae: 745.9888 - val_loss: 1140129.0000 - val_mae: 754.2021\n",
      "Epoch 321/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123899.3750 - mae: 746.1392 - val_loss: 1139690.3750 - val_mae: 753.7794\n",
      "Epoch 322/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123001.5000 - mae: 744.8992 - val_loss: 1138222.3750 - val_mae: 756.8291\n",
      "Epoch 323/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124517.2500 - mae: 745.5135 - val_loss: 1138963.3750 - val_mae: 755.5328\n",
      "Epoch 324/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123557.1250 - mae: 746.0544 - val_loss: 1136707.8750 - val_mae: 754.1722\n",
      "Epoch 325/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125268.3750 - mae: 746.7826 - val_loss: 1138092.6250 - val_mae: 754.1691\n",
      "Epoch 326/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123767.0000 - mae: 745.0710 - val_loss: 1137009.6250 - val_mae: 754.2814\n",
      "Epoch 327/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1124168.3750 - mae: 745.4894 - val_loss: 1139719.3750 - val_mae: 754.2111\n",
      "Epoch 328/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1122913.5000 - mae: 745.9930 - val_loss: 1140515.1250 - val_mae: 754.1125\n",
      "Epoch 329/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1125272.5000 - mae: 746.0883 - val_loss: 1139076.3750 - val_mae: 755.2457\n",
      "Epoch 330/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123234.7500 - mae: 745.4655 - val_loss: 1138772.2500 - val_mae: 753.4870\n",
      "Epoch 331/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123232.7500 - mae: 745.3853 - val_loss: 1137975.7500 - val_mae: 754.4667\n",
      "Epoch 332/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123040.3750 - mae: 745.7234 - val_loss: 1139513.7500 - val_mae: 755.8618\n",
      "Epoch 333/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122830.7500 - mae: 745.8931 - val_loss: 1137849.8750 - val_mae: 755.2008\n",
      "Epoch 334/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122207.2500 - mae: 744.8118 - val_loss: 1139988.6250 - val_mae: 756.6445\n",
      "Epoch 335/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1123033.8750 - mae: 745.8058 - val_loss: 1140940.6250 - val_mae: 756.9203\n",
      "Epoch 336/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122164.3750 - mae: 744.7123 - val_loss: 1139480.1250 - val_mae: 756.0726\n",
      "Epoch 337/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121576.3750 - mae: 745.6889 - val_loss: 1139112.6250 - val_mae: 754.0567\n",
      "Epoch 338/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122520.1250 - mae: 745.4460 - val_loss: 1142847.2500 - val_mae: 753.3780\n",
      "Epoch 339/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122880.3750 - mae: 744.9963 - val_loss: 1139117.5000 - val_mae: 756.8986\n",
      "Epoch 340/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122390.2500 - mae: 745.0678 - val_loss: 1141989.6250 - val_mae: 757.7040\n",
      "Epoch 341/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122735.7500 - mae: 746.1599 - val_loss: 1141525.7500 - val_mae: 754.2486\n",
      "Epoch 342/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121931.6250 - mae: 745.1208 - val_loss: 1139467.7500 - val_mae: 755.0843\n",
      "Epoch 343/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121839.5000 - mae: 745.9388 - val_loss: 1137722.1250 - val_mae: 755.4320\n",
      "Epoch 344/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122562.5000 - mae: 744.7765 - val_loss: 1140435.2500 - val_mae: 753.9123\n",
      "Epoch 345/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122575.5000 - mae: 744.6086 - val_loss: 1139593.5000 - val_mae: 756.7606\n",
      "Epoch 346/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121537.1250 - mae: 745.2979 - val_loss: 1139207.0000 - val_mae: 755.2742\n",
      "Epoch 347/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121255.2500 - mae: 746.5982 - val_loss: 1137798.8750 - val_mae: 755.3952\n",
      "Epoch 348/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121571.1250 - mae: 745.7032 - val_loss: 1140486.2500 - val_mae: 756.2644\n",
      "Epoch 349/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120602.2500 - mae: 744.9422 - val_loss: 1139423.6250 - val_mae: 754.8033\n",
      "Epoch 350/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120420.3750 - mae: 744.5123 - val_loss: 1139479.7500 - val_mae: 755.6318\n",
      "Epoch 351/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120334.8750 - mae: 745.1387 - val_loss: 1139622.5000 - val_mae: 754.3568\n",
      "Epoch 352/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121192.1250 - mae: 743.4891 - val_loss: 1140959.7500 - val_mae: 758.5895\n",
      "Epoch 353/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1122022.0000 - mae: 746.3111 - val_loss: 1138647.0000 - val_mae: 754.2495\n",
      "Epoch 354/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120359.6250 - mae: 744.1965 - val_loss: 1138278.0000 - val_mae: 754.6137\n",
      "Epoch 355/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119981.2500 - mae: 744.4734 - val_loss: 1139931.7500 - val_mae: 756.4263\n",
      "Epoch 356/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120355.2500 - mae: 744.4441 - val_loss: 1141256.8750 - val_mae: 754.4411\n",
      "Epoch 357/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120291.2500 - mae: 744.5228 - val_loss: 1138662.8750 - val_mae: 754.9785\n",
      "Epoch 358/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119603.0000 - mae: 744.4289 - val_loss: 1142226.2500 - val_mae: 753.7755\n",
      "Epoch 359/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119274.1250 - mae: 744.0448 - val_loss: 1139955.5000 - val_mae: 754.9623\n",
      "Epoch 360/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1120148.2500 - mae: 743.8732 - val_loss: 1139906.8750 - val_mae: 753.8909\n",
      "Epoch 361/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1119375.0000 - mae: 744.4446 - val_loss: 1140351.3750 - val_mae: 755.3558\n",
      "Epoch 362/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1121328.7500 - mae: 744.9976 - val_loss: 1139571.5000 - val_mae: 755.4976\n",
      "Epoch 363/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119094.6250 - mae: 744.0193 - val_loss: 1139826.3750 - val_mae: 755.4929\n",
      "Epoch 364/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119457.8750 - mae: 744.1248 - val_loss: 1139073.6250 - val_mae: 754.3688\n",
      "Epoch 365/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119012.3750 - mae: 743.9798 - val_loss: 1140049.3750 - val_mae: 755.5769\n",
      "Epoch 366/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118168.3750 - mae: 744.2578 - val_loss: 1139946.1250 - val_mae: 753.6989\n",
      "Epoch 367/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1117926.1250 - mae: 743.0824 - val_loss: 1140469.5000 - val_mae: 756.2272\n",
      "Epoch 368/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118731.0000 - mae: 743.6424 - val_loss: 1140093.8750 - val_mae: 754.4683\n",
      "Epoch 369/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1117544.8750 - mae: 744.0973 - val_loss: 1142105.1250 - val_mae: 754.0364\n",
      "Epoch 370/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1119715.5000 - mae: 744.3744 - val_loss: 1138903.7500 - val_mae: 755.8679\n",
      "Epoch 371/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118503.5000 - mae: 744.1147 - val_loss: 1137913.8750 - val_mae: 755.2013\n",
      "Epoch 372/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1118387.0000 - mae: 743.2989 - val_loss: 1140289.1250 - val_mae: 756.2881\n",
      "Epoch 373/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118567.2500 - mae: 744.1677 - val_loss: 1141179.7500 - val_mae: 755.8287\n",
      "Epoch 374/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117294.2500 - mae: 743.4402 - val_loss: 1140638.0000 - val_mae: 754.8276\n",
      "Epoch 375/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1118944.3750 - mae: 744.1075 - val_loss: 1140883.5000 - val_mae: 756.0294\n",
      "Epoch 376/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117298.1250 - mae: 743.3760 - val_loss: 1139314.2500 - val_mae: 755.0694\n",
      "Epoch 377/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117479.1250 - mae: 744.1470 - val_loss: 1140286.3750 - val_mae: 754.7322\n",
      "Epoch 378/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1117807.1250 - mae: 743.7602 - val_loss: 1141870.2500 - val_mae: 755.5272\n",
      "Epoch 379/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117104.0000 - mae: 743.3621 - val_loss: 1141107.1250 - val_mae: 754.9507\n",
      "Epoch 380/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116905.5000 - mae: 743.6329 - val_loss: 1142384.7500 - val_mae: 754.1964\n",
      "Epoch 381/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1118446.7500 - mae: 743.3156 - val_loss: 1139140.2500 - val_mae: 755.2571\n",
      "Epoch 382/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1116316.1250 - mae: 744.1589 - val_loss: 1143962.8750 - val_mae: 754.2763\n",
      "Epoch 383/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1117186.5000 - mae: 743.3179 - val_loss: 1140460.2500 - val_mae: 756.6971\n",
      "Epoch 384/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1116082.7500 - mae: 743.0349 - val_loss: 1143055.3750 - val_mae: 754.4499\n",
      "Epoch 385/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1116632.8750 - mae: 743.4757 - val_loss: 1141455.7500 - val_mae: 756.9286\n",
      "Epoch 386/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1115896.3750 - mae: 743.2141 - val_loss: 1139910.6250 - val_mae: 756.7031\n",
      "Epoch 387/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1116004.0000 - mae: 743.4459 - val_loss: 1140078.6250 - val_mae: 756.0512\n",
      "Epoch 388/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1115108.5000 - mae: 742.6552 - val_loss: 1142263.7500 - val_mae: 758.0497\n",
      "Epoch 389/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1117683.5000 - mae: 743.9351 - val_loss: 1140907.2500 - val_mae: 755.9401\n",
      "Epoch 390/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1115951.5000 - mae: 742.6850 - val_loss: 1144100.0000 - val_mae: 755.3934\n",
      "Epoch 391/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1115178.7500 - mae: 743.0667 - val_loss: 1142482.7500 - val_mae: 754.9861\n",
      "Epoch 392/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1115254.6250 - mae: 742.1679 - val_loss: 1140039.8750 - val_mae: 755.7690\n",
      "Epoch 393/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1115061.8750 - mae: 743.4167 - val_loss: 1143585.0000 - val_mae: 753.5248\n",
      "Epoch 394/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116948.2500 - mae: 743.0321 - val_loss: 1139872.6250 - val_mae: 754.4283\n",
      "Epoch 395/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1116640.3750 - mae: 743.9557 - val_loss: 1142761.1250 - val_mae: 754.5040\n",
      "Epoch 396/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1115286.6250 - mae: 742.1538 - val_loss: 1140835.3750 - val_mae: 754.9969\n",
      "Epoch 397/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114340.6250 - mae: 742.6647 - val_loss: 1141585.0000 - val_mae: 754.7777\n",
      "Epoch 398/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114622.1250 - mae: 741.7959 - val_loss: 1143416.7500 - val_mae: 759.7017\n",
      "Epoch 399/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114466.7500 - mae: 742.8055 - val_loss: 1141894.2500 - val_mae: 754.4179\n",
      "Epoch 400/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1114159.1250 - mae: 742.7054 - val_loss: 1141430.1250 - val_mae: 756.1995\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "# passing the independent and dependent features for training set for training the model\n",
    "\n",
    "# validation data will be evaluated at the end of each epoch\n",
    "\n",
    "# setting the epochs as 50\n",
    "\n",
    "# storing the trained model in model_history variable which will be used to visualize the training process\n",
    "\n",
    "model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 973us/step - loss: 1141430.1250 - mae: 756.1995\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 730us/step\n",
      "R2 Score: 0.6046330932654591\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model_history.history['mae'])\n",
    "plt.plot(model_history.history['val_mae'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.605356359282686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
