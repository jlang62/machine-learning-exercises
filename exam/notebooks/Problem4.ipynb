{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv('../data/deep_learning_task_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            5000 non-null   object \n",
      " 1   Item_Weight                4182 non-null   float64\n",
      " 2   Item_Fat_Content           5000 non-null   object \n",
      " 3   Item_Visibility            5000 non-null   float64\n",
      " 4   Item_Type                  5000 non-null   object \n",
      " 5   Item_MRP                   5000 non-null   float64\n",
      " 6   Outlet_Identifier          5000 non-null   object \n",
      " 7   Outlet_Establishment_Year  5000 non-null   int64  \n",
      " 8   Outlet_Size                3561 non-null   object \n",
      " 9   Outlet_Location_Type       5000 non-null   object \n",
      " 10  Outlet_Type                5000 non-null   object \n",
      " 11  Item_Outlet_Sales          5000 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                   818\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  1439\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/pk9yd5v978d_6j_wky4ptw480000gn/T/ipykernel_28464/889244835.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df.fillna(df.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# fill the missing values with the mean of the column\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df['Outlet_Size'].fillna(df['Outlet_Size'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    3044\n",
       "Small     1398\n",
       "High       558\n",
       "Name: Outlet_Size, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Outlet_Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat' 'Regular' 'low fat' 'LF' 'reg']\n",
      "['Dairy' 'Soft Drinks' 'Meat' 'Fruits and Vegetables' 'Household'\n",
      " 'Baking Goods' 'Snack Foods' 'Frozen Foods' 'Breakfast'\n",
      " 'Health and Hygiene' 'Hard Drinks' 'Canned' 'Breads' 'Starchy Foods'\n",
      " 'Others' 'Seafood']\n",
      "['Medium' 'High' 'Small']\n",
      "['Tier 1' 'Tier 3' 'Tier 2']\n",
      "['OUT049' 'OUT018' 'OUT010' 'OUT013' 'OUT027' 'OUT045' 'OUT017' 'OUT046'\n",
      " 'OUT035' 'OUT019']\n"
     ]
    }
   ],
   "source": [
    "print(df['Item_Fat_Content'].unique())\n",
    "print(df['Item_Type'].unique())\n",
    "print(df['Outlet_Size'].unique())\n",
    "print(df['Outlet_Location_Type'].unique())\n",
    "print(df['Outlet_Identifier'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998      Medium               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Item_Fat_Content'] = le.fit_transform(df['Item_Fat_Content'])\n",
    "df['Item_Type'] = le.fit_transform(df['Item_Type'])\n",
    "df['Outlet_Size'] = le.fit_transform(df['Outlet_Size'])\n",
    "df['Outlet_Location_Type'] = le.fit_transform(df['Outlet_Location_Type'])\n",
    "df['Outlet_Identifier'] = le.fit_transform(df['Outlet_Identifier'])\n",
    "df['Outlet_Type'] = le.fit_transform(df['Outlet_Type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>4</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>9</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>14</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>10</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>9</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight  Item_Fat_Content  Item_Visibility  Item_Type  \\\n",
       "0           FDA15         9.30                 1         0.016047          4   \n",
       "1           DRC01         5.92                 2         0.019278         14   \n",
       "2           FDN15        17.50                 1         0.016760         10   \n",
       "3           FDX07        19.20                 2         0.000000          6   \n",
       "4           NCD19         8.93                 1         0.000000          9   \n",
       "\n",
       "   Item_MRP  Outlet_Identifier  Outlet_Establishment_Year  Outlet_Size  \\\n",
       "0  249.8092                  9                       1999            1   \n",
       "1   48.2692                  3                       2009            1   \n",
       "2  141.6180                  9                       1999            1   \n",
       "3  182.0950                  0                       1998            1   \n",
       "4   53.8614                  1                       1987            0   \n",
       "\n",
       "   Outlet_Location_Type  Outlet_Type  Item_Outlet_Sales  \n",
       "0                     0            1          3735.1380  \n",
       "1                     2            2           443.4228  \n",
       "2                     0            1          2097.2700  \n",
       "3                     2            0           732.3800  \n",
       "4                     2            1           994.7052  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>4</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.92</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>14</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>10</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Fat_Content  Item_Visibility  Item_Type  Item_MRP  \\\n",
       "0         9.30                 1         0.016047          4  249.8092   \n",
       "1         5.92                 2         0.019278         14   48.2692   \n",
       "2        17.50                 1         0.016760         10  141.6180   \n",
       "3        19.20                 2         0.000000          6  182.0950   \n",
       "4         8.93                 1         0.000000          9   53.8614   \n",
       "\n",
       "   Outlet_Identifier  Outlet_Size  Outlet_Location_Type  Outlet_Type  \\\n",
       "0                  9            1                     0            1   \n",
       "1                  3            1                     2            2   \n",
       "2                  9            1                     0            1   \n",
       "3                  0            1                     2            0   \n",
       "4                  1            0                     2            1   \n",
       "\n",
       "   Item_Outlet_Sales  \n",
       "0          3735.1380  \n",
       "1           443.4228  \n",
       "2          2097.2700  \n",
       "3           732.3800  \n",
       "4           994.7052  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Item_Identifier', 'Outlet_Establishment_Year'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Item_Outlet_Sales'], axis=1)\n",
    "y = df['Item_Outlet_Sales']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 9), (5000,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((4000, 9), (4000,)), ((1000, 9), (1000,)))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation set\n",
    "\n",
    "# stratify will make sure that the distribution of classes in train and validation set it similar\n",
    "# random state to regenerate the same train and validation set\n",
    "# test size 0.2 will keep 20% data in validation and remaining 80% in train set\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=10,test_size=0.2)\n",
    "\n",
    "# shape of training and validation set\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the sequential model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# importing different layers from keras\n",
    "from keras.layers import InputLayer, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of input neurons\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features in the data\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining input neurons\n",
    "input_neurons = X_train.shape[1]\n",
    "input_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of output neurons\n",
    "output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hidden layers and neuron in each layer\n",
    "number_of_hidden_layers = 2\n",
    "neuron_hidden_layer_1 = 20\n",
    "neuron_hidden_layer_2 = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 20)                200       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 421 (1.64 KB)\n",
      "Trainable params: 421 (1.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the architecture of the model\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=(input_neurons)))\n",
    "model.add(Dense(units=neuron_hidden_layer_1, activation='relu'))\n",
    "model.add(Dense(units=neuron_hidden_layer_2, activation='relu'))\n",
    "# model.add(Dense(units=neuron_hidden_layer_3, activation='relu'))\n",
    "model.add(Dense(units=output_neurons, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 7507944.5000 - mae: 2152.6079 - val_loss: 7390119.5000 - val_mae: 2129.3633\n",
      "Epoch 2/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 6429356.5000 - mae: 1937.6523 - val_loss: 5411020.5000 - val_mae: 1737.8484\n",
      "Epoch 3/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3800907.7500 - mae: 1403.7450 - val_loss: 2588318.2500 - val_mae: 1169.7527\n",
      "Epoch 4/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2118734.0000 - mae: 1054.8809 - val_loss: 1997210.3750 - val_mae: 1052.9968\n",
      "Epoch 5/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1941424.6250 - mae: 1037.1759 - val_loss: 1984700.3750 - val_mae: 1053.6396\n",
      "Epoch 6/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1934871.3750 - mae: 1035.7435 - val_loss: 1980872.7500 - val_mae: 1054.7767\n",
      "Epoch 7/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1931086.5000 - mae: 1035.9043 - val_loss: 1976743.8750 - val_mae: 1052.9841\n",
      "Epoch 8/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1927189.8750 - mae: 1035.0250 - val_loss: 1973020.0000 - val_mae: 1049.8903\n",
      "Epoch 9/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1923355.7500 - mae: 1032.8912 - val_loss: 1968612.6250 - val_mae: 1049.1976\n",
      "Epoch 10/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1918589.5000 - mae: 1030.6262 - val_loss: 1964786.5000 - val_mae: 1049.0394\n",
      "Epoch 11/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1914684.1250 - mae: 1030.5658 - val_loss: 1961240.1250 - val_mae: 1048.5039\n",
      "Epoch 12/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1910911.3750 - mae: 1028.9618 - val_loss: 1956604.0000 - val_mae: 1046.3584\n",
      "Epoch 13/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1906516.1250 - mae: 1027.2463 - val_loss: 1953535.6250 - val_mae: 1046.4426\n",
      "Epoch 14/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1902413.2500 - mae: 1026.7279 - val_loss: 1948019.2500 - val_mae: 1042.8812\n",
      "Epoch 15/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1898642.0000 - mae: 1025.4114 - val_loss: 1943867.3750 - val_mae: 1040.3588\n",
      "Epoch 16/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1895096.7500 - mae: 1023.7548 - val_loss: 1940574.2500 - val_mae: 1038.2283\n",
      "Epoch 17/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1888697.2500 - mae: 1020.5201 - val_loss: 1938431.6250 - val_mae: 1042.3864\n",
      "Epoch 18/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1885043.3750 - mae: 1021.0621 - val_loss: 1932073.8750 - val_mae: 1038.6570\n",
      "Epoch 19/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1880639.2500 - mae: 1019.3649 - val_loss: 1927026.0000 - val_mae: 1035.0188\n",
      "Epoch 20/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1878742.3750 - mae: 1018.4970 - val_loss: 1922762.6250 - val_mae: 1034.3875\n",
      "Epoch 21/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1872475.1250 - mae: 1016.5460 - val_loss: 1919310.0000 - val_mae: 1034.3226\n",
      "Epoch 22/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1868171.7500 - mae: 1015.3499 - val_loss: 1914505.7500 - val_mae: 1032.0570\n",
      "Epoch 23/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1863671.8750 - mae: 1014.3101 - val_loss: 1910445.7500 - val_mae: 1031.0985\n",
      "Epoch 24/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1859354.8750 - mae: 1012.3036 - val_loss: 1906662.1250 - val_mae: 1030.4263\n",
      "Epoch 25/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1854809.6250 - mae: 1012.3079 - val_loss: 1901388.5000 - val_mae: 1026.6780\n",
      "Epoch 26/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1851655.5000 - mae: 1010.9515 - val_loss: 1896992.6250 - val_mae: 1026.0972\n",
      "Epoch 27/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1846762.0000 - mae: 1008.8527 - val_loss: 1895516.8750 - val_mae: 1028.3328\n",
      "Epoch 28/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1842646.8750 - mae: 1008.2521 - val_loss: 1888592.6250 - val_mae: 1024.2228\n",
      "Epoch 29/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1837590.5000 - mae: 1006.5064 - val_loss: 1883769.0000 - val_mae: 1022.3702\n",
      "Epoch 30/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1833821.6250 - mae: 1005.4978 - val_loss: 1882263.5000 - val_mae: 1024.1954\n",
      "Epoch 31/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1829074.5000 - mae: 1004.6590 - val_loss: 1874604.8750 - val_mae: 1018.7123\n",
      "Epoch 32/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1823882.0000 - mae: 1002.5706 - val_loss: 1871594.7500 - val_mae: 1020.0210\n",
      "Epoch 33/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1820143.2500 - mae: 1001.5222 - val_loss: 1866094.8750 - val_mae: 1017.7260\n",
      "Epoch 34/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1814624.2500 - mae: 1000.9444 - val_loss: 1862510.3750 - val_mae: 1013.7310\n",
      "Epoch 35/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1810702.2500 - mae: 998.6278 - val_loss: 1856283.6250 - val_mae: 1013.7283\n",
      "Epoch 36/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1805802.2500 - mae: 996.8363 - val_loss: 1854575.8750 - val_mae: 1015.8833\n",
      "Epoch 37/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1800907.8750 - mae: 996.5467 - val_loss: 1847208.1250 - val_mae: 1012.1200\n",
      "Epoch 38/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1796280.3750 - mae: 995.3958 - val_loss: 1842163.8750 - val_mae: 1010.4810\n",
      "Epoch 39/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1792852.0000 - mae: 994.2284 - val_loss: 1839473.0000 - val_mae: 1011.2446\n",
      "Epoch 40/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1786475.8750 - mae: 994.7623 - val_loss: 1832221.5000 - val_mae: 1006.5546\n",
      "Epoch 41/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1780789.7500 - mae: 989.3860 - val_loss: 1831127.1250 - val_mae: 1009.5974\n",
      "Epoch 42/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1779359.3750 - mae: 992.0401 - val_loss: 1822296.1250 - val_mae: 1003.8226\n",
      "Epoch 43/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1771137.6250 - mae: 988.5654 - val_loss: 1817527.3750 - val_mae: 1003.9535\n",
      "Epoch 44/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1765536.2500 - mae: 987.4504 - val_loss: 1811962.8750 - val_mae: 1001.5361\n",
      "Epoch 45/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1761163.0000 - mae: 986.3273 - val_loss: 1806815.6250 - val_mae: 1000.4785\n",
      "Epoch 46/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1756016.0000 - mae: 985.3027 - val_loss: 1801983.6250 - val_mae: 999.8726\n",
      "Epoch 47/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1749601.0000 - mae: 983.6286 - val_loss: 1796739.5000 - val_mae: 995.7808\n",
      "Epoch 48/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1743735.5000 - mae: 980.7150 - val_loss: 1792473.6250 - val_mae: 998.2424\n",
      "Epoch 49/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1741740.0000 - mae: 981.9412 - val_loss: 1785136.1250 - val_mae: 994.6020\n",
      "Epoch 50/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1733766.3750 - mae: 979.0366 - val_loss: 1779464.7500 - val_mae: 991.6777\n",
      "Epoch 51/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1727471.6250 - mae: 978.4629 - val_loss: 1773807.7500 - val_mae: 990.8115\n",
      "Epoch 52/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1721372.8750 - mae: 975.8586 - val_loss: 1770469.8750 - val_mae: 992.9807\n",
      "Epoch 53/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1715376.0000 - mae: 974.8439 - val_loss: 1762062.5000 - val_mae: 987.8088\n",
      "Epoch 54/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1710914.3750 - mae: 971.2134 - val_loss: 1759394.1250 - val_mae: 990.5449\n",
      "Epoch 55/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1706491.2500 - mae: 975.5845 - val_loss: 1750421.2500 - val_mae: 984.4355\n",
      "Epoch 56/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1698599.3750 - mae: 969.9581 - val_loss: 1745391.1250 - val_mae: 985.1179\n",
      "Epoch 57/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1693020.7500 - mae: 969.3866 - val_loss: 1740276.7500 - val_mae: 984.5795\n",
      "Epoch 58/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1686053.1250 - mae: 968.3747 - val_loss: 1732892.7500 - val_mae: 980.7517\n",
      "Epoch 59/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1682151.2500 - mae: 966.3039 - val_loss: 1726779.0000 - val_mae: 978.9861\n",
      "Epoch 60/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1673390.5000 - mae: 965.3044 - val_loss: 1721251.6250 - val_mae: 974.7981\n",
      "Epoch 61/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1668689.3750 - mae: 961.7879 - val_loss: 1715957.2500 - val_mae: 977.9514\n",
      "Epoch 62/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1661072.0000 - mae: 961.3218 - val_loss: 1709023.3750 - val_mae: 975.4186\n",
      "Epoch 63/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1654519.3750 - mae: 960.7433 - val_loss: 1702018.8750 - val_mae: 971.2484\n",
      "Epoch 64/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1649929.1250 - mae: 958.0273 - val_loss: 1695885.7500 - val_mae: 969.6145\n",
      "Epoch 65/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1642407.7500 - mae: 957.7217 - val_loss: 1689618.7500 - val_mae: 968.4316\n",
      "Epoch 66/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1638074.5000 - mae: 955.9440 - val_loss: 1683186.0000 - val_mae: 967.0314\n",
      "Epoch 67/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1629720.6250 - mae: 955.3759 - val_loss: 1676679.1250 - val_mae: 964.0834\n",
      "Epoch 68/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1623503.3750 - mae: 951.7360 - val_loss: 1669734.3750 - val_mae: 964.4020\n",
      "Epoch 69/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1618133.7500 - mae: 950.9793 - val_loss: 1664286.1250 - val_mae: 960.1022\n",
      "Epoch 70/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1611666.3750 - mae: 948.3248 - val_loss: 1656936.1250 - val_mae: 959.8734\n",
      "Epoch 71/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1603223.7500 - mae: 946.8956 - val_loss: 1651127.3750 - val_mae: 960.5615\n",
      "Epoch 72/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1597228.2500 - mae: 947.6884 - val_loss: 1644915.7500 - val_mae: 955.8852\n",
      "Epoch 73/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1590234.8750 - mae: 943.8904 - val_loss: 1639006.7500 - val_mae: 953.6077\n",
      "Epoch 74/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1583106.0000 - mae: 943.5620 - val_loss: 1632439.7500 - val_mae: 953.7627\n",
      "Epoch 75/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1580293.1250 - mae: 940.5051 - val_loss: 1627044.1250 - val_mae: 953.8549\n",
      "Epoch 76/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1572391.8750 - mae: 939.5263 - val_loss: 1625973.5000 - val_mae: 957.7043\n",
      "Epoch 77/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1564628.7500 - mae: 937.8168 - val_loss: 1615583.8750 - val_mae: 949.2625\n",
      "Epoch 78/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1559180.3750 - mae: 937.1374 - val_loss: 1610664.3750 - val_mae: 946.5751\n",
      "Epoch 79/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1554641.7500 - mae: 933.5543 - val_loss: 1606372.0000 - val_mae: 950.2973\n",
      "Epoch 80/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1549684.1250 - mae: 934.0047 - val_loss: 1603390.7500 - val_mae: 951.1694\n",
      "Epoch 81/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1542913.1250 - mae: 934.3339 - val_loss: 1595040.7500 - val_mae: 944.2360\n",
      "Epoch 82/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1539443.6250 - mae: 930.8639 - val_loss: 1591053.8750 - val_mae: 945.5505\n",
      "Epoch 83/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1535557.7500 - mae: 930.3118 - val_loss: 1586991.2500 - val_mae: 945.1994\n",
      "Epoch 84/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1528448.7500 - mae: 928.3987 - val_loss: 1587881.2500 - val_mae: 949.1537\n",
      "Epoch 85/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1524018.1250 - mae: 927.9818 - val_loss: 1579277.0000 - val_mae: 937.4844\n",
      "Epoch 86/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1519166.5000 - mae: 926.4425 - val_loss: 1573781.8750 - val_mae: 938.3862\n",
      "Epoch 87/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1516628.5000 - mae: 925.9910 - val_loss: 1569772.8750 - val_mae: 938.3417\n",
      "Epoch 88/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1512702.0000 - mae: 923.4462 - val_loss: 1566490.8750 - val_mae: 936.3921\n",
      "Epoch 89/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1507399.2500 - mae: 921.6528 - val_loss: 1567778.2500 - val_mae: 943.5930\n",
      "Epoch 90/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1504126.2500 - mae: 923.3127 - val_loss: 1560043.3750 - val_mae: 937.3737\n",
      "Epoch 91/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1501918.5000 - mae: 920.4423 - val_loss: 1557371.6250 - val_mae: 937.2678\n",
      "Epoch 92/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1498050.5000 - mae: 920.1543 - val_loss: 1555699.8750 - val_mae: 930.4662\n",
      "Epoch 93/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1491670.2500 - mae: 915.6456 - val_loss: 1552958.8750 - val_mae: 937.4450\n",
      "Epoch 94/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1490283.7500 - mae: 917.6760 - val_loss: 1547653.1250 - val_mae: 932.1890\n",
      "Epoch 95/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1486154.8750 - mae: 914.9030 - val_loss: 1547419.8750 - val_mae: 935.6923\n",
      "Epoch 96/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1484796.8750 - mae: 915.3323 - val_loss: 1546096.8750 - val_mae: 926.0756\n",
      "Epoch 97/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1481500.2500 - mae: 914.3960 - val_loss: 1549313.2500 - val_mae: 923.2985\n",
      "Epoch 98/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1479581.7500 - mae: 910.5487 - val_loss: 1541149.8750 - val_mae: 934.4503\n",
      "Epoch 99/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1473830.0000 - mae: 912.0619 - val_loss: 1536168.7500 - val_mae: 924.4698\n",
      "Epoch 100/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1468542.8750 - mae: 907.3918 - val_loss: 1533825.6250 - val_mae: 930.5317\n",
      "Epoch 101/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1468753.2500 - mae: 909.5226 - val_loss: 1529532.6250 - val_mae: 927.2072\n",
      "Epoch 102/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1465355.0000 - mae: 906.1087 - val_loss: 1534520.8750 - val_mae: 934.0984\n",
      "Epoch 103/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1465881.3750 - mae: 907.2405 - val_loss: 1524885.8750 - val_mae: 926.1675\n",
      "Epoch 104/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1458811.7500 - mae: 905.5140 - val_loss: 1521156.7500 - val_mae: 921.1115\n",
      "Epoch 105/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1456615.1250 - mae: 903.8401 - val_loss: 1518381.6250 - val_mae: 920.4617\n",
      "Epoch 106/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1453695.5000 - mae: 902.5659 - val_loss: 1521775.6250 - val_mae: 914.9851\n",
      "Epoch 107/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1451095.6250 - mae: 899.4053 - val_loss: 1513667.2500 - val_mae: 916.3620\n",
      "Epoch 108/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1447870.7500 - mae: 899.4203 - val_loss: 1512093.0000 - val_mae: 920.6395\n",
      "Epoch 109/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1444166.0000 - mae: 898.2056 - val_loss: 1508452.5000 - val_mae: 913.5216\n",
      "Epoch 110/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1441933.6250 - mae: 896.5750 - val_loss: 1506046.5000 - val_mae: 911.8328\n",
      "Epoch 111/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1439572.7500 - mae: 894.9807 - val_loss: 1501540.0000 - val_mae: 912.3152\n",
      "Epoch 112/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1434042.6250 - mae: 892.8284 - val_loss: 1500980.8750 - val_mae: 916.6442\n",
      "Epoch 113/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1429930.7500 - mae: 892.5711 - val_loss: 1498774.7500 - val_mae: 903.6174\n",
      "Epoch 114/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1423795.1250 - mae: 887.3813 - val_loss: 1490912.5000 - val_mae: 910.3217\n",
      "Epoch 115/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1419497.0000 - mae: 886.7109 - val_loss: 1490031.3750 - val_mae: 900.6181\n",
      "Epoch 116/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1417750.2500 - mae: 886.5715 - val_loss: 1486755.1250 - val_mae: 899.1531\n",
      "Epoch 117/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1413248.8750 - mae: 883.6933 - val_loss: 1480241.8750 - val_mae: 899.6416\n",
      "Epoch 118/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1408595.5000 - mae: 880.2486 - val_loss: 1478488.2500 - val_mae: 896.4695\n",
      "Epoch 119/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1403007.0000 - mae: 879.4199 - val_loss: 1473618.5000 - val_mae: 900.7908\n",
      "Epoch 120/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1400349.8750 - mae: 879.3024 - val_loss: 1470680.5000 - val_mae: 894.0735\n",
      "Epoch 121/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1398251.7500 - mae: 874.7659 - val_loss: 1466399.0000 - val_mae: 896.3506\n",
      "Epoch 122/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1395980.2500 - mae: 874.8844 - val_loss: 1465318.7500 - val_mae: 888.9092\n",
      "Epoch 123/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1390237.8750 - mae: 872.9141 - val_loss: 1460383.5000 - val_mae: 888.2940\n",
      "Epoch 124/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1385355.8750 - mae: 869.9282 - val_loss: 1455868.7500 - val_mae: 890.2667\n",
      "Epoch 125/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1379312.2500 - mae: 868.2524 - val_loss: 1456769.0000 - val_mae: 882.0256\n",
      "Epoch 126/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1375905.0000 - mae: 866.9159 - val_loss: 1449161.0000 - val_mae: 883.5237\n",
      "Epoch 127/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1371949.0000 - mae: 861.8129 - val_loss: 1448261.0000 - val_mae: 891.2699\n",
      "Epoch 128/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1370327.3750 - mae: 862.7388 - val_loss: 1442272.6250 - val_mae: 885.8760\n",
      "Epoch 129/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1365484.6250 - mae: 858.1863 - val_loss: 1439897.2500 - val_mae: 885.4318\n",
      "Epoch 130/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1361449.0000 - mae: 857.7209 - val_loss: 1436072.5000 - val_mae: 883.2584\n",
      "Epoch 131/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1357627.8750 - mae: 856.1394 - val_loss: 1432855.5000 - val_mae: 874.1552\n",
      "Epoch 132/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1354910.7500 - mae: 853.9387 - val_loss: 1428411.1250 - val_mae: 877.2661\n",
      "Epoch 133/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1350292.0000 - mae: 851.6632 - val_loss: 1425304.7500 - val_mae: 875.6265\n",
      "Epoch 134/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1347239.8750 - mae: 847.3179 - val_loss: 1422439.3750 - val_mae: 875.2814\n",
      "Epoch 135/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1343254.2500 - mae: 848.0487 - val_loss: 1418772.7500 - val_mae: 870.2281\n",
      "Epoch 136/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1338581.0000 - mae: 844.5765 - val_loss: 1418612.8750 - val_mae: 872.7908\n",
      "Epoch 137/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1338037.6250 - mae: 845.4482 - val_loss: 1412975.6250 - val_mae: 868.7731\n",
      "Epoch 138/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1332335.0000 - mae: 842.2852 - val_loss: 1412233.2500 - val_mae: 861.6038\n",
      "Epoch 139/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1330169.0000 - mae: 839.5414 - val_loss: 1407681.8750 - val_mae: 862.6077\n",
      "Epoch 140/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1327429.0000 - mae: 838.1266 - val_loss: 1404875.5000 - val_mae: 862.0568\n",
      "Epoch 141/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1325480.3750 - mae: 835.9711 - val_loss: 1402495.8750 - val_mae: 863.0140\n",
      "Epoch 142/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1321258.5000 - mae: 835.6484 - val_loss: 1406952.5000 - val_mae: 854.0741\n",
      "Epoch 143/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1320264.7500 - mae: 831.8026 - val_loss: 1398039.8750 - val_mae: 860.8478\n",
      "Epoch 144/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1313398.2500 - mae: 832.6287 - val_loss: 1397013.5000 - val_mae: 853.0389\n",
      "Epoch 145/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1321449.8750 - mae: 833.9019 - val_loss: 1399652.8750 - val_mae: 863.6617\n",
      "Epoch 146/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1310598.8750 - mae: 826.3542 - val_loss: 1400585.7500 - val_mae: 866.1525\n",
      "Epoch 147/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1311283.6250 - mae: 829.6298 - val_loss: 1391844.8750 - val_mae: 858.4974\n",
      "Epoch 148/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1306379.0000 - mae: 826.9085 - val_loss: 1387958.5000 - val_mae: 849.8684\n",
      "Epoch 149/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1303448.5000 - mae: 825.1859 - val_loss: 1386775.7500 - val_mae: 852.5137\n",
      "Epoch 150/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1304648.5000 - mae: 824.9992 - val_loss: 1385604.6250 - val_mae: 854.7850\n",
      "Epoch 151/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1302010.0000 - mae: 823.0911 - val_loss: 1382830.2500 - val_mae: 851.4116\n",
      "Epoch 152/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1298984.6250 - mae: 824.5216 - val_loss: 1385113.8750 - val_mae: 847.7483\n",
      "Epoch 153/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1297887.8750 - mae: 821.5122 - val_loss: 1379171.6250 - val_mae: 846.0135\n",
      "Epoch 154/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1295909.2500 - mae: 820.9070 - val_loss: 1379124.6250 - val_mae: 843.4449\n",
      "Epoch 155/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1295101.7500 - mae: 820.1118 - val_loss: 1378658.2500 - val_mae: 841.3943\n",
      "Epoch 156/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1294387.2500 - mae: 819.5013 - val_loss: 1375147.7500 - val_mae: 842.1395\n",
      "Epoch 157/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1291633.5000 - mae: 818.6588 - val_loss: 1373824.2500 - val_mae: 844.0532\n",
      "Epoch 158/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1290382.5000 - mae: 816.7758 - val_loss: 1376475.7500 - val_mae: 848.5110\n",
      "Epoch 159/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1289061.5000 - mae: 816.5425 - val_loss: 1372472.5000 - val_mae: 842.9489\n",
      "Epoch 160/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1288244.6250 - mae: 815.8876 - val_loss: 1369560.1250 - val_mae: 840.9835\n",
      "Epoch 161/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1286992.1250 - mae: 816.1238 - val_loss: 1368469.1250 - val_mae: 839.2472\n",
      "Epoch 162/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1286937.8750 - mae: 815.5537 - val_loss: 1367609.1250 - val_mae: 839.9730\n",
      "Epoch 163/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1284496.7500 - mae: 813.9385 - val_loss: 1369359.0000 - val_mae: 836.4719\n",
      "Epoch 164/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1285439.2500 - mae: 812.8705 - val_loss: 1365691.7500 - val_mae: 838.3577\n",
      "Epoch 165/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1281676.1250 - mae: 812.5563 - val_loss: 1371849.2500 - val_mae: 836.2315\n",
      "Epoch 166/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1282708.1250 - mae: 810.8209 - val_loss: 1364209.5000 - val_mae: 838.1089\n",
      "Epoch 167/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1279513.5000 - mae: 813.1229 - val_loss: 1368862.1250 - val_mae: 832.9811\n",
      "Epoch 168/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1280035.8750 - mae: 809.7786 - val_loss: 1365422.7500 - val_mae: 833.1979\n",
      "Epoch 169/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1279117.5000 - mae: 809.2399 - val_loss: 1361714.0000 - val_mae: 835.2421\n",
      "Epoch 170/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1277556.2500 - mae: 809.0295 - val_loss: 1364219.0000 - val_mae: 836.2190\n",
      "Epoch 171/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1278974.6250 - mae: 809.8167 - val_loss: 1358708.7500 - val_mae: 832.4598\n",
      "Epoch 172/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1277189.5000 - mae: 807.8960 - val_loss: 1358360.2500 - val_mae: 833.4114\n",
      "Epoch 173/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1276205.6250 - mae: 807.7426 - val_loss: 1363769.1250 - val_mae: 838.9178\n",
      "Epoch 174/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1276314.6250 - mae: 808.9968 - val_loss: 1357233.7500 - val_mae: 830.3209\n",
      "Epoch 175/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1274921.1250 - mae: 805.1002 - val_loss: 1358641.5000 - val_mae: 834.0582\n",
      "Epoch 176/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1273116.8750 - mae: 805.3727 - val_loss: 1363093.1250 - val_mae: 838.4473\n",
      "Epoch 177/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1272218.0000 - mae: 808.3214 - val_loss: 1358185.0000 - val_mae: 828.5050\n",
      "Epoch 178/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1270221.5000 - mae: 805.8539 - val_loss: 1369536.0000 - val_mae: 830.6804\n",
      "Epoch 179/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1272822.3750 - mae: 804.3670 - val_loss: 1354850.8750 - val_mae: 829.7114\n",
      "Epoch 180/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1271153.3750 - mae: 806.0348 - val_loss: 1360718.0000 - val_mae: 837.9924\n",
      "Epoch 181/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1272765.1250 - mae: 806.6935 - val_loss: 1352737.3750 - val_mae: 828.6449\n",
      "Epoch 182/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1268336.5000 - mae: 802.3966 - val_loss: 1360115.1250 - val_mae: 829.4202\n",
      "Epoch 183/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1268466.7500 - mae: 803.2693 - val_loss: 1352644.0000 - val_mae: 827.4292\n",
      "Epoch 184/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1267686.3750 - mae: 802.7445 - val_loss: 1349831.2500 - val_mae: 827.6897\n",
      "Epoch 185/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1268328.5000 - mae: 803.3224 - val_loss: 1351833.8750 - val_mae: 829.1249\n",
      "Epoch 186/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1266915.0000 - mae: 801.8445 - val_loss: 1350783.1250 - val_mae: 828.8326\n",
      "Epoch 187/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1265126.5000 - mae: 801.7488 - val_loss: 1351196.7500 - val_mae: 829.1630\n",
      "Epoch 188/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1265144.3750 - mae: 801.3495 - val_loss: 1348892.6250 - val_mae: 824.6574\n",
      "Epoch 189/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1266896.6250 - mae: 801.2597 - val_loss: 1352353.2500 - val_mae: 830.9763\n",
      "Epoch 190/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1264443.0000 - mae: 800.9771 - val_loss: 1348558.2500 - val_mae: 823.8574\n",
      "Epoch 191/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1262942.7500 - mae: 800.3721 - val_loss: 1358163.2500 - val_mae: 823.7974\n",
      "Epoch 192/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1266704.3750 - mae: 800.9564 - val_loss: 1346918.6250 - val_mae: 823.1259\n",
      "Epoch 193/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1262895.5000 - mae: 799.3354 - val_loss: 1346478.7500 - val_mae: 825.1245\n",
      "Epoch 194/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1261362.0000 - mae: 798.9928 - val_loss: 1351654.2500 - val_mae: 831.4446\n",
      "Epoch 195/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1261187.6250 - mae: 799.7224 - val_loss: 1347080.8750 - val_mae: 821.7081\n",
      "Epoch 196/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1259911.2500 - mae: 798.8173 - val_loss: 1356443.5000 - val_mae: 823.0082\n",
      "Epoch 197/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1260818.1250 - mae: 797.8517 - val_loss: 1346287.2500 - val_mae: 821.3710\n",
      "Epoch 198/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1257992.2500 - mae: 796.7437 - val_loss: 1353691.2500 - val_mae: 833.5263\n",
      "Epoch 199/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1259974.3750 - mae: 799.5007 - val_loss: 1343107.3750 - val_mae: 822.4578\n",
      "Epoch 200/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1258588.6250 - mae: 797.5816 - val_loss: 1342391.5000 - val_mae: 822.8864\n",
      "Epoch 201/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1256088.2500 - mae: 797.1657 - val_loss: 1346076.0000 - val_mae: 824.6945\n",
      "Epoch 202/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1257797.5000 - mae: 797.3828 - val_loss: 1343714.3750 - val_mae: 823.0721\n",
      "Epoch 203/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1256532.8750 - mae: 796.1896 - val_loss: 1341916.8750 - val_mae: 822.0701\n",
      "Epoch 204/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1255743.1250 - mae: 795.8721 - val_loss: 1340250.6250 - val_mae: 822.0208\n",
      "Epoch 205/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1257802.3750 - mae: 795.8687 - val_loss: 1341307.7500 - val_mae: 824.3017\n",
      "Epoch 206/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1255666.7500 - mae: 796.1606 - val_loss: 1340806.7500 - val_mae: 822.4630\n",
      "Epoch 207/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1256878.6250 - mae: 795.2678 - val_loss: 1343082.1250 - val_mae: 825.8278\n",
      "Epoch 208/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1256114.8750 - mae: 796.2472 - val_loss: 1339255.2500 - val_mae: 820.0435\n",
      "Epoch 209/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1254049.0000 - mae: 796.9706 - val_loss: 1340602.0000 - val_mae: 817.4039\n",
      "Epoch 210/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1255743.8750 - mae: 793.3679 - val_loss: 1338248.5000 - val_mae: 820.1221\n",
      "Epoch 211/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1252584.6250 - mae: 794.1526 - val_loss: 1341994.3750 - val_mae: 820.1016\n",
      "Epoch 212/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1253385.2500 - mae: 794.7805 - val_loss: 1338107.2500 - val_mae: 817.8176\n",
      "Epoch 213/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1251898.0000 - mae: 794.4736 - val_loss: 1336551.6250 - val_mae: 817.7285\n",
      "Epoch 214/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1250285.7500 - mae: 793.4013 - val_loss: 1337931.0000 - val_mae: 817.2094\n",
      "Epoch 215/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1249884.8750 - mae: 793.3199 - val_loss: 1336964.6250 - val_mae: 819.1697\n",
      "Epoch 216/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1249395.0000 - mae: 792.6273 - val_loss: 1337558.2500 - val_mae: 823.2247\n",
      "Epoch 217/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1249067.0000 - mae: 794.1383 - val_loss: 1338901.5000 - val_mae: 823.8611\n",
      "Epoch 218/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1246258.8750 - mae: 792.7775 - val_loss: 1336471.5000 - val_mae: 815.5693\n",
      "Epoch 219/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1247727.2500 - mae: 792.0758 - val_loss: 1336719.7500 - val_mae: 817.0178\n",
      "Epoch 220/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1246481.1250 - mae: 791.0486 - val_loss: 1333762.2500 - val_mae: 819.3486\n",
      "Epoch 221/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1245108.5000 - mae: 793.6619 - val_loss: 1347969.2500 - val_mae: 815.5602\n",
      "Epoch 222/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1243798.7500 - mae: 789.6940 - val_loss: 1335936.3750 - val_mae: 821.3309\n",
      "Epoch 223/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1245737.3750 - mae: 792.1989 - val_loss: 1332345.0000 - val_mae: 817.7128\n",
      "Epoch 224/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1246719.6250 - mae: 793.0173 - val_loss: 1335055.0000 - val_mae: 816.4484\n",
      "Epoch 225/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1243410.2500 - mae: 791.0859 - val_loss: 1331622.7500 - val_mae: 817.2374\n",
      "Epoch 226/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1243639.2500 - mae: 791.5957 - val_loss: 1332097.6250 - val_mae: 817.1339\n",
      "Epoch 227/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1242155.1250 - mae: 790.0516 - val_loss: 1331549.7500 - val_mae: 814.7548\n",
      "Epoch 228/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1242078.0000 - mae: 791.1968 - val_loss: 1329754.5000 - val_mae: 815.1688\n",
      "Epoch 229/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1241950.0000 - mae: 790.7040 - val_loss: 1330007.8750 - val_mae: 815.0073\n",
      "Epoch 230/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1241773.0000 - mae: 790.3484 - val_loss: 1332697.5000 - val_mae: 813.1821\n",
      "Epoch 231/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1240016.5000 - mae: 789.2128 - val_loss: 1332754.0000 - val_mae: 821.0063\n",
      "Epoch 232/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1238929.2500 - mae: 789.2727 - val_loss: 1331664.1250 - val_mae: 819.2291\n",
      "Epoch 233/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1240065.1250 - mae: 790.3021 - val_loss: 1330652.5000 - val_mae: 812.1718\n",
      "Epoch 234/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1240428.7500 - mae: 788.5377 - val_loss: 1329546.5000 - val_mae: 818.1920\n",
      "Epoch 235/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1237645.6250 - mae: 789.5601 - val_loss: 1338985.5000 - val_mae: 814.3099\n",
      "Epoch 236/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1241420.0000 - mae: 791.4241 - val_loss: 1332776.1250 - val_mae: 811.6212\n",
      "Epoch 237/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1244567.7500 - mae: 790.5826 - val_loss: 1331753.1250 - val_mae: 810.8952\n",
      "Epoch 238/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1238441.6250 - mae: 790.0275 - val_loss: 1329970.7500 - val_mae: 811.5466\n",
      "Epoch 239/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1238143.6250 - mae: 786.3847 - val_loss: 1328012.3750 - val_mae: 817.2568\n",
      "Epoch 240/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1236595.1250 - mae: 789.2508 - val_loss: 1327013.2500 - val_mae: 816.0576\n",
      "Epoch 241/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1237069.8750 - mae: 788.4897 - val_loss: 1329142.1250 - val_mae: 812.7036\n",
      "Epoch 242/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1236455.3750 - mae: 788.3284 - val_loss: 1327355.2500 - val_mae: 815.6021\n",
      "Epoch 243/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1234290.7500 - mae: 787.9380 - val_loss: 1324863.7500 - val_mae: 812.1921\n",
      "Epoch 244/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1236260.1250 - mae: 787.3674 - val_loss: 1326368.0000 - val_mae: 816.3660\n",
      "Epoch 245/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1233457.5000 - mae: 787.8058 - val_loss: 1334504.7500 - val_mae: 811.8522\n",
      "Epoch 246/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1231845.5000 - mae: 786.0687 - val_loss: 1325927.0000 - val_mae: 814.3687\n",
      "Epoch 247/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1233495.1250 - mae: 787.9706 - val_loss: 1325385.8750 - val_mae: 812.7303\n",
      "Epoch 248/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1235065.5000 - mae: 788.5114 - val_loss: 1324412.6250 - val_mae: 811.5862\n",
      "Epoch 249/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1232207.6250 - mae: 785.5737 - val_loss: 1326452.5000 - val_mae: 817.0718\n",
      "Epoch 250/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1234561.3750 - mae: 788.5329 - val_loss: 1322366.7500 - val_mae: 811.4488\n",
      "Epoch 251/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1231088.6250 - mae: 785.4856 - val_loss: 1322151.6250 - val_mae: 810.8946\n",
      "Epoch 252/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1229993.8750 - mae: 786.1237 - val_loss: 1322323.8750 - val_mae: 809.2953\n",
      "Epoch 253/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1231002.8750 - mae: 785.3682 - val_loss: 1324211.8750 - val_mae: 816.0114\n",
      "Epoch 254/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1233206.1250 - mae: 786.5629 - val_loss: 1321522.3750 - val_mae: 812.9419\n",
      "Epoch 255/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1229739.5000 - mae: 786.1633 - val_loss: 1321089.8750 - val_mae: 811.8397\n",
      "Epoch 256/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1231539.0000 - mae: 786.3422 - val_loss: 1321177.2500 - val_mae: 812.4108\n",
      "Epoch 257/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1228116.6250 - mae: 784.2684 - val_loss: 1321561.5000 - val_mae: 812.7349\n",
      "Epoch 258/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1227155.8750 - mae: 786.0725 - val_loss: 1320058.3750 - val_mae: 808.6113\n",
      "Epoch 259/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1228094.8750 - mae: 783.8316 - val_loss: 1321339.7500 - val_mae: 813.0296\n",
      "Epoch 260/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1226380.5000 - mae: 784.4002 - val_loss: 1319781.6250 - val_mae: 811.3733\n",
      "Epoch 261/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1226710.7500 - mae: 785.2440 - val_loss: 1319312.0000 - val_mae: 809.4592\n",
      "Epoch 262/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1226659.2500 - mae: 784.1226 - val_loss: 1318715.0000 - val_mae: 811.9146\n",
      "Epoch 263/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1226762.0000 - mae: 785.1671 - val_loss: 1318431.7500 - val_mae: 807.6876\n",
      "Epoch 264/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1225313.0000 - mae: 784.2888 - val_loss: 1317850.6250 - val_mae: 807.1979\n",
      "Epoch 265/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1225572.7500 - mae: 783.1227 - val_loss: 1319616.3750 - val_mae: 813.1447\n",
      "Epoch 266/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1225508.3750 - mae: 784.6095 - val_loss: 1318780.0000 - val_mae: 812.5815\n",
      "Epoch 267/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1223377.8750 - mae: 783.6402 - val_loss: 1319403.3750 - val_mae: 813.5530\n",
      "Epoch 268/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1224317.7500 - mae: 784.3766 - val_loss: 1316391.3750 - val_mae: 810.1479\n",
      "Epoch 269/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1224121.0000 - mae: 783.1829 - val_loss: 1315410.5000 - val_mae: 808.6233\n",
      "Epoch 270/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1221935.0000 - mae: 783.4758 - val_loss: 1315595.8750 - val_mae: 808.9839\n",
      "Epoch 271/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1221102.1250 - mae: 782.1134 - val_loss: 1317283.3750 - val_mae: 813.0349\n",
      "Epoch 272/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1222565.8750 - mae: 784.4734 - val_loss: 1315546.5000 - val_mae: 808.5327\n",
      "Epoch 273/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1223261.8750 - mae: 782.8635 - val_loss: 1314070.2500 - val_mae: 807.8151\n",
      "Epoch 274/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1223110.8750 - mae: 784.1403 - val_loss: 1314609.2500 - val_mae: 806.8052\n",
      "Epoch 275/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1222357.0000 - mae: 783.0608 - val_loss: 1313095.7500 - val_mae: 808.8928\n",
      "Epoch 276/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1220213.0000 - mae: 781.9615 - val_loss: 1314427.0000 - val_mae: 811.2684\n",
      "Epoch 277/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1218362.1250 - mae: 783.9827 - val_loss: 1314775.5000 - val_mae: 804.2864\n",
      "Epoch 278/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1219816.2500 - mae: 781.5262 - val_loss: 1312773.3750 - val_mae: 805.5865\n",
      "Epoch 279/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1218487.2500 - mae: 781.3196 - val_loss: 1315418.2500 - val_mae: 812.7967\n",
      "Epoch 280/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1219324.3750 - mae: 783.1825 - val_loss: 1313176.2500 - val_mae: 808.8207\n",
      "Epoch 281/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1217323.1250 - mae: 782.3862 - val_loss: 1314913.3750 - val_mae: 805.2700\n",
      "Epoch 282/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1216592.5000 - mae: 780.1924 - val_loss: 1315317.7500 - val_mae: 809.8793\n",
      "Epoch 283/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1218705.8750 - mae: 781.5364 - val_loss: 1311734.3750 - val_mae: 805.6198\n",
      "Epoch 284/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1217252.0000 - mae: 781.1127 - val_loss: 1311193.3750 - val_mae: 807.0807\n",
      "Epoch 285/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1215213.6250 - mae: 780.7986 - val_loss: 1311924.3750 - val_mae: 808.7245\n",
      "Epoch 286/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1215272.8750 - mae: 781.4763 - val_loss: 1311898.8750 - val_mae: 804.6754\n",
      "Epoch 287/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1216484.5000 - mae: 781.0207 - val_loss: 1311124.1250 - val_mae: 809.0868\n",
      "Epoch 288/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1214643.5000 - mae: 780.5182 - val_loss: 1309543.7500 - val_mae: 804.8817\n",
      "Epoch 289/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1213737.5000 - mae: 779.6123 - val_loss: 1309839.1250 - val_mae: 807.0971\n",
      "Epoch 290/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1214216.5000 - mae: 780.8809 - val_loss: 1309474.8750 - val_mae: 807.5890\n",
      "Epoch 291/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1212660.6250 - mae: 780.0399 - val_loss: 1309418.3750 - val_mae: 807.6511\n",
      "Epoch 292/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1213138.2500 - mae: 779.6592 - val_loss: 1312279.3750 - val_mae: 811.2466\n",
      "Epoch 293/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1213400.7500 - mae: 780.4690 - val_loss: 1309160.2500 - val_mae: 807.3963\n",
      "Epoch 294/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1211930.3750 - mae: 778.8922 - val_loss: 1309855.5000 - val_mae: 808.0645\n",
      "Epoch 295/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1211626.7500 - mae: 779.5536 - val_loss: 1306621.7500 - val_mae: 804.1389\n",
      "Epoch 296/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1212659.6250 - mae: 778.0386 - val_loss: 1308215.8750 - val_mae: 806.4974\n",
      "Epoch 297/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1211328.2500 - mae: 779.7784 - val_loss: 1306491.0000 - val_mae: 803.6569\n",
      "Epoch 298/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1213350.8750 - mae: 779.9318 - val_loss: 1306257.5000 - val_mae: 804.2084\n",
      "Epoch 299/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1211629.0000 - mae: 780.0963 - val_loss: 1309555.6250 - val_mae: 803.0959\n",
      "Epoch 300/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1210257.3750 - mae: 779.1850 - val_loss: 1310424.6250 - val_mae: 803.4214\n",
      "Epoch 301/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1210272.8750 - mae: 778.9844 - val_loss: 1304915.2500 - val_mae: 803.5947\n",
      "Epoch 302/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1209426.0000 - mae: 778.6982 - val_loss: 1310607.8750 - val_mae: 802.4249\n",
      "Epoch 303/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1211557.2500 - mae: 779.8898 - val_loss: 1307454.7500 - val_mae: 801.5827\n",
      "Epoch 304/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1210507.0000 - mae: 777.6028 - val_loss: 1304629.6250 - val_mae: 801.8318\n",
      "Epoch 305/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1207947.5000 - mae: 777.2781 - val_loss: 1305889.3750 - val_mae: 803.1161\n",
      "Epoch 306/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1211022.6250 - mae: 779.3601 - val_loss: 1305819.3750 - val_mae: 802.7636\n",
      "Epoch 307/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1207332.8750 - mae: 776.6627 - val_loss: 1306715.5000 - val_mae: 807.0242\n",
      "Epoch 308/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1207650.5000 - mae: 777.9955 - val_loss: 1309142.6250 - val_mae: 806.0642\n",
      "Epoch 309/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1206858.7500 - mae: 777.5973 - val_loss: 1303982.1250 - val_mae: 803.2267\n",
      "Epoch 310/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1211311.1250 - mae: 780.1235 - val_loss: 1303361.5000 - val_mae: 800.7074\n",
      "Epoch 311/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1208743.6250 - mae: 777.3936 - val_loss: 1303248.1250 - val_mae: 801.8027\n",
      "Epoch 312/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1204607.5000 - mae: 776.5945 - val_loss: 1305707.8750 - val_mae: 803.1793\n",
      "Epoch 313/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1206312.2500 - mae: 777.7573 - val_loss: 1303546.1250 - val_mae: 803.4608\n",
      "Epoch 314/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1206991.1250 - mae: 778.0710 - val_loss: 1305615.1250 - val_mae: 799.5187\n",
      "Epoch 315/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1206238.5000 - mae: 777.6676 - val_loss: 1306440.2500 - val_mae: 807.6815\n",
      "Epoch 316/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1205818.2500 - mae: 776.8983 - val_loss: 1302138.8750 - val_mae: 802.1040\n",
      "Epoch 317/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1204017.5000 - mae: 777.0801 - val_loss: 1304771.2500 - val_mae: 801.3855\n",
      "Epoch 318/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1205995.8750 - mae: 777.3043 - val_loss: 1302268.5000 - val_mae: 800.5961\n",
      "Epoch 319/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1204490.7500 - mae: 776.8071 - val_loss: 1305621.6250 - val_mae: 807.9319\n",
      "Epoch 320/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1203585.0000 - mae: 777.2834 - val_loss: 1301515.2500 - val_mae: 801.3259\n",
      "Epoch 321/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1203475.8750 - mae: 775.8281 - val_loss: 1300945.5000 - val_mae: 802.5546\n",
      "Epoch 322/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1204536.7500 - mae: 776.5298 - val_loss: 1301196.8750 - val_mae: 802.4499\n",
      "Epoch 323/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1207826.1250 - mae: 778.2404 - val_loss: 1302285.0000 - val_mae: 805.4617\n",
      "Epoch 324/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1201773.5000 - mae: 776.3563 - val_loss: 1300351.5000 - val_mae: 800.4167\n",
      "Epoch 325/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1205975.0000 - mae: 776.5773 - val_loss: 1304565.3750 - val_mae: 803.6985\n",
      "Epoch 326/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1203588.1250 - mae: 775.7191 - val_loss: 1302653.8750 - val_mae: 805.1613\n",
      "Epoch 327/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1203401.8750 - mae: 776.4465 - val_loss: 1299779.0000 - val_mae: 801.4003\n",
      "Epoch 328/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1200743.2500 - mae: 775.1766 - val_loss: 1299747.0000 - val_mae: 801.7327\n",
      "Epoch 329/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1200325.0000 - mae: 774.1852 - val_loss: 1300524.3750 - val_mae: 803.3729\n",
      "Epoch 330/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1204437.7500 - mae: 777.4693 - val_loss: 1299468.3750 - val_mae: 801.1238\n",
      "Epoch 331/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1197442.7500 - mae: 774.0636 - val_loss: 1301106.5000 - val_mae: 803.8632\n",
      "Epoch 332/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1199130.2500 - mae: 775.2026 - val_loss: 1299461.2500 - val_mae: 798.2894\n",
      "Epoch 333/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1200550.0000 - mae: 774.2771 - val_loss: 1300491.8750 - val_mae: 803.3784\n",
      "Epoch 334/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1200672.5000 - mae: 774.8633 - val_loss: 1302733.2500 - val_mae: 800.6339\n",
      "Epoch 335/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1200033.2500 - mae: 775.9944 - val_loss: 1299799.5000 - val_mae: 804.6412\n",
      "Epoch 336/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1200317.0000 - mae: 775.7022 - val_loss: 1303946.6250 - val_mae: 805.3798\n",
      "Epoch 337/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1197895.7500 - mae: 775.2065 - val_loss: 1300272.1250 - val_mae: 803.4671\n",
      "Epoch 338/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1196175.7500 - mae: 774.7767 - val_loss: 1302182.2500 - val_mae: 797.2657\n",
      "Epoch 339/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1199476.3750 - mae: 774.4627 - val_loss: 1297232.5000 - val_mae: 798.8471\n",
      "Epoch 340/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1200565.3750 - mae: 774.4551 - val_loss: 1300664.1250 - val_mae: 804.6423\n",
      "Epoch 341/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1203183.7500 - mae: 777.0281 - val_loss: 1297849.2500 - val_mae: 800.9937\n",
      "Epoch 342/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1198153.7500 - mae: 773.5156 - val_loss: 1297500.8750 - val_mae: 798.5798\n",
      "Epoch 343/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194770.8750 - mae: 773.3373 - val_loss: 1301312.6250 - val_mae: 805.4622\n",
      "Epoch 344/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1197100.7500 - mae: 774.3113 - val_loss: 1297083.5000 - val_mae: 802.7633\n",
      "Epoch 345/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195987.1250 - mae: 774.6529 - val_loss: 1295416.2500 - val_mae: 799.1823\n",
      "Epoch 346/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1197799.2500 - mae: 773.5843 - val_loss: 1294604.5000 - val_mae: 797.5318\n",
      "Epoch 347/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195892.8750 - mae: 772.6864 - val_loss: 1297231.7500 - val_mae: 801.4443\n",
      "Epoch 348/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195750.7500 - mae: 773.8201 - val_loss: 1297288.6250 - val_mae: 803.1901\n",
      "Epoch 349/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1199160.5000 - mae: 774.5673 - val_loss: 1301808.5000 - val_mae: 805.4500\n",
      "Epoch 350/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1192913.6250 - mae: 774.1439 - val_loss: 1297611.1250 - val_mae: 795.5276\n",
      "Epoch 351/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194932.3750 - mae: 771.6055 - val_loss: 1301181.7500 - val_mae: 804.8088\n",
      "Epoch 352/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195515.2500 - mae: 773.4270 - val_loss: 1296529.3750 - val_mae: 799.6237\n",
      "Epoch 353/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1196095.8750 - mae: 773.8347 - val_loss: 1294030.3750 - val_mae: 797.0109\n",
      "Epoch 354/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1196411.6250 - mae: 772.9703 - val_loss: 1295290.3750 - val_mae: 797.5225\n",
      "Epoch 355/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1196223.0000 - mae: 773.6430 - val_loss: 1293766.0000 - val_mae: 798.5629\n",
      "Epoch 356/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1194767.1250 - mae: 773.1188 - val_loss: 1294751.6250 - val_mae: 795.5215\n",
      "Epoch 357/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194887.3750 - mae: 772.9708 - val_loss: 1293837.1250 - val_mae: 797.3846\n",
      "Epoch 358/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194724.3750 - mae: 773.0571 - val_loss: 1293260.3750 - val_mae: 797.5065\n",
      "Epoch 359/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195035.8750 - mae: 772.7627 - val_loss: 1295231.7500 - val_mae: 799.0893\n",
      "Epoch 360/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1193466.1250 - mae: 773.0312 - val_loss: 1295622.0000 - val_mae: 798.9268\n",
      "Epoch 361/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1192586.3750 - mae: 772.9889 - val_loss: 1293865.3750 - val_mae: 795.0675\n",
      "Epoch 362/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1193248.5000 - mae: 771.7130 - val_loss: 1294083.7500 - val_mae: 798.2092\n",
      "Epoch 363/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195479.7500 - mae: 774.0596 - val_loss: 1293747.0000 - val_mae: 797.7977\n",
      "Epoch 364/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1190363.2500 - mae: 770.2840 - val_loss: 1298892.6250 - val_mae: 805.6021\n",
      "Epoch 365/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1193364.5000 - mae: 773.7949 - val_loss: 1292181.5000 - val_mae: 797.3795\n",
      "Epoch 366/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1192380.1250 - mae: 771.6721 - val_loss: 1291916.2500 - val_mae: 797.0909\n",
      "Epoch 367/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1192071.7500 - mae: 771.8043 - val_loss: 1297635.8750 - val_mae: 804.2869\n",
      "Epoch 368/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1191900.2500 - mae: 773.3989 - val_loss: 1294145.7500 - val_mae: 795.6609\n",
      "Epoch 369/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1192080.3750 - mae: 771.8828 - val_loss: 1291068.6250 - val_mae: 796.5410\n",
      "Epoch 370/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1191543.0000 - mae: 770.8063 - val_loss: 1292475.8750 - val_mae: 798.2114\n",
      "Epoch 371/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195002.0000 - mae: 773.0134 - val_loss: 1292510.0000 - val_mae: 796.2676\n",
      "Epoch 372/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1189143.5000 - mae: 772.0327 - val_loss: 1298290.1250 - val_mae: 798.2222\n",
      "Epoch 373/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194142.0000 - mae: 772.9845 - val_loss: 1291351.8750 - val_mae: 797.5387\n",
      "Epoch 374/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1193090.3750 - mae: 772.4836 - val_loss: 1290086.0000 - val_mae: 796.0291\n",
      "Epoch 375/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1191404.7500 - mae: 771.2516 - val_loss: 1290004.0000 - val_mae: 796.0066\n",
      "Epoch 376/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1188966.2500 - mae: 771.7264 - val_loss: 1292426.3750 - val_mae: 794.0514\n",
      "Epoch 377/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1193953.2500 - mae: 771.3100 - val_loss: 1292802.3750 - val_mae: 795.3617\n",
      "Epoch 378/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1188912.6250 - mae: 770.0627 - val_loss: 1294584.2500 - val_mae: 801.6688\n",
      "Epoch 379/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187803.6250 - mae: 771.6199 - val_loss: 1291039.0000 - val_mae: 796.3069\n",
      "Epoch 380/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187463.1250 - mae: 769.8647 - val_loss: 1292979.1250 - val_mae: 799.1644\n",
      "Epoch 381/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187710.7500 - mae: 771.0763 - val_loss: 1292942.8750 - val_mae: 799.2396\n",
      "Epoch 382/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1189347.3750 - mae: 771.1427 - val_loss: 1295311.0000 - val_mae: 803.5765\n",
      "Epoch 383/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1190301.0000 - mae: 772.4930 - val_loss: 1289486.3750 - val_mae: 794.3575\n",
      "Epoch 384/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187748.8750 - mae: 770.3321 - val_loss: 1288682.3750 - val_mae: 795.5637\n",
      "Epoch 385/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187556.8750 - mae: 770.9750 - val_loss: 1290944.1250 - val_mae: 799.7808\n",
      "Epoch 386/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1188868.3750 - mae: 771.0298 - val_loss: 1288620.0000 - val_mae: 795.9243\n",
      "Epoch 387/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187485.5000 - mae: 770.4368 - val_loss: 1290813.7500 - val_mae: 799.3596\n",
      "Epoch 388/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1189495.3750 - mae: 771.2170 - val_loss: 1288597.1250 - val_mae: 796.0237\n",
      "Epoch 389/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1190894.5000 - mae: 772.6641 - val_loss: 1288935.2500 - val_mae: 795.8082\n",
      "Epoch 390/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1184763.0000 - mae: 770.3373 - val_loss: 1318734.6250 - val_mae: 802.4193\n",
      "Epoch 391/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1189904.1250 - mae: 770.2963 - val_loss: 1291558.5000 - val_mae: 800.3508\n",
      "Epoch 392/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1186210.3750 - mae: 770.7239 - val_loss: 1288720.7500 - val_mae: 797.1942\n",
      "Epoch 393/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1186163.2500 - mae: 771.1619 - val_loss: 1288806.1250 - val_mae: 795.4685\n",
      "Epoch 394/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1186752.0000 - mae: 771.1999 - val_loss: 1289984.5000 - val_mae: 798.9437\n",
      "Epoch 395/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1188435.7500 - mae: 771.9709 - val_loss: 1287449.1250 - val_mae: 796.7386\n",
      "Epoch 396/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1185274.6250 - mae: 769.6266 - val_loss: 1290146.0000 - val_mae: 799.8613\n",
      "Epoch 397/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1186809.0000 - mae: 769.8080 - val_loss: 1291531.3750 - val_mae: 799.1199\n",
      "Epoch 398/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1185355.1250 - mae: 770.4137 - val_loss: 1287047.6250 - val_mae: 795.1284\n",
      "Epoch 399/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1185180.3750 - mae: 770.6689 - val_loss: 1286999.1250 - val_mae: 794.9910\n",
      "Epoch 400/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1184430.2500 - mae: 770.0766 - val_loss: 1287361.8750 - val_mae: 795.6178\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "# passing the independent and dependent features for training set for training the model\n",
    "\n",
    "# validation data will be evaluated at the end of each epoch\n",
    "\n",
    "# setting the epochs as 50\n",
    "\n",
    "# storing the trained model in model_history variable which will be used to visualize the training process\n",
    "\n",
    "model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 987us/step - loss: 1287361.8750 - mae: 795.6178\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 805us/step\n",
      "R2 Score: 0.5596254492380754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model_history.history['mae'])\n",
    "plt.plot(model_history.history['val_mae'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
