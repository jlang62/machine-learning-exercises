{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv('../data/deep_learning_task_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            5000 non-null   object \n",
      " 1   Item_Weight                4182 non-null   float64\n",
      " 2   Item_Fat_Content           5000 non-null   object \n",
      " 3   Item_Visibility            5000 non-null   float64\n",
      " 4   Item_Type                  5000 non-null   object \n",
      " 5   Item_MRP                   5000 non-null   float64\n",
      " 6   Outlet_Identifier          5000 non-null   object \n",
      " 7   Outlet_Establishment_Year  5000 non-null   int64  \n",
      " 8   Outlet_Size                3561 non-null   object \n",
      " 9   Outlet_Location_Type       5000 non-null   object \n",
      " 10  Outlet_Type                5000 non-null   object \n",
      " 11  Item_Outlet_Sales          5000 non-null   float64\n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                   818\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  1439\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/pk9yd5v978d_6j_wky4ptw480000gn/T/ipykernel_8437/889244835.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  df.fillna(df.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# fill the missing values with the mean of the column\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df['Outlet_Size'].fillna(df['Outlet_Size'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Medium    3044\n",
       "Small     1398\n",
       "High       558\n",
       "Name: Outlet_Size, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Outlet_Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low Fat' 'Regular' 'low fat' 'LF' 'reg']\n",
      "['Dairy' 'Soft Drinks' 'Meat' 'Fruits and Vegetables' 'Household'\n",
      " 'Baking Goods' 'Snack Foods' 'Frozen Foods' 'Breakfast'\n",
      " 'Health and Hygiene' 'Hard Drinks' 'Canned' 'Breads' 'Starchy Foods'\n",
      " 'Others' 'Seafood']\n",
      "['Medium' 'High' 'Small']\n",
      "['Tier 1' 'Tier 3' 'Tier 2']\n",
      "['OUT049' 'OUT018' 'OUT010' 'OUT013' 'OUT027' 'OUT045' 'OUT017' 'OUT046'\n",
      " 'OUT035' 'OUT019']\n",
      "['Supermarket Type1' 'Supermarket Type2' 'Grocery Store'\n",
      " 'Supermarket Type3']\n"
     ]
    }
   ],
   "source": [
    "print(df['Item_Fat_Content'].unique())\n",
    "print(df['Item_Type'].unique())\n",
    "print(df['Outlet_Size'].unique())\n",
    "print(df['Outlet_Location_Type'].unique())\n",
    "print(df['Outlet_Identifier'].unique())\n",
    "print(df['Outlet_Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low Fat', 'Regular'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Item_Fat_Content'].replace(['low fat', 'LF', 'reg'], ['Low Fat', 'Low Fat', 'Regular'], inplace=True)\n",
    "df['Item_Fat_Content'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998      Medium               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df.drop(['Item_Identifier', 'Outlet_Establishment_Year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282525</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.048866</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>0.927507</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081274</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.058705</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>0.072068</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770765</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>Meat</td>\n",
       "      <td>0.468288</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.871986</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260494</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>0.095805</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight Item_Fat_Content  Item_Visibility              Item_Type  \\\n",
       "0     0.282525          Low Fat         0.048866                  Dairy   \n",
       "1     0.081274          Regular         0.058705            Soft Drinks   \n",
       "2     0.770765          Low Fat         0.051037                   Meat   \n",
       "3     0.871986          Regular         0.000000  Fruits and Vegetables   \n",
       "4     0.260494          Low Fat         0.000000              Household   \n",
       "\n",
       "   Item_MRP Outlet_Identifier Outlet_Size Outlet_Location_Type  \\\n",
       "0  0.927507            OUT049      Medium               Tier 1   \n",
       "1  0.072068            OUT018      Medium               Tier 3   \n",
       "2  0.468288            OUT049      Medium               Tier 1   \n",
       "3  0.640093            OUT010      Medium               Tier 3   \n",
       "4  0.095805            OUT013        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalizing the data Item_Weight, Item_Visibility, Item_MRP, Outlet_Establishment_Year\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_sub[['Item_Weight', 'Item_Visibility', 'Item_MRP']] = scaler.fit_transform(df_sub[['Item_Weight', 'Item_Visibility', 'Item_MRP']])\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Item_Fat_Content_Low Fat</th>\n",
       "      <th>Item_Fat_Content_Regular</th>\n",
       "      <th>Item_Type_Baking Goods</th>\n",
       "      <th>Item_Type_Breads</th>\n",
       "      <th>Item_Type_Breakfast</th>\n",
       "      <th>Item_Type_Canned</th>\n",
       "      <th>Item_Type_Dairy</th>\n",
       "      <th>...</th>\n",
       "      <th>Outlet_Size_High</th>\n",
       "      <th>Outlet_Size_Medium</th>\n",
       "      <th>Outlet_Size_Small</th>\n",
       "      <th>Outlet_Location_Type_Tier 1</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Supermarket Type2</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.282525</td>\n",
       "      <td>0.048866</td>\n",
       "      <td>0.927507</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081274</td>\n",
       "      <td>0.058705</td>\n",
       "      <td>0.072068</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.770765</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>0.468288</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.871986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095805</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Visibility  Item_MRP  Item_Fat_Content_Low Fat  \\\n",
       "0     0.282525         0.048866  0.927507                         1   \n",
       "1     0.081274         0.058705  0.072068                         0   \n",
       "2     0.770765         0.051037  0.468288                         1   \n",
       "3     0.871986         0.000000  0.640093                         0   \n",
       "4     0.260494         0.000000  0.095805                         1   \n",
       "\n",
       "   Item_Fat_Content_Regular  Item_Type_Baking Goods  Item_Type_Breads  \\\n",
       "0                         0                       0                 0   \n",
       "1                         1                       0                 0   \n",
       "2                         0                       0                 0   \n",
       "3                         1                       0                 0   \n",
       "4                         0                       0                 0   \n",
       "\n",
       "   Item_Type_Breakfast  Item_Type_Canned  Item_Type_Dairy  ...  \\\n",
       "0                    0                 0                1  ...   \n",
       "1                    0                 0                0  ...   \n",
       "2                    0                 0                0  ...   \n",
       "3                    0                 0                0  ...   \n",
       "4                    0                 0                0  ...   \n",
       "\n",
       "   Outlet_Size_High  Outlet_Size_Medium  Outlet_Size_Small  \\\n",
       "0                 0                   1                  0   \n",
       "1                 0                   1                  0   \n",
       "2                 0                   1                  0   \n",
       "3                 0                   1                  0   \n",
       "4                 1                   0                  0   \n",
       "\n",
       "   Outlet_Location_Type_Tier 1  Outlet_Location_Type_Tier 2  \\\n",
       "0                            1                            0   \n",
       "1                            0                            0   \n",
       "2                            1                            0   \n",
       "3                            0                            0   \n",
       "4                            0                            0   \n",
       "\n",
       "   Outlet_Location_Type_Tier 3  Outlet_Type_Grocery Store  \\\n",
       "0                            0                          0   \n",
       "1                            1                          0   \n",
       "2                            0                          0   \n",
       "3                            1                          1   \n",
       "4                            1                          0   \n",
       "\n",
       "   Outlet_Type_Supermarket Type1  Outlet_Type_Supermarket Type2  \\\n",
       "0                              1                              0   \n",
       "1                              0                              1   \n",
       "2                              1                              0   \n",
       "3                              0                              0   \n",
       "4                              1                              0   \n",
       "\n",
       "   Outlet_Type_Supermarket Type3  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(df_sub.drop(['Item_Outlet_Sales'], axis=1))\n",
    "y = df_sub['Item_Outlet_Sales']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 41), (5000,))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((4000, 41), (4000,)), ((1000, 41), (1000,)))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation set\n",
    "\n",
    "# stratify will make sure that the distribution of classes in train and validation set it similar\n",
    "# random state to regenerate the same train and validation set\n",
    "# test size 0.2 will keep 20% data in validation and remaining 80% in train set\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "\n",
    "# shape of training and validation set\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the sequential model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# importing different layers from keras\n",
    "from keras.layers import InputLayer, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 41)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of input neurons\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features in the data\n",
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining input neurons\n",
    "input_neurons = X_train.shape[1]\n",
    "input_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of output neurons\n",
    "output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hidden layers and neuron in each layer\n",
    "number_of_hidden_layers = 2\n",
    "neuron_hidden_layer_1 = 80\n",
    "neuron_hidden_layer_2 = 40\n",
    "neuron_hidden_layer_3 = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 80)                3360      \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 40)                3240      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 41        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6641 (25.94 KB)\n",
      "Trainable params: 6641 (25.94 KB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "# defining the architecture of the model\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=(input_neurons)))\n",
    "model.add(Dense(units=neuron_hidden_layer_1, activation='relu'))\n",
    "model.add(Dense(units=neuron_hidden_layer_2, activation='relu'))\n",
    "model.add(Dense(units=output_neurons, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(lr=0.001), metrics=['mae'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "125/125 [==============================] - 1s 2ms/step - loss: 7614978.5000 - mae: 2170.6777 - val_loss: 7136325.5000 - val_mae: 2063.7620\n",
      "Epoch 2/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 6162853.5000 - mae: 1848.5541 - val_loss: 4507825.5000 - val_mae: 1495.7717\n",
      "Epoch 3/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 3294997.5000 - mae: 1297.6127 - val_loss: 2522175.2500 - val_mae: 1199.1370\n",
      "Epoch 4/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2397585.5000 - mae: 1205.5023 - val_loss: 2324342.0000 - val_mae: 1190.9218\n",
      "Epoch 5/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2246155.2500 - mae: 1173.0597 - val_loss: 2202003.7500 - val_mae: 1156.0485\n",
      "Epoch 6/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2131034.7500 - mae: 1133.6495 - val_loss: 2096729.2500 - val_mae: 1124.4675\n",
      "Epoch 7/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2035321.1250 - mae: 1099.3915 - val_loss: 2000540.3750 - val_mae: 1081.4537\n",
      "Epoch 8/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1953372.1250 - mae: 1065.6064 - val_loss: 1921840.1250 - val_mae: 1058.5160\n",
      "Epoch 9/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1884485.3750 - mae: 1040.1792 - val_loss: 1842895.5000 - val_mae: 1014.7104\n",
      "Epoch 10/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1821784.5000 - mae: 1011.2802 - val_loss: 1785211.6250 - val_mae: 1010.6010\n",
      "Epoch 11/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1771049.2500 - mae: 1000.5297 - val_loss: 1720554.5000 - val_mae: 981.6735\n",
      "Epoch 12/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1721276.7500 - mae: 985.3851 - val_loss: 1663386.6250 - val_mae: 954.5806\n",
      "Epoch 13/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1675883.3750 - mae: 969.1929 - val_loss: 1611515.3750 - val_mae: 942.9550\n",
      "Epoch 14/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1629092.0000 - mae: 953.1254 - val_loss: 1566185.6250 - val_mae: 924.7692\n",
      "Epoch 15/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1585538.3750 - mae: 940.7306 - val_loss: 1517423.8750 - val_mae: 914.0177\n",
      "Epoch 16/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1542572.8750 - mae: 927.8758 - val_loss: 1473238.1250 - val_mae: 895.5347\n",
      "Epoch 17/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1499745.5000 - mae: 913.1010 - val_loss: 1430995.2500 - val_mae: 877.6092\n",
      "Epoch 18/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1459808.6250 - mae: 900.2034 - val_loss: 1393511.2500 - val_mae: 858.2352\n",
      "Epoch 19/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1418662.8750 - mae: 882.0702 - val_loss: 1351322.1250 - val_mae: 857.2183\n",
      "Epoch 20/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1385400.8750 - mae: 872.8063 - val_loss: 1316979.5000 - val_mae: 836.5526\n",
      "Epoch 21/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1351486.7500 - mae: 858.2567 - val_loss: 1289932.0000 - val_mae: 836.6804\n",
      "Epoch 22/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1322940.8750 - mae: 848.2051 - val_loss: 1259409.5000 - val_mae: 817.1356\n",
      "Epoch 23/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1297381.0000 - mae: 834.9502 - val_loss: 1237648.2500 - val_mae: 806.1562\n",
      "Epoch 24/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1275575.7500 - mae: 828.5388 - val_loss: 1223850.5000 - val_mae: 794.2446\n",
      "Epoch 25/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1260803.1250 - mae: 819.4370 - val_loss: 1207219.6250 - val_mae: 792.4269\n",
      "Epoch 26/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1246429.5000 - mae: 813.3285 - val_loss: 1196106.5000 - val_mae: 788.1806\n",
      "Epoch 27/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1235759.3750 - mae: 808.7592 - val_loss: 1187371.7500 - val_mae: 787.9703\n",
      "Epoch 28/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1225727.1250 - mae: 803.7676 - val_loss: 1182509.7500 - val_mae: 780.9338\n",
      "Epoch 29/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1220049.3750 - mae: 801.2549 - val_loss: 1178496.3750 - val_mae: 785.1728\n",
      "Epoch 30/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1214884.2500 - mae: 799.3303 - val_loss: 1176596.6250 - val_mae: 777.1370\n",
      "Epoch 31/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1212216.1250 - mae: 798.2653 - val_loss: 1172657.6250 - val_mae: 779.5482\n",
      "Epoch 32/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1210129.8750 - mae: 796.3848 - val_loss: 1171884.6250 - val_mae: 778.0117\n",
      "Epoch 33/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1206826.6250 - mae: 794.7815 - val_loss: 1170536.2500 - val_mae: 781.3791\n",
      "Epoch 34/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1205962.3750 - mae: 796.0111 - val_loss: 1173245.0000 - val_mae: 776.4896\n",
      "Epoch 35/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1205787.8750 - mae: 793.9434 - val_loss: 1170419.0000 - val_mae: 778.7302\n",
      "Epoch 36/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1204965.6250 - mae: 793.9353 - val_loss: 1172625.6250 - val_mae: 777.0283\n",
      "Epoch 37/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1204924.1250 - mae: 793.3790 - val_loss: 1170628.3750 - val_mae: 780.3078\n",
      "Epoch 38/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1203785.3750 - mae: 793.6040 - val_loss: 1169081.1250 - val_mae: 777.9011\n",
      "Epoch 39/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1201864.5000 - mae: 793.4104 - val_loss: 1171797.6250 - val_mae: 782.8898\n",
      "Epoch 40/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1202078.8750 - mae: 792.8161 - val_loss: 1169932.1250 - val_mae: 776.4730\n",
      "Epoch 41/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1200455.3750 - mae: 791.2245 - val_loss: 1170037.0000 - val_mae: 776.7946\n",
      "Epoch 42/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1199575.1250 - mae: 792.0372 - val_loss: 1170855.3750 - val_mae: 775.6039\n",
      "Epoch 43/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1200344.6250 - mae: 791.6710 - val_loss: 1171784.8750 - val_mae: 775.9870\n",
      "Epoch 44/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1198766.7500 - mae: 790.5369 - val_loss: 1173488.2500 - val_mae: 784.6959\n",
      "Epoch 45/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1200640.8750 - mae: 792.9167 - val_loss: 1169712.2500 - val_mae: 776.0773\n",
      "Epoch 46/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1199656.3750 - mae: 791.2236 - val_loss: 1173380.7500 - val_mae: 775.3217\n",
      "Epoch 47/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1198857.0000 - mae: 789.9951 - val_loss: 1170263.3750 - val_mae: 775.6729\n",
      "Epoch 48/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1198203.5000 - mae: 789.9354 - val_loss: 1168535.6250 - val_mae: 775.3705\n",
      "Epoch 49/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1196788.8750 - mae: 790.2593 - val_loss: 1170075.8750 - val_mae: 774.5018\n",
      "Epoch 50/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195557.0000 - mae: 788.9645 - val_loss: 1170664.3750 - val_mae: 774.2055\n",
      "Epoch 51/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194819.2500 - mae: 787.8362 - val_loss: 1168077.2500 - val_mae: 778.6361\n",
      "Epoch 52/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1196245.8750 - mae: 789.7183 - val_loss: 1167567.5000 - val_mae: 774.7048\n",
      "Epoch 53/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195744.6250 - mae: 788.4650 - val_loss: 1168486.6250 - val_mae: 774.9364\n",
      "Epoch 54/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194263.6250 - mae: 787.4905 - val_loss: 1170557.0000 - val_mae: 773.7203\n",
      "Epoch 55/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1195255.0000 - mae: 787.5671 - val_loss: 1167703.6250 - val_mae: 780.7546\n",
      "Epoch 56/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194840.3750 - mae: 787.6509 - val_loss: 1165636.7500 - val_mae: 773.8612\n",
      "Epoch 57/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1194331.3750 - mae: 788.2308 - val_loss: 1165251.5000 - val_mae: 774.1201\n",
      "Epoch 58/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1192708.1250 - mae: 787.0660 - val_loss: 1164087.8750 - val_mae: 774.6952\n",
      "Epoch 59/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1191793.0000 - mae: 786.4090 - val_loss: 1163374.6250 - val_mae: 774.1487\n",
      "Epoch 60/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1190773.3750 - mae: 787.0307 - val_loss: 1168515.5000 - val_mae: 772.5934\n",
      "Epoch 61/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1193355.0000 - mae: 785.5453 - val_loss: 1164932.0000 - val_mae: 773.3941\n",
      "Epoch 62/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1190085.8750 - mae: 785.7379 - val_loss: 1164629.0000 - val_mae: 772.7386\n",
      "Epoch 63/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1191682.1250 - mae: 785.3961 - val_loss: 1166397.2500 - val_mae: 779.9249\n",
      "Epoch 64/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1190901.1250 - mae: 785.7827 - val_loss: 1163889.1250 - val_mae: 772.5363\n",
      "Epoch 65/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1188608.2500 - mae: 784.2476 - val_loss: 1163707.0000 - val_mae: 775.9902\n",
      "Epoch 66/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1189220.8750 - mae: 785.3176 - val_loss: 1162555.3750 - val_mae: 774.0341\n",
      "Epoch 67/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1188547.2500 - mae: 784.1052 - val_loss: 1162158.5000 - val_mae: 773.7880\n",
      "Epoch 68/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187564.5000 - mae: 783.8813 - val_loss: 1162462.5000 - val_mae: 772.5618\n",
      "Epoch 69/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187871.6250 - mae: 783.4819 - val_loss: 1162695.5000 - val_mae: 776.1031\n",
      "Epoch 70/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187900.8750 - mae: 785.2342 - val_loss: 1164579.1250 - val_mae: 772.1036\n",
      "Epoch 71/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187218.7500 - mae: 783.4499 - val_loss: 1160389.5000 - val_mae: 774.1652\n",
      "Epoch 72/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1187449.6250 - mae: 783.2484 - val_loss: 1161755.1250 - val_mae: 773.3367\n",
      "Epoch 73/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1188639.6250 - mae: 783.4064 - val_loss: 1163143.1250 - val_mae: 772.6760\n",
      "Epoch 74/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1186871.0000 - mae: 782.8324 - val_loss: 1162394.7500 - val_mae: 772.4402\n",
      "Epoch 75/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1185296.2500 - mae: 782.7998 - val_loss: 1163357.7500 - val_mae: 771.4108\n",
      "Epoch 76/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1185074.5000 - mae: 782.4459 - val_loss: 1163623.0000 - val_mae: 771.3169\n",
      "Epoch 77/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1184371.5000 - mae: 781.7548 - val_loss: 1161408.5000 - val_mae: 775.1459\n",
      "Epoch 78/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1185370.0000 - mae: 782.0110 - val_loss: 1161183.3750 - val_mae: 771.1379\n",
      "Epoch 79/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1184966.7500 - mae: 781.1622 - val_loss: 1160551.1250 - val_mae: 773.7757\n",
      "Epoch 80/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1183894.2500 - mae: 781.8342 - val_loss: 1159944.8750 - val_mae: 771.5184\n",
      "Epoch 81/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1184254.8750 - mae: 781.6741 - val_loss: 1159639.7500 - val_mae: 773.8262\n",
      "Epoch 82/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1183221.7500 - mae: 780.9877 - val_loss: 1160085.0000 - val_mae: 772.4606\n",
      "Epoch 83/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1182028.2500 - mae: 781.0237 - val_loss: 1160324.8750 - val_mae: 771.8525\n",
      "Epoch 84/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1183995.2500 - mae: 781.7402 - val_loss: 1165028.5000 - val_mae: 770.8950\n",
      "Epoch 85/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1181764.8750 - mae: 780.2639 - val_loss: 1160492.0000 - val_mae: 770.8677\n",
      "Epoch 86/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1181809.1250 - mae: 780.7906 - val_loss: 1159823.2500 - val_mae: 773.7272\n",
      "Epoch 87/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1181434.5000 - mae: 781.0881 - val_loss: 1161191.2500 - val_mae: 770.4716\n",
      "Epoch 88/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1182124.6250 - mae: 779.9671 - val_loss: 1160164.1250 - val_mae: 772.3686\n",
      "Epoch 89/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1181164.3750 - mae: 779.8535 - val_loss: 1158191.8750 - val_mae: 772.7875\n",
      "Epoch 90/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1181199.5000 - mae: 780.2712 - val_loss: 1159476.6250 - val_mae: 773.4460\n",
      "Epoch 91/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1180898.8750 - mae: 780.1238 - val_loss: 1159003.8750 - val_mae: 772.7696\n",
      "Epoch 92/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1180169.3750 - mae: 779.8926 - val_loss: 1159586.5000 - val_mae: 770.1813\n",
      "Epoch 93/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1179690.5000 - mae: 779.3078 - val_loss: 1156863.5000 - val_mae: 770.7386\n",
      "Epoch 94/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1178404.0000 - mae: 779.0192 - val_loss: 1160450.5000 - val_mae: 769.6129\n",
      "Epoch 95/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1179080.8750 - mae: 778.7433 - val_loss: 1156896.7500 - val_mae: 772.0660\n",
      "Epoch 96/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1178678.2500 - mae: 778.6254 - val_loss: 1156722.2500 - val_mae: 771.5986\n",
      "Epoch 97/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1177863.7500 - mae: 779.3314 - val_loss: 1162944.6250 - val_mae: 768.9908\n",
      "Epoch 98/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1178372.1250 - mae: 779.0606 - val_loss: 1161268.7500 - val_mae: 769.5218\n",
      "Epoch 99/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1178151.7500 - mae: 778.0441 - val_loss: 1163160.6250 - val_mae: 778.4929\n",
      "Epoch 100/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1178152.6250 - mae: 779.5964 - val_loss: 1157391.6250 - val_mae: 769.5680\n",
      "Epoch 101/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1179360.5000 - mae: 778.4366 - val_loss: 1156120.8750 - val_mae: 770.4122\n",
      "Epoch 102/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1177628.5000 - mae: 778.4988 - val_loss: 1156607.6250 - val_mae: 770.9443\n",
      "Epoch 103/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1175250.5000 - mae: 777.7073 - val_loss: 1160194.3750 - val_mae: 769.4996\n",
      "Epoch 104/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1176135.6250 - mae: 778.4993 - val_loss: 1159910.0000 - val_mae: 768.6872\n",
      "Epoch 105/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1177692.1250 - mae: 778.0045 - val_loss: 1155635.1250 - val_mae: 768.8993\n",
      "Epoch 106/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1174583.6250 - mae: 776.8423 - val_loss: 1157533.0000 - val_mae: 773.4510\n",
      "Epoch 107/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1175599.6250 - mae: 778.2016 - val_loss: 1156884.8750 - val_mae: 769.0601\n",
      "Epoch 108/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1176215.3750 - mae: 776.8685 - val_loss: 1156513.8750 - val_mae: 769.0109\n",
      "Epoch 109/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1173805.6250 - mae: 777.3393 - val_loss: 1163004.6250 - val_mae: 768.0607\n",
      "Epoch 110/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1175645.8750 - mae: 777.1889 - val_loss: 1159251.1250 - val_mae: 768.6577\n",
      "Epoch 111/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1175244.2500 - mae: 776.8710 - val_loss: 1155996.2500 - val_mae: 768.9235\n",
      "Epoch 112/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1173757.1250 - mae: 776.3462 - val_loss: 1155124.3750 - val_mae: 768.8375\n",
      "Epoch 113/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1176883.7500 - mae: 777.4034 - val_loss: 1155562.1250 - val_mae: 768.9429\n",
      "Epoch 114/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1174022.2500 - mae: 775.8852 - val_loss: 1156984.2500 - val_mae: 768.7906\n",
      "Epoch 115/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1174143.0000 - mae: 775.7345 - val_loss: 1157418.8750 - val_mae: 773.5385\n",
      "Epoch 116/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1173208.5000 - mae: 776.0316 - val_loss: 1155107.0000 - val_mae: 769.5829\n",
      "Epoch 117/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1172957.1250 - mae: 776.6345 - val_loss: 1161368.8750 - val_mae: 767.3782\n",
      "Epoch 118/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171828.0000 - mae: 774.6519 - val_loss: 1155980.8750 - val_mae: 772.5528\n",
      "Epoch 119/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1172366.8750 - mae: 776.0625 - val_loss: 1155395.2500 - val_mae: 770.6229\n",
      "Epoch 120/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1170618.8750 - mae: 775.8094 - val_loss: 1160269.8750 - val_mae: 767.6867\n",
      "Epoch 121/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171561.1250 - mae: 774.3242 - val_loss: 1156443.1250 - val_mae: 770.3881\n",
      "Epoch 122/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171263.0000 - mae: 775.1760 - val_loss: 1158763.3750 - val_mae: 767.3179\n",
      "Epoch 123/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171232.0000 - mae: 774.1852 - val_loss: 1154076.7500 - val_mae: 768.8389\n",
      "Epoch 124/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171925.6250 - mae: 775.3411 - val_loss: 1155500.2500 - val_mae: 768.0194\n",
      "Epoch 125/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1169828.0000 - mae: 773.0969 - val_loss: 1153693.8750 - val_mae: 770.3381\n",
      "Epoch 126/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1170569.2500 - mae: 775.4705 - val_loss: 1153991.1250 - val_mae: 768.2892\n",
      "Epoch 127/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1171234.5000 - mae: 774.9207 - val_loss: 1153182.1250 - val_mae: 769.0671\n",
      "Epoch 128/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1170344.5000 - mae: 773.0903 - val_loss: 1154037.6250 - val_mae: 769.7670\n",
      "Epoch 129/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1169622.6250 - mae: 774.3386 - val_loss: 1155419.5000 - val_mae: 767.6592\n",
      "Epoch 130/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1170188.5000 - mae: 774.3119 - val_loss: 1153724.0000 - val_mae: 767.7813\n",
      "Epoch 131/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168848.1250 - mae: 773.0959 - val_loss: 1160643.1250 - val_mae: 766.9017\n",
      "Epoch 132/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168307.5000 - mae: 772.5730 - val_loss: 1153924.1250 - val_mae: 769.7822\n",
      "Epoch 133/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1169159.2500 - mae: 773.4583 - val_loss: 1153721.2500 - val_mae: 769.7688\n",
      "Epoch 134/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1167670.0000 - mae: 772.9079 - val_loss: 1157130.7500 - val_mae: 767.4113\n",
      "Epoch 135/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168690.7500 - mae: 773.3365 - val_loss: 1156028.0000 - val_mae: 767.3228\n",
      "Epoch 136/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1169712.6250 - mae: 773.4099 - val_loss: 1156360.1250 - val_mae: 767.2372\n",
      "Epoch 137/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1167820.5000 - mae: 772.4617 - val_loss: 1154423.7500 - val_mae: 769.3317\n",
      "Epoch 138/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1166855.2500 - mae: 772.9768 - val_loss: 1153737.8750 - val_mae: 767.7144\n",
      "Epoch 139/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1165465.7500 - mae: 771.5139 - val_loss: 1152575.2500 - val_mae: 768.4779\n",
      "Epoch 140/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1167130.5000 - mae: 772.4885 - val_loss: 1156507.2500 - val_mae: 773.2543\n",
      "Epoch 141/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1168248.5000 - mae: 774.0585 - val_loss: 1154809.8750 - val_mae: 767.3764\n",
      "Epoch 142/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164894.1250 - mae: 772.0266 - val_loss: 1157002.8750 - val_mae: 766.2187\n",
      "Epoch 143/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1167269.3750 - mae: 772.2198 - val_loss: 1153604.8750 - val_mae: 766.5580\n",
      "Epoch 144/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1165295.1250 - mae: 770.2993 - val_loss: 1156567.3750 - val_mae: 774.1978\n",
      "Epoch 145/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1165483.1250 - mae: 772.6450 - val_loss: 1154515.2500 - val_mae: 766.9999\n",
      "Epoch 146/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164549.2500 - mae: 771.4631 - val_loss: 1159831.5000 - val_mae: 765.9204\n",
      "Epoch 147/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1165776.5000 - mae: 771.0261 - val_loss: 1155811.5000 - val_mae: 766.7884\n",
      "Epoch 148/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164884.1250 - mae: 770.9185 - val_loss: 1153397.3750 - val_mae: 766.9660\n",
      "Epoch 149/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164664.2500 - mae: 770.6747 - val_loss: 1153177.0000 - val_mae: 766.2178\n",
      "Epoch 150/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164109.5000 - mae: 771.0118 - val_loss: 1153392.5000 - val_mae: 766.0889\n",
      "Epoch 151/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164900.3750 - mae: 771.1729 - val_loss: 1152248.1250 - val_mae: 767.0449\n",
      "Epoch 152/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163992.1250 - mae: 770.4996 - val_loss: 1153530.7500 - val_mae: 766.8804\n",
      "Epoch 153/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164486.6250 - mae: 770.0303 - val_loss: 1153516.6250 - val_mae: 770.0907\n",
      "Epoch 154/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163618.5000 - mae: 771.2454 - val_loss: 1155422.6250 - val_mae: 771.6318\n",
      "Epoch 155/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1162948.1250 - mae: 771.1446 - val_loss: 1155572.1250 - val_mae: 765.8926\n",
      "Epoch 156/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163231.8750 - mae: 770.1691 - val_loss: 1157700.1250 - val_mae: 765.8543\n",
      "Epoch 157/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1162994.8750 - mae: 770.1242 - val_loss: 1153300.6250 - val_mae: 766.5234\n",
      "Epoch 158/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1161571.0000 - mae: 770.1672 - val_loss: 1152485.1250 - val_mae: 769.0214\n",
      "Epoch 159/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164369.7500 - mae: 770.1100 - val_loss: 1151873.1250 - val_mae: 767.4737\n",
      "Epoch 160/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163088.8750 - mae: 769.9447 - val_loss: 1152841.1250 - val_mae: 769.0926\n",
      "Epoch 161/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1162225.7500 - mae: 769.9950 - val_loss: 1152117.2500 - val_mae: 768.9779\n",
      "Epoch 162/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1164596.2500 - mae: 771.0292 - val_loss: 1151294.8750 - val_mae: 767.0165\n",
      "Epoch 163/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1163362.5000 - mae: 769.3918 - val_loss: 1151853.7500 - val_mae: 767.3952\n",
      "Epoch 164/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1161288.1250 - mae: 768.9591 - val_loss: 1151792.8750 - val_mae: 767.6989\n",
      "Epoch 165/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160821.3750 - mae: 769.7992 - val_loss: 1152231.1250 - val_mae: 765.4110\n",
      "Epoch 166/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1161315.3750 - mae: 769.0665 - val_loss: 1151054.5000 - val_mae: 768.2935\n",
      "Epoch 167/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1162215.6250 - mae: 769.4719 - val_loss: 1151278.1250 - val_mae: 767.2330\n",
      "Epoch 168/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1161969.3750 - mae: 769.8768 - val_loss: 1153156.3750 - val_mae: 765.4557\n",
      "Epoch 169/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160946.3750 - mae: 769.7369 - val_loss: 1150275.1250 - val_mae: 766.3203\n",
      "Epoch 170/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160706.0000 - mae: 769.5870 - val_loss: 1151881.2500 - val_mae: 765.7869\n",
      "Epoch 171/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160771.0000 - mae: 768.4212 - val_loss: 1151376.6250 - val_mae: 766.8353\n",
      "Epoch 172/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159736.3750 - mae: 768.6572 - val_loss: 1152976.5000 - val_mae: 765.8415\n",
      "Epoch 173/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159835.0000 - mae: 768.1844 - val_loss: 1150974.8750 - val_mae: 767.3439\n",
      "Epoch 174/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160771.7500 - mae: 769.2581 - val_loss: 1151172.6250 - val_mae: 766.1064\n",
      "Epoch 175/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159611.0000 - mae: 768.1114 - val_loss: 1150461.7500 - val_mae: 765.7659\n",
      "Epoch 176/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159148.0000 - mae: 768.1964 - val_loss: 1150405.6250 - val_mae: 765.6338\n",
      "Epoch 177/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1160215.5000 - mae: 768.8687 - val_loss: 1150142.3750 - val_mae: 767.3038\n",
      "Epoch 178/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1158549.1250 - mae: 768.4498 - val_loss: 1155552.0000 - val_mae: 764.7942\n",
      "Epoch 179/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159593.5000 - mae: 768.1949 - val_loss: 1149619.1250 - val_mae: 767.0365\n",
      "Epoch 180/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157777.3750 - mae: 767.4005 - val_loss: 1151285.2500 - val_mae: 765.6817\n",
      "Epoch 181/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157729.5000 - mae: 768.2026 - val_loss: 1151851.1250 - val_mae: 764.7010\n",
      "Epoch 182/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159201.6250 - mae: 767.9988 - val_loss: 1150408.5000 - val_mae: 765.7715\n",
      "Epoch 183/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1158474.1250 - mae: 768.7996 - val_loss: 1155891.2500 - val_mae: 764.4138\n",
      "Epoch 184/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1160053.2500 - mae: 768.0330 - val_loss: 1152964.1250 - val_mae: 765.1210\n",
      "Epoch 185/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157026.0000 - mae: 767.4789 - val_loss: 1151090.7500 - val_mae: 765.3962\n",
      "Epoch 186/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1157165.6250 - mae: 767.6268 - val_loss: 1150300.6250 - val_mae: 769.2034\n",
      "Epoch 187/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157492.1250 - mae: 766.7002 - val_loss: 1151684.8750 - val_mae: 770.4980\n",
      "Epoch 188/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157926.1250 - mae: 768.7789 - val_loss: 1150609.7500 - val_mae: 766.9383\n",
      "Epoch 189/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1158239.5000 - mae: 768.1328 - val_loss: 1151545.0000 - val_mae: 765.0248\n",
      "Epoch 190/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157771.7500 - mae: 768.0561 - val_loss: 1149884.6250 - val_mae: 765.3906\n",
      "Epoch 191/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156288.5000 - mae: 766.6348 - val_loss: 1151676.2500 - val_mae: 769.3121\n",
      "Epoch 192/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157187.2500 - mae: 767.2532 - val_loss: 1149317.5000 - val_mae: 766.0993\n",
      "Epoch 193/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157227.6250 - mae: 767.0131 - val_loss: 1147748.0000 - val_mae: 766.5096\n",
      "Epoch 194/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155860.6250 - mae: 767.2089 - val_loss: 1150652.5000 - val_mae: 765.1960\n",
      "Epoch 195/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1157396.2500 - mae: 767.4146 - val_loss: 1149283.3750 - val_mae: 765.0487\n",
      "Epoch 196/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1155092.6250 - mae: 766.8073 - val_loss: 1150775.2500 - val_mae: 765.2656\n",
      "Epoch 197/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1155913.3750 - mae: 766.4170 - val_loss: 1149236.3750 - val_mae: 767.3236\n",
      "Epoch 198/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1159367.7500 - mae: 768.0665 - val_loss: 1150089.5000 - val_mae: 768.6370\n",
      "Epoch 199/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156373.0000 - mae: 767.2996 - val_loss: 1153033.1250 - val_mae: 763.9388\n",
      "Epoch 200/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156295.3750 - mae: 766.3188 - val_loss: 1150016.7500 - val_mae: 765.1245\n",
      "Epoch 201/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156272.5000 - mae: 767.2003 - val_loss: 1149423.3750 - val_mae: 764.8823\n",
      "Epoch 202/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1154700.3750 - mae: 765.8505 - val_loss: 1148407.6250 - val_mae: 766.3978\n",
      "Epoch 203/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1154588.6250 - mae: 766.7548 - val_loss: 1148727.2500 - val_mae: 764.7515\n",
      "Epoch 204/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1154946.2500 - mae: 764.6536 - val_loss: 1148594.7500 - val_mae: 766.6731\n",
      "Epoch 205/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1155921.3750 - mae: 766.8881 - val_loss: 1149578.8750 - val_mae: 764.9888\n",
      "Epoch 206/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1156631.3750 - mae: 766.1821 - val_loss: 1150101.1250 - val_mae: 767.4339\n",
      "Epoch 207/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1154542.3750 - mae: 766.6559 - val_loss: 1149339.2500 - val_mae: 768.3788\n",
      "Epoch 208/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153656.1250 - mae: 765.9668 - val_loss: 1147763.7500 - val_mae: 767.2126\n",
      "Epoch 209/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152835.1250 - mae: 765.5001 - val_loss: 1148683.6250 - val_mae: 765.9833\n",
      "Epoch 210/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152976.7500 - mae: 765.0036 - val_loss: 1150730.3750 - val_mae: 769.0981\n",
      "Epoch 211/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1154054.3750 - mae: 766.5205 - val_loss: 1152660.6250 - val_mae: 763.7098\n",
      "Epoch 212/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153665.0000 - mae: 765.1527 - val_loss: 1148662.3750 - val_mae: 763.7048\n",
      "Epoch 213/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153178.7500 - mae: 766.0696 - val_loss: 1148922.5000 - val_mae: 764.2103\n",
      "Epoch 214/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153063.2500 - mae: 764.7674 - val_loss: 1149399.1250 - val_mae: 766.1219\n",
      "Epoch 215/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153165.1250 - mae: 765.6362 - val_loss: 1149168.5000 - val_mae: 763.6445\n",
      "Epoch 216/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1152606.2500 - mae: 765.4047 - val_loss: 1149548.7500 - val_mae: 764.7050\n",
      "Epoch 217/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152424.6250 - mae: 764.5596 - val_loss: 1148494.7500 - val_mae: 766.1954\n",
      "Epoch 218/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152672.1250 - mae: 765.6597 - val_loss: 1148460.8750 - val_mae: 763.6193\n",
      "Epoch 219/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153794.8750 - mae: 765.8197 - val_loss: 1146911.0000 - val_mae: 765.7365\n",
      "Epoch 220/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153974.0000 - mae: 765.0359 - val_loss: 1148418.0000 - val_mae: 763.6475\n",
      "Epoch 221/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152254.1250 - mae: 764.8321 - val_loss: 1146405.3750 - val_mae: 765.0116\n",
      "Epoch 222/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151483.3750 - mae: 764.8887 - val_loss: 1148430.2500 - val_mae: 766.2466\n",
      "Epoch 223/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1152657.3750 - mae: 765.2163 - val_loss: 1148260.2500 - val_mae: 764.1433\n",
      "Epoch 224/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151039.5000 - mae: 764.0219 - val_loss: 1149736.5000 - val_mae: 768.7017\n",
      "Epoch 225/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1151388.0000 - mae: 764.5775 - val_loss: 1147926.8750 - val_mae: 766.8901\n",
      "Epoch 226/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151089.8750 - mae: 764.6056 - val_loss: 1147682.7500 - val_mae: 764.5399\n",
      "Epoch 227/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151067.5000 - mae: 764.1759 - val_loss: 1148641.8750 - val_mae: 763.1059\n",
      "Epoch 228/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1150720.8750 - mae: 764.0579 - val_loss: 1149368.2500 - val_mae: 763.1794\n",
      "Epoch 229/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149747.3750 - mae: 763.7003 - val_loss: 1145984.2500 - val_mae: 764.2065\n",
      "Epoch 230/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1150293.5000 - mae: 764.0340 - val_loss: 1149018.8750 - val_mae: 768.8343\n",
      "Epoch 231/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151633.1250 - mae: 764.6429 - val_loss: 1147760.6250 - val_mae: 763.0988\n",
      "Epoch 232/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1151871.6250 - mae: 764.1140 - val_loss: 1147499.8750 - val_mae: 764.5432\n",
      "Epoch 233/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148964.0000 - mae: 764.4020 - val_loss: 1151622.2500 - val_mae: 762.5079\n",
      "Epoch 234/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153849.7500 - mae: 764.5567 - val_loss: 1147092.1250 - val_mae: 763.9364\n",
      "Epoch 235/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1150877.0000 - mae: 763.8422 - val_loss: 1147851.1250 - val_mae: 763.2935\n",
      "Epoch 236/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1150019.7500 - mae: 764.1495 - val_loss: 1148664.5000 - val_mae: 762.9707\n",
      "Epoch 237/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148250.2500 - mae: 763.6804 - val_loss: 1151443.6250 - val_mae: 762.6467\n",
      "Epoch 238/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1150806.7500 - mae: 763.3464 - val_loss: 1147608.6250 - val_mae: 767.3912\n",
      "Epoch 239/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148647.7500 - mae: 762.9955 - val_loss: 1148016.7500 - val_mae: 767.8048\n",
      "Epoch 240/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149141.8750 - mae: 764.8442 - val_loss: 1147425.1250 - val_mae: 766.8277\n",
      "Epoch 241/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149757.8750 - mae: 763.8484 - val_loss: 1145071.1250 - val_mae: 763.8420\n",
      "Epoch 242/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149431.2500 - mae: 763.4410 - val_loss: 1147419.6250 - val_mae: 767.1978\n",
      "Epoch 243/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149235.0000 - mae: 763.2990 - val_loss: 1144859.6250 - val_mae: 764.0052\n",
      "Epoch 244/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148280.7500 - mae: 763.5012 - val_loss: 1146911.1250 - val_mae: 763.4822\n",
      "Epoch 245/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148044.5000 - mae: 762.9253 - val_loss: 1145970.5000 - val_mae: 763.0928\n",
      "Epoch 246/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149570.0000 - mae: 762.9785 - val_loss: 1146398.1250 - val_mae: 765.2307\n",
      "Epoch 247/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1149755.6250 - mae: 763.2045 - val_loss: 1144579.3750 - val_mae: 763.7316\n",
      "Epoch 248/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147686.3750 - mae: 762.8112 - val_loss: 1146390.5000 - val_mae: 763.7672\n",
      "Epoch 249/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148945.0000 - mae: 762.6934 - val_loss: 1149181.7500 - val_mae: 762.5781\n",
      "Epoch 250/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147438.2500 - mae: 762.6902 - val_loss: 1150004.7500 - val_mae: 770.0465\n",
      "Epoch 251/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1148760.1250 - mae: 763.8898 - val_loss: 1146204.1250 - val_mae: 763.1122\n",
      "Epoch 252/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147189.5000 - mae: 762.4455 - val_loss: 1150820.7500 - val_mae: 761.7639\n",
      "Epoch 253/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147629.8750 - mae: 761.7837 - val_loss: 1147302.8750 - val_mae: 762.0436\n",
      "Epoch 254/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146785.5000 - mae: 761.0193 - val_loss: 1145220.0000 - val_mae: 764.4983\n",
      "Epoch 255/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1153440.7500 - mae: 765.5229 - val_loss: 1152198.5000 - val_mae: 771.3278\n",
      "Epoch 256/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147374.2500 - mae: 762.8424 - val_loss: 1146782.5000 - val_mae: 764.1034\n",
      "Epoch 257/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145636.7500 - mae: 762.1479 - val_loss: 1149931.3750 - val_mae: 761.5417\n",
      "Epoch 258/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147086.1250 - mae: 762.0759 - val_loss: 1146725.2500 - val_mae: 762.3958\n",
      "Epoch 259/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147163.7500 - mae: 762.1447 - val_loss: 1145610.5000 - val_mae: 765.0341\n",
      "Epoch 260/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145686.5000 - mae: 761.8375 - val_loss: 1151409.7500 - val_mae: 761.7009\n",
      "Epoch 261/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1147119.2500 - mae: 761.4283 - val_loss: 1144258.0000 - val_mae: 765.2312\n",
      "Epoch 262/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1147548.7500 - mae: 762.5128 - val_loss: 1145614.1250 - val_mae: 762.1014\n",
      "Epoch 263/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146238.5000 - mae: 762.1850 - val_loss: 1143438.0000 - val_mae: 762.3666\n",
      "Epoch 264/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146037.2500 - mae: 761.4401 - val_loss: 1144230.8750 - val_mae: 764.9616\n",
      "Epoch 265/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146137.3750 - mae: 762.9698 - val_loss: 1148789.1250 - val_mae: 761.8824\n",
      "Epoch 266/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145948.1250 - mae: 761.4386 - val_loss: 1147159.1250 - val_mae: 762.0284\n",
      "Epoch 267/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145160.7500 - mae: 761.1154 - val_loss: 1142994.1250 - val_mae: 764.0557\n",
      "Epoch 268/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146875.6250 - mae: 761.6373 - val_loss: 1144203.8750 - val_mae: 765.8322\n",
      "Epoch 269/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144218.2500 - mae: 761.1069 - val_loss: 1144870.5000 - val_mae: 761.9166\n",
      "Epoch 270/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144846.1250 - mae: 761.4413 - val_loss: 1143940.7500 - val_mae: 762.4207\n",
      "Epoch 271/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145190.2500 - mae: 761.8990 - val_loss: 1150110.6250 - val_mae: 761.3856\n",
      "Epoch 272/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1146095.2500 - mae: 761.1727 - val_loss: 1146671.0000 - val_mae: 761.8348\n",
      "Epoch 273/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1142780.2500 - mae: 760.7508 - val_loss: 1146244.8750 - val_mae: 765.7515\n",
      "Epoch 274/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145726.5000 - mae: 762.0308 - val_loss: 1144459.8750 - val_mae: 764.1625\n",
      "Epoch 275/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1143375.6250 - mae: 760.9523 - val_loss: 1144875.3750 - val_mae: 765.8052\n",
      "Epoch 276/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145943.0000 - mae: 760.6979 - val_loss: 1143937.6250 - val_mae: 761.7408\n",
      "Epoch 277/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1145014.0000 - mae: 760.9662 - val_loss: 1144003.1250 - val_mae: 764.7733\n",
      "Epoch 278/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1143843.3750 - mae: 760.9256 - val_loss: 1145665.0000 - val_mae: 761.1431\n",
      "Epoch 279/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144334.5000 - mae: 760.7864 - val_loss: 1142419.0000 - val_mae: 762.2560\n",
      "Epoch 280/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1143922.8750 - mae: 760.5870 - val_loss: 1142519.3750 - val_mae: 762.2724\n",
      "Epoch 281/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1143401.1250 - mae: 760.5142 - val_loss: 1143607.5000 - val_mae: 763.3506\n",
      "Epoch 282/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1142787.3750 - mae: 760.0963 - val_loss: 1143807.2500 - val_mae: 763.0001\n",
      "Epoch 283/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1143207.5000 - mae: 760.8959 - val_loss: 1142421.1250 - val_mae: 762.3656\n",
      "Epoch 284/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1143624.2500 - mae: 760.2045 - val_loss: 1142140.6250 - val_mae: 762.9530\n",
      "Epoch 285/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1142825.5000 - mae: 761.2092 - val_loss: 1144324.1250 - val_mae: 760.7627\n",
      "Epoch 286/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1142930.8750 - mae: 759.0994 - val_loss: 1143693.0000 - val_mae: 764.3486\n",
      "Epoch 287/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1144756.3750 - mae: 761.6284 - val_loss: 1144468.2500 - val_mae: 761.9784\n",
      "Epoch 288/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1142456.1250 - mae: 759.8695 - val_loss: 1144760.1250 - val_mae: 764.2176\n",
      "Epoch 289/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1140820.5000 - mae: 760.4916 - val_loss: 1146455.7500 - val_mae: 761.2634\n",
      "Epoch 290/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141902.5000 - mae: 759.2386 - val_loss: 1142879.0000 - val_mae: 762.1710\n",
      "Epoch 291/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141554.1250 - mae: 759.3591 - val_loss: 1143456.5000 - val_mae: 761.9606\n",
      "Epoch 292/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1142210.1250 - mae: 760.3467 - val_loss: 1144294.0000 - val_mae: 762.0256\n",
      "Epoch 293/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141367.7500 - mae: 758.8749 - val_loss: 1148396.0000 - val_mae: 760.8481\n",
      "Epoch 294/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140511.0000 - mae: 759.0334 - val_loss: 1142846.1250 - val_mae: 763.7966\n",
      "Epoch 295/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141829.6250 - mae: 760.1877 - val_loss: 1146261.1250 - val_mae: 761.3134\n",
      "Epoch 296/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141611.6250 - mae: 758.6765 - val_loss: 1143780.0000 - val_mae: 764.1864\n",
      "Epoch 297/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1141519.3750 - mae: 760.1198 - val_loss: 1143670.3750 - val_mae: 762.8361\n",
      "Epoch 298/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140411.7500 - mae: 758.3981 - val_loss: 1142827.6250 - val_mae: 763.3596\n",
      "Epoch 299/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141111.0000 - mae: 759.2978 - val_loss: 1144126.0000 - val_mae: 764.1689\n",
      "Epoch 300/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140336.7500 - mae: 758.9385 - val_loss: 1141348.6250 - val_mae: 762.7086\n",
      "Epoch 301/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139719.0000 - mae: 760.6700 - val_loss: 1149717.2500 - val_mae: 759.8947\n",
      "Epoch 302/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141962.3750 - mae: 758.7628 - val_loss: 1146179.8750 - val_mae: 766.8043\n",
      "Epoch 303/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139609.1250 - mae: 759.0236 - val_loss: 1150194.0000 - val_mae: 759.9700\n",
      "Epoch 304/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141367.3750 - mae: 758.5905 - val_loss: 1147672.8750 - val_mae: 760.5057\n",
      "Epoch 305/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1141749.7500 - mae: 758.4174 - val_loss: 1142774.1250 - val_mae: 763.3887\n",
      "Epoch 306/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1141495.3750 - mae: 759.3092 - val_loss: 1141944.7500 - val_mae: 760.8440\n",
      "Epoch 307/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140711.7500 - mae: 758.5789 - val_loss: 1142796.1250 - val_mae: 761.9614\n",
      "Epoch 308/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140359.5000 - mae: 758.3587 - val_loss: 1142496.7500 - val_mae: 760.6610\n",
      "Epoch 309/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139908.1250 - mae: 758.3435 - val_loss: 1144734.1250 - val_mae: 762.7606\n",
      "Epoch 310/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140937.1250 - mae: 758.3952 - val_loss: 1144146.1250 - val_mae: 764.8351\n",
      "Epoch 311/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139570.2500 - mae: 757.5538 - val_loss: 1145205.8750 - val_mae: 764.9988\n",
      "Epoch 312/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140233.7500 - mae: 759.1676 - val_loss: 1141619.5000 - val_mae: 760.9236\n",
      "Epoch 313/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140550.7500 - mae: 758.1691 - val_loss: 1150212.2500 - val_mae: 759.7592\n",
      "Epoch 314/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1138673.1250 - mae: 757.3240 - val_loss: 1143245.5000 - val_mae: 763.5441\n",
      "Epoch 315/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140839.3750 - mae: 758.2794 - val_loss: 1142481.6250 - val_mae: 761.4166\n",
      "Epoch 316/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138466.2500 - mae: 757.1594 - val_loss: 1141733.3750 - val_mae: 760.5302\n",
      "Epoch 317/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138503.8750 - mae: 758.0106 - val_loss: 1140812.3750 - val_mae: 760.1312\n",
      "Epoch 318/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138441.3750 - mae: 757.6581 - val_loss: 1143159.2500 - val_mae: 759.8534\n",
      "Epoch 319/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1140108.3750 - mae: 758.8058 - val_loss: 1142702.8750 - val_mae: 760.0380\n",
      "Epoch 320/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139019.8750 - mae: 756.4256 - val_loss: 1141786.3750 - val_mae: 761.3771\n",
      "Epoch 321/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137663.1250 - mae: 756.8307 - val_loss: 1141572.7500 - val_mae: 760.6492\n",
      "Epoch 322/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1138017.3750 - mae: 756.9076 - val_loss: 1141756.0000 - val_mae: 760.1005\n",
      "Epoch 323/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138089.3750 - mae: 757.3758 - val_loss: 1146947.0000 - val_mae: 759.0439\n",
      "Epoch 324/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1139124.7500 - mae: 757.7130 - val_loss: 1149142.3750 - val_mae: 759.5280\n",
      "Epoch 325/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138607.2500 - mae: 755.7758 - val_loss: 1142403.7500 - val_mae: 761.6898\n",
      "Epoch 326/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137341.0000 - mae: 756.9121 - val_loss: 1142923.2500 - val_mae: 760.0096\n",
      "Epoch 327/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137095.3750 - mae: 755.6631 - val_loss: 1142336.6250 - val_mae: 760.2747\n",
      "Epoch 328/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137425.7500 - mae: 757.4982 - val_loss: 1143822.3750 - val_mae: 759.0307\n",
      "Epoch 329/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137578.3750 - mae: 756.8198 - val_loss: 1142012.0000 - val_mae: 758.6664\n",
      "Epoch 330/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135649.2500 - mae: 754.5937 - val_loss: 1142985.6250 - val_mae: 762.8992\n",
      "Epoch 331/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137775.5000 - mae: 756.6629 - val_loss: 1143640.8750 - val_mae: 758.3653\n",
      "Epoch 332/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137899.7500 - mae: 756.0421 - val_loss: 1142203.8750 - val_mae: 761.3019\n",
      "Epoch 333/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137950.5000 - mae: 756.2771 - val_loss: 1142087.6250 - val_mae: 760.9806\n",
      "Epoch 334/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138352.1250 - mae: 757.0670 - val_loss: 1141990.2500 - val_mae: 761.5985\n",
      "Epoch 335/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136017.3750 - mae: 755.7981 - val_loss: 1142967.6250 - val_mae: 758.9620\n",
      "Epoch 336/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136111.5000 - mae: 755.3453 - val_loss: 1142749.7500 - val_mae: 761.1316\n",
      "Epoch 337/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136608.8750 - mae: 756.1762 - val_loss: 1141527.0000 - val_mae: 760.0103\n",
      "Epoch 338/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135929.6250 - mae: 755.3885 - val_loss: 1141670.7500 - val_mae: 760.4871\n",
      "Epoch 339/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1136031.7500 - mae: 756.2231 - val_loss: 1147047.0000 - val_mae: 758.1116\n",
      "Epoch 340/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136990.5000 - mae: 754.9171 - val_loss: 1141861.7500 - val_mae: 761.0069\n",
      "Epoch 341/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137210.5000 - mae: 756.7068 - val_loss: 1143211.6250 - val_mae: 761.8062\n",
      "Epoch 342/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135243.8750 - mae: 755.9186 - val_loss: 1145371.2500 - val_mae: 757.9274\n",
      "Epoch 343/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136246.6250 - mae: 754.3015 - val_loss: 1141034.1250 - val_mae: 759.4637\n",
      "Epoch 344/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135586.7500 - mae: 755.2896 - val_loss: 1142099.2500 - val_mae: 761.4642\n",
      "Epoch 345/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1138052.6250 - mae: 756.0991 - val_loss: 1143662.6250 - val_mae: 759.5020\n",
      "Epoch 346/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135136.6250 - mae: 755.5998 - val_loss: 1141638.6250 - val_mae: 760.1606\n",
      "Epoch 347/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1135916.1250 - mae: 755.7110 - val_loss: 1143737.5000 - val_mae: 758.0261\n",
      "Epoch 348/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137125.1250 - mae: 755.6432 - val_loss: 1143902.2500 - val_mae: 758.6295\n",
      "Epoch 349/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134833.2500 - mae: 755.6113 - val_loss: 1145428.1250 - val_mae: 757.5122\n",
      "Epoch 350/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135350.7500 - mae: 753.3289 - val_loss: 1140304.0000 - val_mae: 759.6505\n",
      "Epoch 351/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1137883.2500 - mae: 756.5085 - val_loss: 1143170.0000 - val_mae: 756.7764\n",
      "Epoch 352/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133970.2500 - mae: 755.2562 - val_loss: 1141580.2500 - val_mae: 761.5019\n",
      "Epoch 353/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135026.7500 - mae: 753.9726 - val_loss: 1140656.3750 - val_mae: 759.7632\n",
      "Epoch 354/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1134627.3750 - mae: 754.8781 - val_loss: 1141412.6250 - val_mae: 759.1710\n",
      "Epoch 355/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135579.7500 - mae: 754.4578 - val_loss: 1141865.3750 - val_mae: 758.9363\n",
      "Epoch 356/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134375.6250 - mae: 755.8137 - val_loss: 1141097.2500 - val_mae: 758.3807\n",
      "Epoch 357/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136431.7500 - mae: 754.9399 - val_loss: 1141689.3750 - val_mae: 759.1526\n",
      "Epoch 358/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134133.1250 - mae: 752.4670 - val_loss: 1141562.5000 - val_mae: 761.9066\n",
      "Epoch 359/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1136077.7500 - mae: 755.3424 - val_loss: 1140478.0000 - val_mae: 757.8397\n",
      "Epoch 360/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134271.2500 - mae: 753.3730 - val_loss: 1141859.1250 - val_mae: 760.5826\n",
      "Epoch 361/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133423.6250 - mae: 753.3100 - val_loss: 1140928.6250 - val_mae: 756.7560\n",
      "Epoch 362/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134799.1250 - mae: 753.9644 - val_loss: 1140424.1250 - val_mae: 759.5644\n",
      "Epoch 363/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1134940.3750 - mae: 754.8471 - val_loss: 1144176.8750 - val_mae: 756.1665\n",
      "Epoch 364/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1135155.8750 - mae: 753.2842 - val_loss: 1143751.6250 - val_mae: 757.2260\n",
      "Epoch 365/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132668.3750 - mae: 753.3328 - val_loss: 1144165.0000 - val_mae: 756.1008\n",
      "Epoch 366/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134179.0000 - mae: 753.7759 - val_loss: 1142150.8750 - val_mae: 756.8722\n",
      "Epoch 367/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134507.7500 - mae: 753.2106 - val_loss: 1139831.1250 - val_mae: 757.2909\n",
      "Epoch 368/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134547.8750 - mae: 754.5770 - val_loss: 1141166.3750 - val_mae: 756.2195\n",
      "Epoch 369/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1134244.1250 - mae: 753.6125 - val_loss: 1141500.1250 - val_mae: 755.7361\n",
      "Epoch 370/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134585.8750 - mae: 753.2632 - val_loss: 1142720.2500 - val_mae: 756.2864\n",
      "Epoch 371/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134125.1250 - mae: 752.9541 - val_loss: 1140537.0000 - val_mae: 757.3203\n",
      "Epoch 372/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132768.2500 - mae: 753.1063 - val_loss: 1141594.3750 - val_mae: 757.0545\n",
      "Epoch 373/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132499.2500 - mae: 752.0767 - val_loss: 1144022.8750 - val_mae: 762.2388\n",
      "Epoch 374/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134821.8750 - mae: 753.4680 - val_loss: 1138732.7500 - val_mae: 756.5186\n",
      "Epoch 375/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133168.2500 - mae: 752.9686 - val_loss: 1140939.5000 - val_mae: 756.3332\n",
      "Epoch 376/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133653.1250 - mae: 753.0895 - val_loss: 1140665.5000 - val_mae: 755.9244\n",
      "Epoch 377/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1132292.5000 - mae: 752.5262 - val_loss: 1142396.7500 - val_mae: 754.7107\n",
      "Epoch 378/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131915.8750 - mae: 750.4702 - val_loss: 1139116.6250 - val_mae: 756.8379\n",
      "Epoch 379/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1134700.6250 - mae: 752.8859 - val_loss: 1140073.1250 - val_mae: 756.0130\n",
      "Epoch 380/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132508.3750 - mae: 751.5776 - val_loss: 1140226.3750 - val_mae: 756.3549\n",
      "Epoch 381/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132938.6250 - mae: 751.7312 - val_loss: 1140808.3750 - val_mae: 757.2856\n",
      "Epoch 382/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131872.0000 - mae: 752.1640 - val_loss: 1142109.6250 - val_mae: 755.2511\n",
      "Epoch 383/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132413.6250 - mae: 751.9428 - val_loss: 1140542.0000 - val_mae: 756.0769\n",
      "Epoch 384/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1132099.0000 - mae: 752.1151 - val_loss: 1140022.6250 - val_mae: 756.4060\n",
      "Epoch 385/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133037.7500 - mae: 752.6801 - val_loss: 1140620.0000 - val_mae: 757.9109\n",
      "Epoch 386/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132059.3750 - mae: 752.3433 - val_loss: 1139067.6250 - val_mae: 755.8608\n",
      "Epoch 387/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1133476.0000 - mae: 752.0808 - val_loss: 1140215.5000 - val_mae: 756.4015\n",
      "Epoch 388/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132201.6250 - mae: 751.9902 - val_loss: 1140699.8750 - val_mae: 754.6755\n",
      "Epoch 389/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131953.2500 - mae: 750.6927 - val_loss: 1139925.8750 - val_mae: 757.6190\n",
      "Epoch 390/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132503.2500 - mae: 752.2637 - val_loss: 1139324.3750 - val_mae: 757.1607\n",
      "Epoch 391/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132248.8750 - mae: 752.2841 - val_loss: 1139815.6250 - val_mae: 755.1372\n",
      "Epoch 392/400\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1133369.3750 - mae: 750.9456 - val_loss: 1142746.5000 - val_mae: 754.1428\n",
      "Epoch 393/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1132082.3750 - mae: 750.7900 - val_loss: 1139132.8750 - val_mae: 755.2932\n",
      "Epoch 394/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131182.2500 - mae: 750.7711 - val_loss: 1138948.2500 - val_mae: 755.4957\n",
      "Epoch 395/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130423.2500 - mae: 751.8809 - val_loss: 1141479.3750 - val_mae: 753.7077\n",
      "Epoch 396/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130512.3750 - mae: 749.6888 - val_loss: 1138029.1250 - val_mae: 755.1254\n",
      "Epoch 397/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130159.1250 - mae: 750.1332 - val_loss: 1140519.6250 - val_mae: 757.0048\n",
      "Epoch 398/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1131515.7500 - mae: 750.5931 - val_loss: 1140700.3750 - val_mae: 754.5181\n",
      "Epoch 399/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130759.5000 - mae: 750.5009 - val_loss: 1139218.3750 - val_mae: 755.6128\n",
      "Epoch 400/400\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1130592.8750 - mae: 750.3220 - val_loss: 1139342.1250 - val_mae: 755.5479\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "\n",
    "# passing the independent and dependent features for training set for training the model\n",
    "\n",
    "# validation data will be evaluated at the end of each epoch\n",
    "\n",
    "# setting the epochs as 50\n",
    "\n",
    "# storing the trained model in model_history variable which will be used to visualize the training process\n",
    "\n",
    "model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 1139342.1250 - mae: 755.5479\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 882us/step\n",
      "R2 Score: 0.605356359282686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2 Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model_history.history['mae'])\n",
    "plt.plot(model_history.history['val_mae'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.605356359282686"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
